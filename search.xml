<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[二、Fabric 架构和原理]]></title>
    <url>%2F2019%2F12%2F07%2Fblockchain%2F2019-12-07-%E4%BA%8C%E3%80%81Fabric%20%E6%9E%B6%E6%9E%84%E5%92%8C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[#1.Fabric总体架构 Fabric架构主要包括三个模块：会员(Membership)，区块链(Blockchan)和链码(chaincode)。 1.1成员服务包含下列组件：注册、身份认证管理及审计。 成员服务通过公钥基础设施(Public Key Infrastructure (PKI))和去中心化的/共识技术使得不带权限的区块链变成带权限的区块链。成员必须被许可才能加入网络，通过实体注册来获得长时间的，可能根据实体类型生成的身份凭证(登记证书enrollment certificates)。在用户使用过程中，这样的证书允许交易证书颁发机构(Transaction Certificate Authority (TCA))颁发匿名证书。交易证书被用来对提交交易授权。交易证书存储在区块链中，并对审计集群授权，否则交易是不可链接的。 1.2区块链服务包含下列组件：共识管理、分布式账本、点对点网络和分类存储 区块链服务通过HTTP/2上的点对点(peer-to-peer)协议来管理分布式总账。为了提供最高效的哈希算法来维护世界状态的复制，数据结构进行了高度的优化。每个部署中可以插入和配置不同的共识算法(PBFT, Raft, PoW, PoS)。 1.3链码服务包含下列组件：安全容器 、安全注册中心 Fabric的智能合约smart contract称为链码chaincode，是一段代码，它处理网络成员所同意的业务逻辑。 链码可采用Go、Java、Node.js语言编写。链码被编译成一个独立的应用程序，fabric用Docker容器来运行chaincode，里面的base镜像都是经过签名验证的安全镜像，包括OS层和开发chaincode的语言、runtime和SDK层。一旦chaincode容器被启动，它就会通过gRPC与启动这个chaincode的Peer节点连接。 1.4账本账本Ledger主要包含两块：blockchain和state。blockchain就是一系列连在一起的block，用来记录历史交易。state对应账本的当前最新状态，它是一个key-value数据库，Fabric默认采用Level DB, 可以替换成其他的Key-value数据库，如Couch DB。 1.5交易Fabric上的transction交易分两种，部署和调用。 1.5.1部署：把Chaincode部署到peer节点上并准备好被调用，当一个部署交易成功执行时，Chaincode就被部署到各个peer节点上。好比把一个web service或者EJB部署到应用服务器上的不同实例上。 1.5.2调用：客户端应用程序通过Fabric提供的API调用先前已部署好的某个chaincode的某个函数执行交易，并相应地读取和写入KV数据库，返回是否成功或者失败。 1.6 APIs, Events, SDKsFabric提供API方便应用开发，对服务端的ChainCode，目前支持用Go、Java或者Node.js开发。对客户端应用，Fabric目前提供Node.js和Java SDK。未来计划提供Python 和Go SDK，Fabric还提供RESTAPI。对于开发者，还可以通过CLI快速去测试chaincode，或者去查询交易状态。在区块链网络里，节点和chaincode会发送events来触发一些监听动作，方便与其他外部系统的集成。 2.Fabric应用开发流程开发者创建客户端应用和智能合约（chaincode），Chaincode被部署到区块链网络的Peer节点上面。通过chaincode来操作账本，当你调用一个交易transaction时，你实际上是在调用Chaincode中的一个函数方法，它实现业务逻辑，并对账本进行get, put, delete操作。客户端应用提供用户交互界面，并提交交易到区块链网络上。 3.Fabric网络节点是区块链的通信实体，节点是一个逻辑概念，不同类型的节点可以运行在同一台物理服务器上。这些节点可能部署在云上面或者本地。可能来自不同的公司或者组织。在区块链网络中有两种类型的节点：Peer节点和Orderer节点，如下图所示。Peer节点：chaincode部署在Peer节点上，它对账本进行读写操作。一个Peer节点可以充当多种角色，如背书者endorser,提交者committer。一个区块链网络中会有多个Peer节点。 Orderer节点：对交易进行排序，批量打包，生成区块，发给Peer节点。一个区块链网络中会有多个Orderer节点，它们共同提供排序服务。排序服务可以别实现为多种不同的方式，从一个中心化的服务（被用于开发和测试，如Solo）,到分布式协议（如Kafka）。 排序服务提供了通向客户端和Peer节点的共享通信通道。提供了包含交易的消息广播服务（broadcast和deliver）。客户端可以通过这个通道向所有的节点广播（broadcast）消息。通道可以向连接到该通道的节点投递(deliver)消息。 排序服务支持多通道，类似于发布/订阅消息系统中的主题topic。客户端和Peer节点可以连接到一个给点的通道，并通过给定的通道发送和接收消息。多通道使得Peer节点可以基于应用访问控制策略来订阅任意数量的通道;也就是说，应用程序在指定Peer节点的子集中架设通道。这些peer组成提交到该通道交易的相关者集合，而且只有这些peer可以接收包含相关交易的区块，与其他交易完全隔离，实现数据隔离和保密。 此外，peers的子集将这些私有块提交到不同的账本上，允许它们保护这些私有交易，与其他peers子集的账本隔离开来。应用程序根据业务逻辑决定将交易发送到1个或多个通道。 例如，如上图所示，peer 1,2和N订阅红色通道，并共同维护红色账本; peer 1和N订阅蓝色通道并维护蓝色账本;类似地，peer 2和peer N在黑色通道上并维护黑色账本。 在这个例子中，peer N在订阅了所有通道，我们看到每个通道都有一个相关的账本。一般来说，我们称不涉及所有peer的账本为子账本，另一种是系统账本，即全账本。 4.Fabric交易流程 第一步，客户端Client构造交易提案 client利用SDK（Node.js\java..）构造一个交易提案propose，该propose包含调用智能合约功能函数请求，用来确认哪些数据可以读取或者写入账本，client将交易提案propose发送给一个或多个peer节点，交易提案包含本次交易要调用的合约标识、合约方法和参数信息以及客户端签名等。 SDK将交易提案打包为可识别的格式（如gRPC上的protocolbuffer），并使用用户的加密凭证为该交易提案生成唯一的签名。 第二步，背书节点模拟执行交易 背书节点endorser收到交易提案后，验证签名并确定提交者是否有权执行操作。背书节点将交易提案的参数作为输入，在当前状态KV数据库上执行交易，生成包含执行返回值、读操作集合和写操作集合的交易结果（此时不会更新账本），这些值的集合、背书节点的签名和背书结果（YES / NO）作为提案的结果返回给客户端SDK，SDK解析这些信息判断是否应用于后续的交易。 第三步，客户端把交易发送到共识服务节点 应用程序（SDK）验证背书节点签名，并比较各节点返回的提案结果，判断提案结果是否一致以及是否参照指定的背书策略执行。客户端收到各个背书节点的应答后，打包到一起组成一个交易并签名，发送给Orderers。 第四步，orderer节点共识排序，生成新区块，提交交易 Orderers对接收到的交易进行共识排序，然后按照区块生成策略，将一批交易打包到一起，生成新的区块，调用deliver API投递消息，发送给提交节点。 提交节点收到区块后，会对区块中的每笔交易进行校验，检查交易依赖的输入输出是否符合当前区块链的状态，完成后将区块追加到本地的区块链，并修改K-V状态数据库。]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、Fabric 动态添加组织机构]]></title>
    <url>%2F2019%2F12%2F07%2Fblockchain%2F2019-12-07-%E5%85%AD%E3%80%81Fabric%20%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0%E7%BB%84%E7%BB%87%E6%9C%BA%E6%9E%84%2F</url>
    <content type="text"><![CDATA[#1 核心步骤本文基于hellowrold区块链环境，动态添加机构 org3,以及两个peer 。动态添加机构比较复杂，需要修改通道配置文件，增量配置信息需要被超过50%的机构签名，并为每个peer更新通道增量配置。 核心分为三步： 1.生成新增org的组织机构的证书， 2.修改channel的配置块并更新， 3.编写docker-compose文件 #2 操作流程 ##2.1.生成证书###新增加crypto-config-org3.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758PeerOrgs: # --------------------------------------------------------------------------- # Org3 # --------------------------------------------------------------------------- - Name: Org3 Domain: org3.example.com EnableNodeOUs: true Specs: - Hostname: peer0 - Hostname: peer1 # --------------------------------------------------------------------------- # "Specs" # --------------------------------------------------------------------------- # Uncomment this section to enable the explicit definition of hosts in your # configuration. Most users will want to use Template, below # # Specs is an array of Spec entries. Each Spec entry consists of two fields: # - Hostname: (Required) The desired hostname, sans the domain. # - CommonName: (Optional) Specifies the template or explicit override for # the CN. By default, this is the template: # # "&#123;&#123;.Hostname&#125;&#125;.&#123;&#123;.Domain&#125;&#125;" # # which obtains its values from the Spec.Hostname and # Org.Domain, respectively. # --------------------------------------------------------------------------- # Specs: # - Hostname: foo # implicitly "foo.org1.example.com" # CommonName: foo27.org5.example.com # overrides Hostname-based FQDN set above # - Hostname: bar # - Hostname: baz # --------------------------------------------------------------------------- # "Template" # --------------------------------------------------------------------------- # Allows for the definition of 1 or more hosts that are created sequentially # from a template. By default, this looks like "peer%d" from 0 to Count-1. # You may override the number of nodes (Count), the starting index (Start) # or the template used to construct the name (Hostname). # # Note: Template and Specs are not mutually exclusive. You may define both # sections and the aggregate nodes will be created for you. Take care with # name collisions # --------------------------------------------------------------------------- Template: Count: 2 # Start: 5 # Hostname: &#123;&#123;.Prefix&#125;&#125;&#123;&#123;.Index&#125;&#125; # default # --------------------------------------------------------------------------- # "Users" # --------------------------------------------------------------------------- # Count: The number of user accounts _in addition_ to Admin # --------------------------------------------------------------------------- Users: Count: 1 # --------------------------------------------------------------------------- # Org3: See "Org1" for full specification # --------------------------------------------------------------------------- 执行证书生成1./bin/cryptogen generate --config=crypto-config-org3.yaml 在crypto-config/peerOrganizations目录下会多出org3.example.com文件夹。 生成org3 json配置修改configtx.yaml 文件 添加Org3相关内容执行 1./bin/configtxgen -printOrg Org3MSP &gt; ../channel-artifacts/org3.json 生成org3 的json配置 #2. 修改channel的配置块 ###2.1 制作增量配置文件在peer0.org1.example.com中操做，修改channel的配置，进入cli_peer0_org1中进行命令行操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748docker exec -it cli_peer0_org1 bash#在客户端容器中执行以下命令：ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#获取mychannel的配置区块peer channel fetch config config_block.pb -o orderer.example.com:7050 -c mychannel --tls --cafile $ORDERER_CA#转为jsonconfigtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.json#将org3加入到此json中jq -s &apos;.[0] * &#123;&quot;channel_group&quot;:&#123;&quot;groups&quot;:&#123;&quot;Application&quot;:&#123;&quot;groups&quot;: &#123;&quot;Org3MSP&quot;:.[1]&#125;&#125;&#125;&#125;&#125;&apos; config.json ./channel-artifacts/org3.json &gt; modified_config.json #原channel配置转为pbconfigtxlator proto_encode --input config.json --type common.Config --output config.pb#新channel配置转为pbconfigtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pb#计算新旧两个pb之间的增量configtxlator compute_update --channel_id mychannel --original config.pb --updated modified_config.pb --output org3_update.pb#增量PB转为jsonconfigtxlator proto_decode --input org3_update.pb --type common.ConfigUpdate | jq . &gt; org3_update.json#加入header信息echo &apos;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;mychannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&apos;$(cat org3_update.json)&apos;&#125;&#125;&#125;&apos; | jq . &gt; org3_update_in_envelope.json#转为pbconfigtxlator proto_encode --input org3_update_in_envelope.json --type common.Envelope --output org3_update_in_envelope.pb#新增org3需要此channel里面的大多数组织机构签名同意，也就是超过50%#Org1对增量配置进行签名peer channel signconfigtx -f org3_update_in_envelope.pb#cli切换到org2export CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:9051Org2对增量配置进行签名peer channel signconfigtx -f org3_update_in_envelope.pb 到此，已经有两个机构对增量配置进行了签名，超过了机构的51% ###2.2使用增量配置文件更新通道 1234ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem更新channel配置peer channel update -f org3_update_in_envelope.pb -c mychannel -o orderer.example.com:7050 --tls --cafile $ORDERER_CA #3.编写docker-compose文件并启动 编写docker-compose文件（官方first-network有，可以照着改为自己新增的org4，org5…………） ##3.1 peer0.org3.example.com的docker-compose配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: peer0.org3.example.com: container_name: peer0.org3.example.com image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer0.org3.example.com - CORE_PEER_LISTENADDRESS=0.0.0.0:13051 - CORE_PEER_ADDRESS=peer0.org3.example.com:13051 - CORE_PEER_CHAINCODEADDRESS=peer0.org3.example.com:13052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:13052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org3.example.com:13051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org3.example.com:13151 - CORE_PEER_LOCALMSPID=Org3MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=helloworld_hello #- CORE_LOGGING_LEVEL=ERROR - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls:/etc/hyperledger/fabric/tls ports: - 13051:13051 - 13052:13052 - 13053:13053 # extra_hosts: # - "orderer.example.com:192.168.235.100" networks: - hello cli_peer0_org3: container_name: cli_peer0_org3 image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli_peer0_org3 - CORE_PEER_ADDRESS=peer0.org3.example.com:13051 - CORE_PEER_LOCALMSPID=Org3MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/users/Admin@org3.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/helloworld/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer0.org3.example.com # extra_hosts: # - "orderer.example.com:192.168.235.100" # - "peer0.org1.example.com:192.168.235.101" # - "peer1.org1.example.com:192.168.235.102" # - "peer0.org2.example.com:192.168.235.103" # - "peer1.org2.example.com:192.168.235.104" networks: - hello ##3.2 peer1.org3.example.com的docker-compose配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: peer1.org3.example.com: container_name: peer1.org3.example.com image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer1.org3.example.com - CORE_PEER_LISTENADDRESS=0.0.0.0:13151 - CORE_PEER_ADDRESS=peer1.org3.example.com:13151 - CORE_PEER_CHAINCODEADDRESS=peer1.org3.example.com:13152 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:13152 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org3.example.com:13151 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org3.example.com:13051 - CORE_PEER_LOCALMSPID=Org3MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=helloworld_hello #- CORE_LOGGING_LEVEL=ERROR - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org3.example.com/peers/peer1.org3.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org3.example.com/peers/peer1.org3.example.com/tls:/etc/hyperledger/fabric/tls ports: - 13151:13151 - 13152:13152 - 13153:13153 networks: - hello cli_peer1_org3: container_name: cli_peer1_org3 image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli_peer1_org3 - CORE_PEER_ADDRESS=peer1.org3.example.com:13151 - CORE_PEER_LOCALMSPID=Org3MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer1.org3.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer1.org3.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer1.org3.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/users/Admin@org3.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/helloworld/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer1.org3.example.com networks: - hello ##3.3启动、添加通道并安装链码 1234567891011121314151617181920docker-compose -f docker-compose-org3-peer0.yaml up -d进入容器docker exec -it cli_peer0_org3 bashexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem获取第0个区块peer channel fetch 0 mychannel.block -o orderer.example.com:7050 -c mychannel --tls --cafile $ORDERER_CA加入到channel里边peer channel join -b mychannel.block安装链码peer chaincode install -n mycc -p github.com/hyperledger/fabric/helloworld/chaincode/go/helloworld/ -v 1.0测试查询peer chaincode query -C mychannel -n mycc -c &apos;&#123;&quot;function&quot;:&quot;get&quot;,&quot;Args&quot;:[&quot;a&quot;]&#125;&apos;测试invokepeer chaincode invoke --tls --cafile $ORDERER_CA -C mychannel -n mycc -c &apos;&#123;&quot;function&quot;:&quot;set&quot;,&quot;Args&quot;:[&quot;a&quot;,&quot;world&quot;]&#125;&apos;]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、Fabric 使用Node SDK]]></title>
    <url>%2F2019%2F12%2F07%2Fblockchain%2F2019-12-07-%E5%9B%9B%E3%80%81Fabric%20%E4%BD%BF%E7%94%A8Node%20SDK%2F</url>
    <content type="text"><![CDATA[本文基于hellowrold区块链环境，使用fabric-sdk-node 开发客户端应用。 #1.新建连接文件 connection-org1.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115---name: helloworldversion: 1.0.0client: organization: Org1 connection: timeout: peer: endorser: '300'organizations: Org1: mspid: Org1MSP peers: - peer0.org1.example.com - peer1.org1.example.com - peer2.org1.example.com certificateAuthorities: - ca.org1.example.compeers: peer0.org1.example.com: url: grpcs://localhost:7051 tlsCACerts: pem: | -----BEGIN CERTIFICATE----- MIICVzCCAf2gAwIBAgIQPpRrjZvaloVkj2FDjvjdHTAKBggqhkjOPQQDAjB2MQsw CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy YW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEfMB0GA1UEAxMWdGxz Y2Eub3JnMS5leGFtcGxlLmNvbTAeFw0xOTEyMDYwNzE4MDBaFw0yOTEyMDMwNzE4 MDBaMHYxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQH Ew1TYW4gRnJhbmNpc2NvMRkwFwYDVQQKExBvcmcxLmV4YW1wbGUuY29tMR8wHQYD VQQDExZ0bHNjYS5vcmcxLmV4YW1wbGUuY29tMFkwEwYHKoZIzj0CAQYIKoZIzj0D AQcDQgAEm6zQPRtevUHiMlaEfYaAK7Uu3yCbr7s/aoWtm6HqeSP0iKBb/VCXvV0j LDgDLb1kK6obJBl8TA4SIX94xkQ+QaNtMGswDgYDVR0PAQH/BAQDAgGmMB0GA1Ud JQQWMBQGCCsGAQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MCkGA1Ud DgQiBCCaMWO9GF+XwAh3KmV1pJ8zmzqazuahyjDqymQPY79+YTAKBggqhkjOPQQD AgNIADBFAiEAnpxtX/dFdqSZ34s6lETiMpNOg2Xus4z2X7MMHirNDvkCIHgmaZ54 B+c5lYRNqeiO9LSawwid4jfdbZvcNQ9QZQQH -----END CERTIFICATE----- grpcOptions: ssl-target-name-override: peer0.org1.example.com hostnameOverride: peer0.org1.example.com peer1.org1.example.com: url: grpcs://localhost:8051 tlsCACerts: pem: | -----BEGIN CERTIFICATE----- MIICVzCCAf2gAwIBAgIQPpRrjZvaloVkj2FDjvjdHTAKBggqhkjOPQQDAjB2MQsw CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy YW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEfMB0GA1UEAxMWdGxz Y2Eub3JnMS5leGFtcGxlLmNvbTAeFw0xOTEyMDYwNzE4MDBaFw0yOTEyMDMwNzE4 MDBaMHYxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQH Ew1TYW4gRnJhbmNpc2NvMRkwFwYDVQQKExBvcmcxLmV4YW1wbGUuY29tMR8wHQYD VQQDExZ0bHNjYS5vcmcxLmV4YW1wbGUuY29tMFkwEwYHKoZIzj0CAQYIKoZIzj0D AQcDQgAEm6zQPRtevUHiMlaEfYaAK7Uu3yCbr7s/aoWtm6HqeSP0iKBb/VCXvV0j LDgDLb1kK6obJBl8TA4SIX94xkQ+QaNtMGswDgYDVR0PAQH/BAQDAgGmMB0GA1Ud JQQWMBQGCCsGAQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MCkGA1Ud DgQiBCCaMWO9GF+XwAh3KmV1pJ8zmzqazuahyjDqymQPY79+YTAKBggqhkjOPQQD AgNIADBFAiEAnpxtX/dFdqSZ34s6lETiMpNOg2Xus4z2X7MMHirNDvkCIHgmaZ54 B+c5lYRNqeiO9LSawwid4jfdbZvcNQ9QZQQH -----END CERTIFICATE----- grpcOptions: ssl-target-name-override: peer1.org1.example.com hostnameOverride: peer1.org1.example.com peer2.org1.example.com: url: grpcs://localhost:7251 tlsCACerts: pem: | -----BEGIN CERTIFICATE----- MIICVzCCAf2gAwIBAgIQPpRrjZvaloVkj2FDjvjdHTAKBggqhkjOPQQDAjB2MQsw CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy YW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEfMB0GA1UEAxMWdGxz Y2Eub3JnMS5leGFtcGxlLmNvbTAeFw0xOTEyMDYwNzE4MDBaFw0yOTEyMDMwNzE4 MDBaMHYxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQH Ew1TYW4gRnJhbmNpc2NvMRkwFwYDVQQKExBvcmcxLmV4YW1wbGUuY29tMR8wHQYD VQQDExZ0bHNjYS5vcmcxLmV4YW1wbGUuY29tMFkwEwYHKoZIzj0CAQYIKoZIzj0D AQcDQgAEm6zQPRtevUHiMlaEfYaAK7Uu3yCbr7s/aoWtm6HqeSP0iKBb/VCXvV0j LDgDLb1kK6obJBl8TA4SIX94xkQ+QaNtMGswDgYDVR0PAQH/BAQDAgGmMB0GA1Ud JQQWMBQGCCsGAQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MCkGA1Ud DgQiBCCaMWO9GF+XwAh3KmV1pJ8zmzqazuahyjDqymQPY79+YTAKBggqhkjOPQQD AgNIADBFAiEAnpxtX/dFdqSZ34s6lETiMpNOg2Xus4z2X7MMHirNDvkCIHgmaZ54 B+c5lYRNqeiO9LSawwid4jfdbZvcNQ9QZQQH -----END CERTIFICATE----- grpcOptions: ssl-target-name-override: peer2.org1.example.com hostnameOverride: peer2.org1.example.comcertificateAuthorities: ca.org1.example.com: url: https://localhost:7054 caName: ca-org1 tlsCACerts: pem: | -----BEGIN CERTIFICATE----- MIICUjCCAfigAwIBAgIRAMU4/9+dq0VuPKEjSFipx/AwCgYIKoZIzj0EAwIwczEL MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG cmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh Lm9yZzEuZXhhbXBsZS5jb20wHhcNMTkxMjA2MDcxODAwWhcNMjkxMjAzMDcxODAw WjBzMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN U2FuIEZyYW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEcMBoGA1UE AxMTY2Eub3JnMS5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IA BHkedN9y3BKwEyYKqcWM+AkWO5/xwnmybQ+eT4US8MZWNRqPpbxj04QaIb38WLaZ EEHWpwCZ5ibI7pMBL6pQt7qjbTBrMA4GA1UdDwEB/wQEAwIBpjAdBgNVHSUEFjAU BggrBgEFBQcDAgYIKwYBBQUHAwEwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg KmZ7N0Vi4BkkiDL1YbHbv8hdIH4v1feKEDrrPbxEORswCgYIKoZIzj0EAwIDSAAw RQIhAIdEP0JbQI8LqW4XJ6fI/jmS9gqQPtGcwJxtof6pEieCAiAHxiG/VINKnQkT 18juN4fAU6fKQKbRad4/WA5wA4Z6Jw== -----END CERTIFICATE----- httpOptions: verify: false #2.nodejs 脚本 在helloworld下创建script目录，用于放js文件 ##2.1 enrollAdmin.js用于从 CA服务中获取 admin 用户注册信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* * SPDX-License-Identifier: Apache-2.0 */'use strict';const FabricCAServices = require('fabric-ca-client');const &#123; FileSystemWallet, X509WalletMixin &#125; = require('fabric-network');const fs = require('fs');const path = require('path');const ccpPath = path.resolve(__dirname, '..', '..', 'connection-org1.yaml');const ccpJSON = fs.readFileSync(ccpPath, 'utf8');const ccp = JSON.parse(ccpJSON);async function main() &#123; try &#123; // Create a new CA client for interacting with the CA. const caInfo = ccp.certificateAuthorities['ca.org1.example.com']; const caTLSCACerts = caInfo.tlsCACerts.pem; const ca = new FabricCAServices(caInfo.url, &#123; trustedRoots: caTLSCACerts, verify: false &#125;, caInfo.caName); // Create a new file system based wallet for managing identities. const walletPath = path.join(process.cwd(), 'wallet'); const wallet = new FileSystemWallet(walletPath); console.log(`Wallet path: $&#123;walletPath&#125;`); // Check to see if we've already enrolled the admin user. const adminExists = await wallet.exists('admin'); if (adminExists) &#123; console.log('An identity for the admin user "admin" already exists in the wallet'); return; &#125; // Enroll the admin user, and import the new identity into the wallet. const enrollment = await ca.enroll(&#123; enrollmentID: 'admin', enrollmentSecret: 'adminpw' &#125;); const identity = X509WalletMixin.createIdentity('Org1MSP', enrollment.certificate, enrollment.key.toBytes()); await wallet.import('admin', identity); console.log('Successfully enrolled admin user "admin" and imported it into the wallet'); &#125; catch (error) &#123; console.error(`Failed to enroll admin user "admin": $&#123;error&#125;`); process.exit(1); &#125;&#125;main(); ##2.2 registerUser.js用于注册用户user1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/* * SPDX-License-Identifier: Apache-2.0 */'use strict';const &#123; FileSystemWallet, Gateway, X509WalletMixin &#125; = require('fabric-network');const path = require('path');const ccpPath = path.resolve(__dirname, '..', '..', 'connection-org1.yaml');async function main() &#123; try &#123; // Create a new file system based wallet for managing identities. const walletPath = path.join(process.cwd(), 'wallet'); const wallet = new FileSystemWallet(walletPath); console.log(`Wallet path: $&#123;walletPath&#125;`); // Check to see if we've already enrolled the user. const userExists = await wallet.exists('user1'); if (userExists) &#123; console.log('An identity for the user "user1" already exists in the wallet'); return; &#125; // Check to see if we've already enrolled the admin user. const adminExists = await wallet.exists('admin'); if (!adminExists) &#123; console.log('An identity for the admin user "admin" does not exist in the wallet'); console.log('Run the enrollAdmin.js application before retrying'); return; &#125; // Create a new gateway for connecting to our peer node. const gateway = new Gateway(); await gateway.connect(ccpPath, &#123; wallet, identity: 'admin', discovery: &#123; enabled: true, asLocalhost: true &#125; &#125;); // Get the CA client object from the gateway for interacting with the CA. const ca = gateway.getClient().getCertificateAuthority(); const adminIdentity = gateway.getCurrentIdentity(); // Register the user, enroll the user, and import the new identity into the wallet. const secret = await ca.register(&#123; affiliation: 'org1.department1', enrollmentID: 'user1', role: 'client' &#125;, adminIdentity); const enrollment = await ca.enroll(&#123; enrollmentID: 'user1', enrollmentSecret: secret &#125;); const userIdentity = X509WalletMixin.createIdentity('Org1MSP', enrollment.certificate, enrollment.key.toBytes()); await wallet.import('user1', userIdentity); console.log('Successfully registered and enrolled admin user "user1" and imported it into the wallet'); &#125; catch (error) &#123; console.error(`Failed to register user "user1": $&#123;error&#125;`); process.exit(1); &#125;&#125;main(); ##2.3 query.js链码查询 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * SPDX-License-Identifier: Apache-2.0 */'use strict';const &#123; FileSystemWallet, Gateway &#125; = require('fabric-network');const path = require('path');const ccpPath = path.resolve(__dirname, '..', '..', 'connection-org1.yaml');async function main() &#123; try &#123; // Create a new file system based wallet for managing identities. const walletPath = path.join(process.cwd(), 'wallet'); const wallet = new FileSystemWallet(walletPath); console.log(`Wallet path: $&#123;walletPath&#125;`); // Check to see if we've already enrolled the user. const userExists = await wallet.exists('admin'); if (!userExists) &#123; console.log('An identity for the user "user1" does not exist in the wallet'); console.log('Run the registerUser.js application before retrying'); return; &#125; // Create a new gateway for connecting to our peer node. const gateway = new Gateway(); await gateway.connect(ccpPath, &#123; wallet, identity: 'admin', discovery: &#123; enabled: true, asLocalhost: true &#125; &#125;); console.log('11111') // Get the network (channel) our contract is deployed to. const network = await gateway.getNetwork('mychannel');console.log('22222') // Get the contract from the network. const contract = network.getContract('mycc');console.log('3333') // Evaluate the specified transaction. // queryCar transaction - requires 1 argument, ex: ('queryCar', 'CAR4') // queryAllCars transaction - requires no arguments, ex: ('queryAllCars') const result = await contract.evaluateTransaction('get','a'); console.log(`Transaction has been evaluated, result is: $&#123;result.toString()&#125;`); &#125; catch (error) &#123; console.error(`Failed to evaluate transaction: $&#123;error&#125;`); process.exit(1); &#125;&#125;main(); ##2.4 invoke.js执行链码方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* * SPDX-License-Identifier: Apache-2.0 */'use strict';const &#123; FileSystemWallet, Gateway &#125; = require('fabric-network');const path = require('path');const ccpPath = path.resolve(__dirname, '..', '..', 'connection-org1.yaml');async function main() &#123; try &#123; // Create a new file system based wallet for managing identities. const walletPath = path.join(process.cwd(), 'wallet'); const wallet = new FileSystemWallet(walletPath); console.log(`Wallet path: $&#123;walletPath&#125;`); // Check to see if we've already enrolled the user. const userExists = await wallet.exists('user1'); if (!userExists) &#123; console.log('An identity for the user "user1" does not exist in the wallet'); console.log('Run the registerUser.js application before retrying'); return; &#125; // Create a new gateway for connecting to our peer node. const gateway = new Gateway(); await gateway.connect(ccpPath, &#123; wallet, identity: 'user1', discovery: &#123; enabled: true, asLocalhost: true &#125; &#125;); // Get the network (channel) our contract is deployed to. const network = await gateway.getNetwork('mychannel'); // Get the contract from the network. const contract = network.getContract('mycc'); // Submit the specified transaction. // createCar transaction - requires 5 argument, ex: ('createCar', 'CAR12', 'Honda', 'Accord', 'Black', 'Tom') // changeCarOwner transaction - requires 2 args , ex: ('changeCarOwner', 'CAR10', 'Dave') await contract.submitTransaction('set', 'a', 'hello china'); console.log('Transaction has been submitted'); // Disconnect from the gateway. await gateway.disconnect(); &#125; catch (error) &#123; console.error(`Failed to submit transaction: $&#123;error&#125;`); process.exit(1); &#125;&#125;main(); ##2.5 安装Node依赖 12#进入script目录node install ##2.6执行调用链码 123456789101112#获取admin用户证书node enrollAdmin.js#注册用户user1node registerUser.js#查询链码node query.js#执行链码setnode invoke.js#查看调用set后的结果node query.js]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、Fabric 创建Helloword区块链]]></title>
    <url>%2F2019%2F12%2F07%2Fblockchain%2F2019-12-07-%E4%B8%89%E3%80%81Fabric%20%E5%88%9B%E5%BB%BAHelloworld%E5%8C%BA%E5%9D%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[以下内容记录了基于Fabric 架构，利用docker容器创建一个简单的区块链案例，并实现第一个智能合约（链码）。详细配置可以参考fabric-sample/first-network #1.环境准备安装以下环境，详细安装过程上网搜索相关资料： git nodejs npm golang docker docker-compose 配置gopath环境变量,以mac系统为例,打开~/.bash_profile 添加下面内容： 123456#go的安装路径export GOROOT=/usr/local/Cellar/go/1.13.4 #go安装包安装的路径 #hyperledger相关可运行文件，所在的目录，自己可以随意设置export GOPATH=$HOME/go #一些其他与运行hyperledger fabric运行有关的可执行文件所在的目录export PATH=$GOROOT/bin:$GOPATH/bin:$PATH #2.下载fabric资源 下载fabric 1234567# 进入文件hyperledger文件路径# /Users/zgq/go为GPATH cd /Users/zgq/go/src/github.com/hyperledgergit clone https://github.com/hyperledger/fabric.gitcd fabricgit tag #查看所有版本，点击q退出git checkout v1.14.2 #切换到tag中你想要切换到的版本 下载fabric-samples 1234567 cd cd /Users/zgq/go/src # 从git上克隆fabric-samples ,里面有fabric例子git clone https://github.com/hyperledger/fabric-samples.gitcd fabric-samplesgit tag #查看所有版本，点击q退出git checkout v1.14.2 #切换到fabric相同的版本 下载运行hyperledger fabric所需要的二进制文件 12345678# 将$GOPATH/src/github.com/hyperledger/fabric/scripts/bootstrap.sh拷贝到 fabric-samples中# 终端进入到 fabric-samples文件夹中# 修改bootstrap.sh权限chmod +x bootstrap.sh#运行bootstrap.sh./bootstrap.sh# 系统会下载一堆docker镜像、和二进制文件。 二进制文件下载有时候会因为网络问题无法下载，可以通过这个网站手动下载。 https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric/hyperledger-fabric https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric-ca/hyperledger-fabric-ca 压缩包内有 bin 和 config 两个文件夹，将 bin 和 config 文件夹复制到 fabric-samples 文件夹内。 3. 体验Fabric区块链网络你可以通过first-network来体验fabric网络。 进入fabric-samples/first-network,执行命令： 12345678#生成网络./byfn.sh generate#启动./byfn.sh up #停止./byfn.sh down 具体可参考 https://hyperledger-fabric.readthedocs.io/en/latest/build_network.html 4.创建Helloworld区块链网络4.1 架构设计本案例部署一个排序（orderer）服务，两个组织（org1，org2）和四个节点（peer）,每个组织包括两个节点, 另外每个组织一个ca（可选）。需要五台计算机（也可以在一个主机上模拟，这里在一台mac环境搭建演示）架构配置如下： orderer.example.com peer0.org1.example.com peer1.org1.example.com ca.org1.example.com peer0.org2.example.com peer1.org2.example.com ca.org2.example.com 4.2 准备12345678#命令行进入到fabric-samples目录下cd ~/go/src/fabric-samples#新建helloworld目录mkdir helloworld#拷贝脚本到helloworld下方便操作cp -r ../bin /bin 4.3 生成配置文件配置文件主要包括证书和通道生成后分别放在两个文件夹中：crypto-config、channel-artifacts 4.3.1 创建crypto-config.yaml使用fabric提供的cryptogen工具生成文件模板 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107 ./bin/cryptogen showtemplate &gt; crypto-config.yaml ``` 修改crypto-config.yaml ,添加组织,和orderer节点。 ```yaml# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## ---------------------------------------------------------------------------# &quot;OrdererOrgs&quot; - Definition of organizations managing orderer nodes# ---------------------------------------------------------------------------OrdererOrgs: # --------------------------------------------------------------------------- # Orderer # --------------------------------------------------------------------------- - Name: Orderer Domain: example.com EnableNodeOUs: true # --------------------------------------------------------------------------- # &quot;Specs&quot; - See PeerOrgs below for complete description # --------------------------------------------------------------------------- Specs: - Hostname: orderer - Hostname: orderer2 - Hostname: orderer3 - Hostname: orderer4 - Hostname: orderer5# ---------------------------------------------------------------------------# &quot;PeerOrgs&quot; - Definition of organizations managing peer nodes# ---------------------------------------------------------------------------PeerOrgs: # --------------------------------------------------------------------------- # Org1 # --------------------------------------------------------------------------- - Name: Org1 Domain: org1.example.com EnableNodeOUs: true Specs: - Hostname: peer0 - Hostname: peer1 - Hostname: peer2 - Hostname: peer3 - Hostname: peer4 # --------------------------------------------------------------------------- # &quot;Specs&quot; # --------------------------------------------------------------------------- # Uncomment this section to enable the explicit definition of hosts in your # configuration. Most users will want to use Template, below # # Specs is an array of Spec entries. Each Spec entry consists of two fields: # - Hostname: (Required) The desired hostname, sans the domain. # - CommonName: (Optional) Specifies the template or explicit override for # the CN. By default, this is the template: # # &quot;&#123;&#123;.Hostname&#125;&#125;.&#123;&#123;.Domain&#125;&#125;&quot; # # which obtains its values from the Spec.Hostname and # Org.Domain, respectively. # --------------------------------------------------------------------------- # Specs: # - Hostname: foo # implicitly &quot;foo.org1.example.com&quot; # CommonName: foo27.org5.example.com # overrides Hostname-based FQDN set above # - Hostname: bar # - Hostname: baz # --------------------------------------------------------------------------- # &quot;Template&quot; # --------------------------------------------------------------------------- # Allows for the definition of 1 or more hosts that are created sequentially # from a template. By default, this looks like &quot;peer%d&quot; from 0 to Count-1. # You may override the number of nodes (Count), the starting index (Start) # or the template used to construct the name (Hostname). # # Note: Template and Specs are not mutually exclusive. You may define both # sections and the aggregate nodes will be created for you. Take care with # name collisions # --------------------------------------------------------------------------- Template: Count: 2 # Start: 5 # Hostname: &#123;&#123;.Prefix&#125;&#125;&#123;&#123;.Index&#125;&#125; # default # --------------------------------------------------------------------------- # &quot;Users&quot; # --------------------------------------------------------------------------- # Count: The number of user accounts _in addition_ to Admin # --------------------------------------------------------------------------- Users: Count: 1 # --------------------------------------------------------------------------- # Org2: See &quot;Org1&quot; for full specification # --------------------------------------------------------------------------- - Name: Org2 Domain: org2.example.com EnableNodeOUs: true Specs: - Hostname: peer0 - Hostname: peer1 - Hostname: peer2 - Hostname: peer3 - Hostname: peer4 Template: Count: 2 Users: Count: 1 4.3.2 生成证书文件cryptogen generate –config=./crypto-config.yaml 4.3.3 生成创世区块首先要确保channel-artifacts文件夹存在，如果不存在需要手动创建，不然会报错。 1configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block 4.3.4 生成通道配置文件其中通道名mychannel可以修改为自己的名称 1configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/mychannel.tx -channelID mychannel 4.3.5 生成锚节点配置文件Org11configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP Org21configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP 所有需要的配置文件全部建立完成，在channel-artifacts中应该有以下几个文件。my channel.tx、genesis.block、Org1MSPanchors.tx、Org2MSPanchors.tx 4.4 配置docker-compose文件相关配置内容可参考first-network中的配置 docker-compose-orderer.yaml12345678910111213141516171819202122232425262728293031323334353637383940# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: orderer.example.com: container_name: orderer.example.com image: hyperledger/fabric-orderer environment: - ORDERER_GENERAL_LOGLEVEL=debug - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp # enabled TLS - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] - ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s - ORDERER_KAFKA_RETRY_SHORTTOTAL=30s - ORDERER_KAFKA_VERBOSE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp - ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/:/var/hyperledger/orderer/tls ports: - 7050:7050 networks: - hello docker-compose-org1-peer0.yaml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: peer0.org1.example.com: container_name: peer0.org1.example.com image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer0.org1.example.com - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:8051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=helloworld_hello #- CORE_LOGGING_LEVEL=ERROR - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls ports: - 7051:7051 - 7052:7052 - 7053:7053 # extra_hosts: # - "orderer.example.com:192.168.235.100" networks: - hello cli_peer0_org1: container_name: cli_peer0_org1 image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli_peer0_org1 - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/helloworld/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer0.org1.example.com # extra_hosts: # - "orderer.example.com:192.168.235.100" # - "peer0.org1.example.com:192.168.235.101" # - "peer1.org1.example.com:192.168.235.102" # - "peer0.org2.example.com:192.168.235.103" # - "peer1.org2.example.com:192.168.235.104" networks: - hello docker-compose-org1-peer1.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: peer1.org1.example.com: container_name: peer1.org1.example.com image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer1.org1.example.com - CORE_PEER_LISTENADDRESS=0.0.0.0:8051 - CORE_PEER_ADDRESS=peer1.org1.example.com:8051 - CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:8052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:8051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=helloworld_hello #- CORE_LOGGING_LEVEL=ERROR - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls ports: - 8051:8051 - 8052:8052 - 8053:8053 # extra_hosts: # - "orderer.example.com:192.168.235.100" networks: - hello cli_peer1_org1: container_name: cli_peer1_org1 image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli_peer1_org1 - CORE_PEER_ADDRESS=peer1.org1.example.com:8051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/helloworld/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer1.org1.example.com # extra_hosts: # - "orderer.example.com:192.168.235.100" # - "peer1.org1.example.com:192.168.235.101" # - "peer1.org1.example.com:192.168.235.102" # - "peer1.org2.example.com:192.168.235.103" # - "peer1.org2.example.com:192.168.235.104" networks: - hello docker-compose-org2-peer0.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: peer0.org2.example.com: container_name: peer0.org2.example.com image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer0.org2.example.com - CORE_PEER_LISTENADDRESS=0.0.0.0:9051 - CORE_PEER_ADDRESS=peer0.org2.example.com:9051 - CORE_PEER_CHAINCODEADDRESS=peer0.org2.example.com:9052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:9052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org2.example.com:9051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org2.example.com:10051 - CORE_PEER_LOCALMSPID=Org2MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=helloworld_hello #- CORE_LOGGING_LEVEL=ERROR - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls:/etc/hyperledger/fabric/tls ports: - 9051:9051 - 9052:9052 - 9053:9053 # extra_hosts: # - "orderer.example.com:192.168.235.100" networks: - hello cli_peer0_org2: container_name: cli_peer0_org2 image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli_peer0_org2 - CORE_PEER_ADDRESS=peer0.org2.example.com:9051 - CORE_PEER_LOCALMSPID=Org2MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/helloworld/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer0.org2.example.com # extra_hosts: # - "orderer.example.com:192.168.235.100" # - "peer0.org1.example.com:192.168.235.101" # - "peer1.org1.example.com:192.168.235.102" # - "peer0.org2.example.com:192.168.235.103" # - "peer1.org2.example.com:192.168.235.104" networks: - hello docker-compose-org2-peer1.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: peer1.org2.example.com: container_name: peer1.org2.example.com image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer1.org2.example.com - CORE_PEER_LISTENADDRESS=0.0.0.0:10051 - CORE_PEER_ADDRESS=peer1.org2.example.com:10051 - CORE_PEER_CHAINCODEADDRESS=peer1.org2.example.com:10052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:10052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org2.example.com:10051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org2.example.com:9051 - CORE_PEER_LOCALMSPID=Org2MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=helloworld_hello #- CORE_LOGGING_LEVEL=ERROR - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls:/etc/hyperledger/fabric/tls ports: - 10051:10051 - 10052:10052 - 10053:10053 # extra_hosts: # - "orderer.example.com:192.168.235.100" networks: - hello cli_peer1_org2: container_name: cli_peer1_org2 image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli_peer1_org2 - CORE_PEER_ADDRESS=peer1.org2.example.com:10051 - CORE_PEER_LOCALMSPID=Org2MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/helloworld/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer1.org2.example.com # extra_hosts: # - "orderer.example.com:192.168.235.100" # - "peer0.org1.example.com:192.168.235.101" # - "peer1.org1.example.com:192.168.235.102" # - "peer0.org2.example.com:192.168.235.103" # - "peer1.org2.example.com:192.168.235.104" networks: - hello 两个CA服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: ca0: image: hyperledger/fabric-ca environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca-org1 - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY1&#125; - FABRIC_CA_SERVER_PORT=7054 ports: - "7054:7054" command: sh -c 'fabric-ca-server start --ca.certfile /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem --ca.keyfile /etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY1&#125; -b admin:adminpw -d' volumes: - ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config - ./client/ca:/root/ca container_name: ca_peerOrg1 networks: - hello ca1: image: hyperledger/fabric-ca environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca-org2 - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org2.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY2&#125; - FABRIC_CA_SERVER_PORT=9054 ports: - "9054:9054" command: sh -c 'fabric-ca-server start --ca.certfile /etc/hyperledger/fabric-ca-server-config/ca.org2.example.com-cert.pem --ca.keyfile /etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY2&#125; -b admin:adminpw -d' volumes: - ./crypto-config/peerOrganizations/org2.example.com/ca/:/etc/hyperledger/fabric-ca-server-config - ./client/ca:/root/ca container_name: ca_peerOrg2 networks: - hello ##4.5 启动docker执行以下命令启动区块链各个模块。 12345docker-compose -f docker-compose-orderer.yaml up -ddocker-compose -f docker-compose-org1-peer0.yaml up -ddocker-compose -f docker-compose-org1-peer1.yaml up -ddocker-compose -f docker-compose-org2-peer0.yaml up -ddocker-compose -f docker-compose-org2-peer1.yaml up -d 两个org的ca服务docker参数配置中分别有：${PRIVATE_KEY1}和${PRIVATE_KEY2}两个变量，具体路径在：crypto-config/peerOrganizations/org1.example.com/ca/ 下后缀是”_sk”的文件，我们这里写了一个shell脚步用于配置${PRIVATE_KEY1}和${PRIVATE_KEY2}，并启动ca节点。脚步./startCA.sh文件如下： 123456789101112131415161718192021222324252627282930313233COMPOSE_FILE=&quot;docker-compose-ca.yaml&quot;###########key1folder1=&quot;crypto-config/peerOrganizations/org1.example.com/ca&quot;privName1=&quot;&quot;for file_a in $&#123;folder1&#125;/*do temp_file=`basename $file_a` if [ $&#123;temp_file##*.&#125; != &quot;pem&quot; ];then privName1=$temp_file fidoneecho $privName1#############key2folder2=&quot;crypto-config/peerOrganizations/org2.example.com/ca&quot;privName2=&quot;&quot;for file_a in $&#123;folder2&#125;/*do temp_file=`basename $file_a` if [ $&#123;temp_file##*.&#125; != &quot;pem&quot; ];then privName2=$temp_file fidoneecho $privName2CHANNEL_NAME=$CH_NAME TIMEOUT=$CLI_TIMEOUT PRIVATE_KEY1=$privName1 PRIVATE_KEY2=$privName2 docker-compose -f $COMPOSE_FILE up -d 2&gt;&amp;1 启动CA节点 12./startCA.sh docker启动后如下所示： #5.创建通道并加入通道 节点：peer0.org1.example.com 123456789101112#1进入peer0 的客户端docker exec -it cli_peer0_org1 bash#2设置ca路径ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#3创建通道mychannelpeer channel create -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/mychannel.tx --tls --cafile $ORDERER_CA#4节点加入通道mychannelpeer channel join -b mychannel.block#5拷贝mychannel.block到宿主机 节点：peer1.org1.example.com 123456789101112#1拷贝宿主机上的mychannel.block到docker cli_peer1_org1#2进入peer0 的客户端docker exec -it cli_peer1_org1 bash#3设置ca路径ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem #4节点加入通道mychannelpeer channel join -b mychannel.block 其他节点与peer1.org1.example.com类似 #6.链码开发与安装 ##6.1 链码开发在helloworld目录下创建 chaincode/go/helloworld文件夹。 目录fabric-samples/helloworld/chaincode/go/helloworld 我们使用go开发一个包含get和一个set功能的简单的链码，代码如下： chaincode.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/* * * 文件名称 : chaincode.go * 创建者 : zgq * 创建日期: 2019/11/24 * 文件描述: 实现存储Helloworld字符串的智能合约 * 历史记录: 无 */package mainimport ( &quot;fmt&quot; &quot;github.com/hyperledger/fabric/core/chaincode/shim&quot; pb &quot;github.com/hyperledger/fabric/protos/peer&quot;)// SimpleChaincode implements a simple chaincode to manage an assettype SimpleChaincode struct &#123;&#125;// 链码实例化时，调用Init函数初始化数据// 链码升级时，也会调用此函数重置或迁移数据func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response &#123; // 获取交易提案中的参数 args := stub.GetStringArgs() if len(args) != 2 &#123; return shim.Error(&quot;Incorrect arguments. Expecting a key and a value&quot;) &#125; // 通过调用stub.PutState()设置变量和数值 // 在账本上设置key和value err := stub.PutState(args[0], []byte(args[1])) if err != nil &#123; return shim.Error(fmt.Sprintf(&quot;Failed to create asset: %s&quot;, args[0])) &#125; return shim.Success(nil)&#125;// 调用Invoke函数进行资产交易// 每笔交易通过get或set操作Init函数创建的key和value// 通过set可以创建新的key和valuefunc (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response &#123; // 获取交易提案中的函数和参数 fn, args := stub.GetFunctionAndParameters() var result string var err error if fn == &quot;set&quot; &#123; result, err = set(stub, args) &#125; else &#123; // assume &apos;get&apos; even if fn is nil result, err = get(stub, args) &#125; if err != nil &#123; return shim.Error(err.Error()) &#125; // Return the result as success payload return shim.Success([]byte(result))&#125;// 保存key和value到账本上// 如果key存在，覆盖原有的valuefunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) &#123; if len(args) != 2 &#123; return &quot;&quot;, fmt.Errorf(&quot;Incorrect arguments. Expecting a key and a value&quot;) &#125; err := stub.PutState(args[0], []byte(args[1])) if err != nil &#123; return &quot;&quot;, fmt.Errorf(&quot;Failed to set asset: %s&quot;, args[0]) &#125; return args[1], nil&#125;// 获取key对应的valuefunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) &#123; if len(args) != 1 &#123; return &quot;&quot;, fmt.Errorf(&quot;Incorrect arguments. Expecting a key&quot;) &#125; value, err := stub.GetState(args[0]) if err != nil &#123; return &quot;&quot;, fmt.Errorf(&quot;Failed to get asset: %s with error: %s&quot;, args[0], err) &#125; if value == nil &#123; return &quot;&quot;, fmt.Errorf(&quot;Asset not found: %s&quot;, args[0]) &#125; return string(value), nil&#125; *helloworld.go 1234567891011121314151617181920212223/* * * 文件名称 : main.go * 创建者 : zgq * 创建日期: 2019/11/24 * 文件描述: 主入口函数 * 历史记录: 无 */package mainimport ( &quot;fmt&quot; &quot;github.com/hyperledger/fabric/core/chaincode/shim&quot;)func main() &#123; err := shim.Start(new(SimpleChaincode)) if err != nil &#123; fmt.Printf(&quot;Error starting Simple chaincode: %s&quot;, err) &#125;&#125; ##6.2 安装链码 ###在peer0.org1.example.com 安装链码 1234567891011121314#进入cli_peer0_org1 docker环境docker exec -it cli_peer0_org1 bash#orderer证书ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#安装链码peer chaincode install -n mycc -p github.com/hyperledger/fabric/helloworld/chaincode/go/helloworld/ -v 1.0#查看已经安装的链码peer chaincode list --installed#实例化链码,初始化 a=hellopeer chaincode instantiate -o orderer.example.com:7050 --tls --cafile $ORDERER_CA -C mychannel -n mycc -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;a&quot;,&quot;hello&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;)&quot; 查询 1peer chaincode query -C mychannel -n mycc -c &apos;&#123;&quot;function&quot;:&quot;get&quot;,&quot;Args&quot;:[&quot;a&quot;]&#125;&apos; 执行set 1peer chaincode invoke --tls --cafile $ORDERER_CA -C mychannel -n mycc -c &apos;&#123;&quot;function&quot;:&quot;set&quot;,&quot;Args&quot;:[&quot;a&quot;,&quot;world&quot;]&#125;&apos; ###在peer1.org1.example.com 安装链码 1234567891011#进入cli_peer1_org1 docker环境docker exec -it cli_peer1_org1 bash#orderer证书ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#安装链码peer chaincode install -n mycc -p github.com/hyperledger/fabric/helloworld/chaincode/go/helloworld/ -v 1.0#安装完后查询就可以发现数据已经有了peer chaincode query -C mychannel -n mycc -c &apos;&#123;&quot;function&quot;:&quot;get&quot;,&quot;Args&quot;:[&quot;a&quot;]&#125;&apos; ###在其他节点安装链码与peer1.org1.example.com 安装链码过程类似。 通过docker ps命令我们会发现多出来几个链码服务，例如：dev-peer0.org1.example.com-mycc-1.0-388fcb871dc37045ac29faaba82745e39035f4243bf46d1c97df818b4b341bbedev-peer1.org1.example.com-mycc-1.0-cd123150154e6bf2df7ce682e0b1bcbea40499416f37a6da3aae14c4eb51b08ddev-peer0.org2.example.com-mycc-1.0-15b571b3ce849066b7ec74497da3b27e54e0df1345daff3951b94245ce09c42bdev-peer1.org2.example.com-mycc-1.0-26c2ef32838554aac4f7ad6f100aca865e87959c9a126e86d764c8d01f8346ab]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、Fabric 动态添加节点]]></title>
    <url>%2F2019%2F12%2F07%2Fblockchain%2F2019-12-07-%E4%BA%94%E3%80%81Fabric%20%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[本文基于hellowrold区块链环境，为org1动态添加节点peer2。 #1. 修改crypto-config.yaml 文件添加peer2 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## ---------------------------------------------------------------------------# "OrdererOrgs" - Definition of organizations managing orderer nodes# ---------------------------------------------------------------------------OrdererOrgs: # --------------------------------------------------------------------------- # Orderer # --------------------------------------------------------------------------- - Name: Orderer Domain: example.com EnableNodeOUs: true # --------------------------------------------------------------------------- # "Specs" - See PeerOrgs below for complete description # --------------------------------------------------------------------------- Specs: - Hostname: orderer - Hostname: orderer2 - Hostname: orderer3 - Hostname: orderer4 - Hostname: orderer5# ---------------------------------------------------------------------------# "PeerOrgs" - Definition of organizations managing peer nodes# ---------------------------------------------------------------------------PeerOrgs: # --------------------------------------------------------------------------- # Org1 # --------------------------------------------------------------------------- - Name: Org1 Domain: org1.example.com EnableNodeOUs: true Specs: - Hostname: peer0 - Hostname: peer1 - Hostname: peer2 #增加节点 # --------------------------------------------------------------------------- # "Specs" # --------------------------------------------------------------------------- # Uncomment this section to enable the explicit definition of hosts in your # configuration. Most users will want to use Template, below # # Specs is an array of Spec entries. Each Spec entry consists of two fields: # - Hostname: (Required) The desired hostname, sans the domain. # - CommonName: (Optional) Specifies the template or explicit override for # the CN. By default, this is the template: # # "&#123;&#123;.Hostname&#125;&#125;.&#123;&#123;.Domain&#125;&#125;" # # which obtains its values from the Spec.Hostname and # Org.Domain, respectively. # --------------------------------------------------------------------------- # Specs: # - Hostname: foo # implicitly "foo.org1.example.com" # CommonName: foo27.org5.example.com # overrides Hostname-based FQDN set above # - Hostname: bar # - Hostname: baz # --------------------------------------------------------------------------- # "Template" # --------------------------------------------------------------------------- # Allows for the definition of 1 or more hosts that are created sequentially # from a template. By default, this looks like "peer%d" from 0 to Count-1. # You may override the number of nodes (Count), the starting index (Start) # or the template used to construct the name (Hostname). # # Note: Template and Specs are not mutually exclusive. You may define both # sections and the aggregate nodes will be created for you. Take care with # name collisions # --------------------------------------------------------------------------- Template: Count: 3 #增加节点 # Start: 5 # Hostname: &#123;&#123;.Prefix&#125;&#125;&#123;&#123;.Index&#125;&#125; # default # --------------------------------------------------------------------------- # "Users" # --------------------------------------------------------------------------- # Count: The number of user accounts _in addition_ to Admin # --------------------------------------------------------------------------- Users: Count: 1 # --------------------------------------------------------------------------- # Org2: See "Org1" for full specification # --------------------------------------------------------------------------- - Name: Org2 Domain: org2.example.com EnableNodeOUs: true Specs: - Hostname: peer0 - Hostname: peer1 Template: Count: 2 Users: Count: 1 #2. 生成peer2的密钥执行./bin/cryptogen extend –config=./crypto-config.yaml 生成peer2的密钥 #3. 添加peer2的docker-compose 配置文件docker-compose-org1-peer3.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: peer2.org1.example.com: container_name: peer2.org1.example.com image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer2.org1.example.com - CORE_PEER_LISTENADDRESS=0.0.0.0:7251 - CORE_PEER_ADDRESS=peer2.org1.example.com:7251 - CORE_PEER_CHAINCODEADDRESS=peer2.org1.example.com:7252 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7252 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7251 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=helloworld_hello #- CORE_LOGGING_LEVEL=ERROR - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer2.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer2.org1.example.com/tls:/etc/hyperledger/fabric/tls ports: - 7251:7251 - 7252:7252 - 7253:7253 networks: - hello cli_peer2_org1: container_name: cli_peer2_org1 image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli_peer2_org1 - CORE_PEER_ADDRESS=peer2.org1.example.com:7251 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer2.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer2.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer2.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/helloworld/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: - peer2.org1.example.com networks: - hello 启动节点 1docker-compose -f docker-compose-org1-peer2.yaml up -d 配置新节点的通道和链码 12345678910#进入cli 执行docker exec -it cli_peer2_org1 bash#CA 路径配置 ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#添加到channel peer channel join -b mychannel.block#安装链码peer chaincode install -n mycc -p github.com/hyperledger/fabric/helloworld/chaincode/go/helloworld/ -v 1.0#查询链码peer chaincode query -C mychannel -n mycc -c &apos;&#123;&quot;function&quot;:&quot;get&quot;,&quot;Args&quot;:[&quot;a&quot;]&#125;&apos;]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、Fabric CA环境集成与应用]]></title>
    <url>%2F2019%2F12%2F07%2Fblockchain%2F2019-12-07-%E4%B8%83%E3%80%81Fabric%20CA%E7%8E%AF%E5%A2%83%E9%9B%86%E6%88%90%E4%B8%8E%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[本文基于hellowrold区块链环境，添加CA服务，并使用chaincode测试。 在helloworld案例中是由cryptogen这个工具根据crypto-config.yaml而生成用户信息。但是在实际生产环境中，我们应该为每个Org建立一个CA，由CA来管理其中的用户。 #1.新建docker-compose文件，增加CA容器docker-compose-ca.yaml内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: '2'networks: hello:services: ca0: image: hyperledger/fabric-ca environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca-org1 - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY1&#125; - FABRIC_CA_SERVER_PORT=7054 ports: - "7054:7054" command: sh -c 'fabric-ca-server start --ca.certfile /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem --ca.keyfile /etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY1&#125; -b admin:adminpw -d' volumes: - ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config - ./client/ca:/root/ca container_name: ca_peerOrg1 networks: - hello ca1: image: hyperledger/fabric-ca environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca-org2 - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org2.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY2&#125; - FABRIC_CA_SERVER_PORT=9054 ports: - "9054:9054" command: sh -c 'fabric-ca-server start --ca.certfile /etc/hyperledger/fabric-ca-server-config/ca.org2.example.com-cert.pem --ca.keyfile /etc/hyperledger/fabric-ca-server-config/$&#123;PRIVATE_KEY2&#125; -b admin:adminpw -d' volumes: - ./crypto-config/peerOrganizations/org2.example.com/ca/:/etc/hyperledger/fabric-ca-server-config - ./client/ca:/root/ca container_name: ca_peerOrg2 networks: - hello Fabric CA Server启动的时候，带了3个重要的参数： （1）ca.certfile ：指定了CA的根证书。 （2）ca.keyfile ：指定了接下来给新用户签发证书时的私钥，这里我们使用变量${PRIVATE_KEY}代替，这是因为每次network_setup的时候，私钥的名字是不一样的，所以需要从启动脚本中传入。 （3）-b参数：指定了CA Client连接CA Server时使用的用户名密码。 2.添加startCA.sh启动脚本，将CA容器启动的参数带入我们需要新增加一个startCA.sh文件，因为前面我们使用了变量${PRIVATE_KEY1}和${PRIVATE_KEY2}，所以这里我们需要读取变量并带入docker-compose-ca.yaml 启动的时候。具体脚本如下： 123456789101112131415161718192021222324252627282930313233COMPOSE_FILE=&quot;docker-compose-ca.yaml&quot;###########key1folder1=&quot;crypto-config/peerOrganizations/org1.example.com/ca&quot;privName1=&quot;&quot;for file_a in $&#123;folder1&#125;/*do temp_file=`basename $file_a` if [ $&#123;temp_file##*.&#125; != &quot;pem&quot; ];then privName1=$temp_file fidoneecho $privName1#############key2folder2=&quot;crypto-config/peerOrganizations/org2.example.com/ca&quot;privName2=&quot;&quot;for file_a in $&#123;folder2&#125;/*do temp_file=`basename $file_a` if [ $&#123;temp_file##*.&#125; != &quot;pem&quot; ];then privName2=$temp_file fidoneecho $privName2CHANNEL_NAME=$CH_NAME TIMEOUT=$CLI_TIMEOUT PRIVATE_KEY1=$privName1 PRIVATE_KEY2=$privName2 docker-compose -f $COMPOSE_FILE up -d 2&gt;&amp;1 这里脚本的逻辑是去crypto-config/peerOrganizations/org1.example.com/ca这个文件夹中去遍历文件，找到后缀_sk的私钥文件的文件名，并把文件名赋值给privName，然后在docker-compse-ca的启动时，指定到PRIVATE_KEY。 #3.使用CA Client生成新用户通过前面2步，我们给Org1、Org2设置的CA Server。接下来我们需要安装ca client，用于访问和操作CA。 ##3.1启动Fabric网络运行./startCA.sh ##3.2下载并安装Fabric CA Client 然后执行以下命令安装Fabric CA Client： 1go get -u github.com/hyperledger/fabric-ca/cmd/... 该命令执行完毕后，我们应该在~/go/bin下面看到生成的2个文件： fabric-ca-client fabric-ca-server ##3.3注册认证管理员首先需要以管理员身份使用CA Client连接到Org1的 CA Server，并生成相应的文件。 12export FABRIC_CA_CLIENT_HOME=/Users/zgq/cafabric-ca-client enroll -u http://admin:adminpw@localhost:7054 这个时候我们可以去$HOME/ca目录，看到CA Client创建了一个fabric-ca-client-config.yaml文件和一个msp文件夹。config可以去修改一些组织信息之类的。 3.4注册新用户接着新建一个叫zgq的用户，那么需要先执行这个命令：fabric-ca-client register –id.name zgq –id.type user –id.affiliation org1.department1 –id.attrs ‘hf.Revoker=true,foo=bar’系统会返回一个该用户的密码： User provided config file: /Users/zgq/ca/fabric-ca-client-config.yamlConfiguration file location: /Users/zgq/ca/fabric-ca-client-config.yaml Password: GOuMzkcGgGzq拿到这个密码后就可以再次使用enroll命令，给zgq这个用户生成msp的私钥和证书： fabric-ca-client enroll -u http://zgq:GOuMzkcGgGzq@localhost:7054 -M $FABRIC_CA_CLIENT_HOME/zgq现在新用户devin的私钥和证书就在$HOME/ca/devinmsp目录下，我们可以使用tree命令查看一下： 12345678zgq/ ├── cacerts │ └── localhost-7054.pem ├── keystore │ └── a044e43ad1fd7cdfd1fd995abaef53895534bd70e8cdfdb665430d12665f2041_sk └── signcerts └── cert.pem 4.编写ChainCode验证CA用户4.1 编写链码当前用户的信息的获取主要是用到ChainCode接口提供的GetCreator方法，具体的ChainCode如下： sampleChaincode.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport ( &quot;github.com/hyperledger/fabric/core/chaincode/shim&quot; pb &quot;github.com/hyperledger/fabric/protos/peer&quot; &quot;fmt&quot; &quot;encoding/pem&quot; &quot;crypto/x509&quot; &quot;bytes&quot;)type SimpleChaincode struct &#123;&#125;func main() &#123; err := shim.Start(new(SimpleChaincode)) if err != nil &#123; fmt.Printf(&quot;Error starting Simple chaincode: %s&quot;, err) &#125;&#125;func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response &#123; return shim.Success(nil)&#125;func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response &#123; function, args := stub.GetFunctionAndParameters() fmt.Println(&quot;invoke is running &quot; + function) if function == &quot;cert&quot; &#123;//自定义函数名称 return t.testCertificate(stub, args)//定义调用的函数 &#125; return shim.Error(&quot;Received unknown function invocation&quot;)&#125;func (t *SimpleChaincode) testCertificate(stub shim.ChaincodeStubInterface, args []string) pb.Response&#123; creatorByte,_:= stub.GetCreator() certStart := bytes.IndexAny(creatorByte, &quot;-----&quot;)// Devin:I don&apos;t know why sometimes -----BEGIN is invalid, so I use ----- if certStart == -1 &#123; fmt.Errorf(&quot;No certificate found&quot;) &#125; certText := creatorByte[certStart:] bl, _ := pem.Decode(certText) if bl == nil &#123; fmt.Errorf(&quot;Could not decode the PEM structure&quot;) &#125; fmt.Println(string(certText)) cert, err := x509.ParseCertificate(bl.Bytes) if err != nil &#123; fmt.Errorf(&quot;ParseCertificate failed&quot;) &#125; fmt.Println(cert) uname:=cert.Subject.CommonName fmt.Println(&quot;Name:&quot;+uname) return shim.Success([]byte(&quot;Called testCertificate &quot;+uname))&#125; ##4.2 安装链码比验证CA 12345678910#进入peer 客户端docker exec -it cli_peer0_org1 bash#安装peer chaincode install -n sicc -p github.com/hyperledger/fabric/helloworld/chaincode/go/simplecc/ -v 1.0ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#实例化peer chaincode instantiate -o orderer.example.com:7050 --tls --cafile $ORDERER_CA -C mychannel -n sicc -v 1.0 -c &apos;&#123;&quot;Args&quot;:[]&#125;&apos; -P &quot;OR (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;)&quot;#验证CA用户信息peer chaincode query -C mychannel -n sicc -c &apos;&#123;&quot;Args&quot;:[&quot;cert&quot;]&#125;&apos; 系统返回结果，说明我们当前的用户是Admin@org1.example.com 5.验证新用户设置新用户的证书和私钥文件夹，验证新用户的可用性。我们已经给org1设置的CA，用户zgq是在org1下，所以需要把/Users/zgq/ca/zgq下面的文件转移到org1下面。org1的用户证书和私钥文件夹在： 1234567891011121314~/go/src/fabric-examples/helloworld/crypto-config/peerOrganizations/org1.example.com/users#新建文件夹zgq用于保存新用户的证书和私钥，新建命令行窗口，保留前面已经登录的cli_peer0_org1窗口，接下来还会用于验证CA用户。cd ~/go/src/fabric-examples/helloworld/crypto-config/peerOrganizations/org1.example.com/usersmkdir zgqcp ~/ca/zgq/ zgq/msp –R#从signcerts这个文件夹中拷贝一个.pem到admincerts目录，运行以下命令：mkdir zgq/msp/admincertscp zgq/msp/signcerts/cert.pem zgq/msp/admincerts/ 新用户的所有证书准备完毕，tree zgq看看结果： 123456789101112tree zgqzgq/ └── msp ├── admincerts │ └── cert.pem ├── cacerts │ └── localhost-7054.pem ├── keystore │ └── a044e43ad1fd7cdfd1fd995abaef53895534bd70e8cdfdb665430d12665f2041_sk └── signcerts └── cert.pem 切换到cli_peer0_org1窗口，我们把当前用户msp文件夹切换成zgq的文件夹，具体命令是： 12CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/devin/msp 接着再运行一下ChainCode： 1peer chaincode query -C mychannel -n test1 -c &apos;&#123;&quot;Args&quot;:[&quot;cert&quot;]&#125;&apos; 可以看到结果已经变化了，用户已经由Admin变成了zgq。 关于CA其他内容可参考官方文档：http://hyperledger-fabric-ca.readthedocs.io/en/latest/]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、Fabric 简介]]></title>
    <url>%2F2019%2F12%2F07%2Fblockchain%2F2019-12-07-%E4%B8%80%E3%80%81Fabric%20%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[#Fabric简介 Linux基金会2015年成立了超级账本项目（Hyperledger）来推动跨行业区块链技术。并非声明一个单一的区块链标准，它鼓励通过社区来合作开发区块链技术，鼓励开源知识产权，采用随时间演进的关键标准。 Hyperledger Fabric是Hyperledger区块链项目中的一员。像其他区块链技术一样，它有一个账本，使用智能合约，是一个由参与者共同管理他们的交易的系统。 Hyperledger Fabric和其他区块链系统不同之处在于它是私有的和有准入资格授权的。并非一个公开的无授权的允许不明身份参与者进入网络（需要工作量证明之类的协议认证交易和保证网络安全）的系统，Hyperledger Fabric的成员要在会员服务提供商（MSP）注册。 Hyperledger Fabric也提供一些可插拔的选项。账本数据能够以多种格式存储，一致性机制可以引入也可以退出，并且支持不同的多个MSP。 Hyperledger Fabric还提供创建通道(channel)的能力,允许一组参与者建立一个单独的交易账本。这对于参与者可能是竞争对手的网络是一个特别重要的选项，比如参与者之间针对不同交易对象设定不同价格，他们就不希望每一别交易被每一个参与者知道。在一个通道里的两个参与者，有这个通道账本的全部副本，通道之外的其他人没有。（可以把一个通道理解为一个隔离的账本） ##共享账本 Hyperledger Fabric有一个账本子系统包含两个组件：世界状态和交易日志。每一个参与者有一份他们参与的每个Hyperledger Fabric网络的账本的副本。 世界状态组件描述了一个给点时间点的账本状态。它是账本的数据库。交易日志组件记录所有导致世界状态当前值的交易。它是世界状态的更新历史。这样，账本就是世界状态数据库和交易日志历史的组合体。 账本有可替换的世界状态数据库。默认是LevelDB键值存储数据库。交易日志不需要是可插拔的。它只是简单的记录账本数据库被区块链网络使用之前和之后的值。 ##智能合约 Hyperledger Fabric智能合约写在链码（chaincode）里并在区块链外部应用程序要和账本发生交易的时候被外部应用程序调用。在大多数情况下，链码只和账本的数据库组件（世界状态）交互，而不和交易日志交互。 链码可以用多种编程语言实现。目前支持的链码编写语言包括Go、Java、Python等，未来还会支持更多。 ##隐私 出于对网络的需要，B2B网络的参与者可能对于他们分享的信息范围极端敏感。对于其他网络而言，隐私不会成为首要问题。 Hyperledger Fabric支持把隐私（使用通道）作为关键操作要求的同时又比较开放的网络 ##共识 网络中不通参与者之间的交易必须按照发生的顺序被写进账本里。为了实现这一点，必须建立交易顺序，并且设置一个拒绝由于误操作或者（恶意）插入账本的错误（恶意）交易的方法。这是一个经过深入研究的计算机科学领域，有很多方法可以实现它，每种都有不同的权衡。比如PBFT（实践拜占庭容错）可以为文件副本提供通过与其他节点沟通来保持一致性的一种机制，即使发生腐败的情况。另外，在比特币里，排序通过一个称为挖矿的由计算机竞赛解一道加密难题的流程来保证。Hyperledger Fabric设计为允许网络在初始时选择一种能够最好地代表现存参与者之间关系的共识机制。与隐私一样，还有一系列的要求；从高度结构化的网络到更加对等的网络。 联盟链要求 准入机制 高吞吐量 低延迟 交易保证隐私与机密 高可扩展Fabric 特点 高度模块化的设计，使得Fabric平台可以适用于各行各业：供应链、银行、金融、保险、医疗、人力资源、社会保障等。 支持通用编程语言编写智能合约：Java，Go，javascript 网络要求是permissioned 共识协议可插拔，可以适用不同的环境 没有token，减少被攻击的风险，不需要挖矿可以降低成本]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ca-server和ca-client的TLS连接配置]]></title>
    <url>%2F2019%2F11%2F28%2Fblockchain%2F2019-11-28-ca-server%E5%92%8Cca-client%E7%9A%84TLS%E8%BF%9E%E6%8E%A5%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[如何配置fabric-ca-server和fabric-ca-client之间的TLS连接。 配置fabric-ca-server端fabric-ca-server-config.yaml文件里面配置TLS。 1234567891011121314151617181920############################################################################## TLS section for the server's listening port## The following types are supported for client authentication: NoClientCert,# RequestClientCert, RequireAnyClientCert, VerfiyClientCertIfGiven,# and RequireAndVerifyClientCert.## Certfiles is a list of root certificate authorities that the server uses# when verifying client certificates.#############################################################################tls: # Enable TLS (default: false) enabled: false # TLS for the server's listening port certfile: ca-cert.pem keyfile: ca-key.pem clientauth: type: noclientcert certfiles: enabled: true必须配置成true 配置certfile/keyfile；就这个地方，这份证书必须从别的CA签出来。 clientauth如果选择noclientcert，表示server不验证client，也就是通常所说的单向验证，即client端验证server端，而server端不验证client的；其他选项是双向验证，即server端和client端相互验证。 单向验证：server端提供证书(cert和key)，不需要配置certfiles即CA根证书，而在客户端必须提供CA根证书，用来验证server端的证书是否有效。另外client端也不需要自己的证书，因为它不需要想server端提供验证。 双向验证：server端提供证书(cert和key)，还必须配置cerfiles即CA根证书，因为需要验证client端提供的证书。另外client也端必须提供一样的内容，即client端的证书(cert/key)以供server端验证，并且提供CA根证书验证server端提供的证书。 配置fabric-ca-client端fabric-ca-client-config.yaml 1234567891011121314151617############################################################################## TLS section for secure socket connection## certfiles - PEM-encoded list of trusted root certificate files# client:# certfile - PEM-encoded certificate file for when client authentication# is enabled on server# keyfile - PEM-encoded key file for when client authentication# is enabled on server#############################################################################tls: # TLS section for secure socket connection certfiles: client: certfile: keyfile: 包含 CA根证书 client自己的证书(cert和key)，如果启动双向认证。 命令行方式配置除了使用yaml文件配置，server和client也可以在命令行配置TLS信息：1234567Server：--tls.certfile string PEM-encoded TLS certificate file for server&apos;s listening port (default &quot;tls-cert.pem&quot;)--tls.clientauth.certfiles stringSlice A list of comma-separated PEM-encoded trusted certificate files (e.g. root1.pem,root2.pem)--tls.clientauth.type string Policy the server will follow for TLS Client Authentication. (default &quot;noclientcert&quot;)--tls.enabled Enable TLS on the listening port--tls.keyfile string PEM-encoded TLS key for server&apos;s listening port Client: --tls.certfiles stringSlice A list of comma-separated PEM-encoded trusted certificate files (e.g. root1.pem,root2.pem) --tls.client.certfile string PEM-encoded certificate file when mutual authenticate is enabled --tls.client.keyfile string PEM-encoded key file when mutual authentication is enabled]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fabric peer 参数说明]]></title>
    <url>%2F2019%2F11%2F27%2Fblockchain%2F2019-11-27-Fabric%20peer%20%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[peer模块是Fabric中的核心模块，在Fabric中被称为节点模块，主要负责存储区块链数据、运行链码、背书、提供对外服务接口等。在Fabric中使用最频繁 1 peer模块命令和参数Usage: peer [flags] peer [command] Available Commands: chaincode #操作链码，相关子命令: install|instantiate|invoke|package|query|signpackage|upgrade. channel #操作通道，相关子命令: create|fetch|join|list|update. logging #操作日志，相关子命令: getlevel|setlevel|revertlevels. node #节点服务，相关子命令: start|status. version #打印版本信息 Flags: --logging-level string #日志级别 --test.coverprofile string #测试配置文件 -v, --version #显示当前服务器的版本2 peer模块的配置选项peer模块的配置选项可以通过环境变量或者配置文件的方式来配置,在具体操作中，如果是通过Docker方式启动，一般使用环境变量配置方式。如果是采用直接命令启动，一般是采用配置文件方式 环境变量的配置示例如下： 1234567891011export set CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock export set CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=hostexport set CORE_LOGGING_LEVEL=DEBUGexport set CORE_PEER_TLS_ENABLED=trueexport set CORE_PEER_GOSSIP_USELEADERELECTION=trueexport set CORE_PEER_GOSSIP_ORGLEADER=falseexport set CORE_PEER_PROFILE_ENABLED=falseexport set CORE_PEER_TLS_CERT_FILE=/home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/server.crtexport set CORE_PEER_TLS_KEY_FILE=/home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/server.keyexport set CORE_PEER_TLS_ROOTCERT_FILE=/home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/ca.crt 配置文件示例如下：core.yaml 配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177logging: peer: debug cauthdsl: warning gossip: warning ledger: info msp: warning policies: warning grpc: error format: '%&#123;color&#125;%&#123;time:2006-01-02 15:04:05.000 MST&#125; [%&#123;module&#125;] %&#123;shortfunc&#125; -&gt; %&#123;level:.4s&#125; %&#123;id:03x&#125;%&#123;color:reset&#125; %&#123;message&#125;'peer: id: peer0.org1.simple-network.com networkId: dev listenAddress: 0.0.0.0:7051 address: peer0.org1.simple-network.com:7051 chaincodeListenAddress: 0.0.0.0:7052 addressAutoDetect: false gomaxprocs: -1 gossip: bootstrap: 127.0.0.1:7051 useLeaderElection: true orgLeader: false endpoint: maxBlockCountToStore: 100 maxPropagationBurstLatency: 10ms maxPropagationBurstSize: 10 propagateIterations: 1 propagatePeerNum: 3 pullInterval: 4s pullPeerNum: 3 requestStateInfoInterval: 4s publishStateInfoInterval: 4s stateInfoRetentionInterval: publishCertPeriod: 10s skipBlockVerification: false dialTimeout: 3s connTimeout: 2s recvBuffSize: 20 sendBuffSize: 200 digestWaitTime: 1s requestWaitTime: 1s responseWaitTime: 2s aliveTimeInterval: 5s aliveExpirationTimeout: 25s reconnectInterval: 2 externalEndpoint: peer0.org1.simpe-network.com:7051 election: startupGracePeriod: 15s membershipSampleInterval: 1s leaderAliveThreshold: 10s leaderElectionDuration: 5s pvtData: maxPeers: 3 minAck: 3 events: address: 0.0.0.0:7053 buffersize: 100 timeout: 10ms tls: enabled: false cert: file: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/server.crt key: file: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/server.key rootcert: file: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/ca.crt serverhostoverride: fileSystemPath: /home/zym/fabric-ws/simple-demo/peer0-org1/production BCCSP: Default: SW SW: Hash: SHA2 Security: 256 FileKeyStore: KeyStore: mspConfigPath: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/msp localMspId: Org1MSP profile: enabled: false listenAddress: 0.0.0.0:6060 handlers: authFilter: "DefaultAuth" decorator: "DefaultDecorator"vm: endpoint: unix:///var/run/docker.sock docker: tls: enabled: false ca: file: docker/ca.crt cert: file: docker/tls.crt key: file: docker/tls.key attachStdout: false hostConfig: NetworkMode: host Dns: LogConfig: Type: json-file Config: max-size: "50m" max-file: "5" Memory: 2147483648chaincode: peerAddress: id: path: name: builder: $(DOCKER_NS)/fabric-ccenv:$(ARCH)-$(PROJECT_VERSION) golang: runtime: $(BASE_DOCKER_NS)/fabric-baseos:$(ARCH)-$(BASE_VERSION) car: runtime: $(BASE_DOCKER_NS)/fabric-baseos:$(ARCH)-$(BASE_VERSION) java: Dockerfile: | from $(DOCKER_NS)/fabric-javaenv:$(ARCH)-$(PROJECT_VERSION) startuptimeout: 300s executetimeout: 30s mode: net keepalive: 0 system: cscc: enable lscc: enable escc: enable vscc: enable qscc: enable logging: level: info shim: warning format: '%&#123;color&#125;%&#123;time:2006-01-02 15:04:05.000 MST&#125; [%&#123;module&#125;] %&#123;shortfunc&#125; -&gt; %&#123;level:.4s&#125; %&#123;id:03x&#125;%&#123;color:reset&#125; %&#123;message&#125;'ledger: blockchain: state: stateDatabase: goleveldb couchDBConfig: couchDBAddress: 127.0.0.1:5984 username: password: maxRetries: 3 maxRetriesOnStartup: 10 requestTimeout: 35s queryLimit: 10000 history: enableHistoryDatabase: true 2.1 peer模块配置文件详解peer的配置文件的默认名为core.yaml，配置文件分为logging、peer、vm、chaincode、ledger这5大部分。各部分相关属性如下所示。 2.1.1 配置文件中logging相关的属性longing节点定义了peer模块中所有模块的日志级别和日志格式。 日志级别:critical、error、warning、notice、info、debug 123456789101112logging: peer: debug cauthdsl: warning gossip: warning ledger: info msp: warning policies: warning grpc: error format: '%&#123;color&#125;%&#123;time:2006-01-02 15:04:05.000 MST&#125; [%&#123;module&#125;] %&#123;shortfunc&#125; -&gt; %&#123;level:.4s&#125; %&#123;id:03x&#125;%&#123;color:reset&#125; %&#123;message&#125;' 2.1.2 peer相关的配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126peer: #节点的编号 id: peer0.org1.simple-network.com #节点的网络编号 networkId: dev #节点监听地址 listenAddress: 0.0.0.0:7051 #节点访问地址 address: peer0.org1.simple-network.com:7051 #chaincode监听地址 chaincodeListenAddress: 0.0.0.0:7052 #对等端是否应以编程方式确定其地址 addressAutoDetect: false #peer最大可用cpu数， -1表示用默认值 gomaxprocs: -1 gossip: #启动节点后向哪些节点发起gossip连接加入网络，本节点需要和所连接节点同属一个组织 bootstrap: 127.0.0.1:7051 #是否开启主节点自动选举 useLeaderElection: true #是否将当前节点配置成主节点 orgLeader: false #当前节点在组织内的gossip id，默认为peer.address endpoint: #保存到内存中的区块个数上限，超过则丢弃 maxBlockCountToStore: 100 #保存消息的最大时间，超过则触发转发给其他节点 maxPropagationBurstLatency: 10ms #保存消息最大个数，超过则转发给其他节点 maxPropagationBurstSize: 10 #消息转发次数 propagateIterations: 1 #消息转发给指定个数的节点 propagatePeerNum: 3 #拉去消息时间间隔 pullInterval: 4s #从指定个数的节点拉取消息 pullPeerNum: 3 #从节点拉取状态信息消息间隔 requestStateInfoInterval: 4s #向其他节点推送状态信息消息的间隔 publishStateInfoInterval: 4s #状态消息的超时时间 stateInfoRetentionInterval: #启动后在心跳消息中嵌入证书的等待时间 publishCertPeriod: 10s #是否不对区块消息进行校验，默认为false skipBlockVerification: false #gRPC连接拨号的超时时间 dialTimeout: 3s #建立连接的超时时间 connTimeout: 2s #接收消息缓冲区大小 recvBuffSize: 20 #发送消息缓冲区大小 sendBuffSize: 200 #处理摘要数据的等待时间 digestWaitTime: 1s #处理nonce数据的等待时间 requestWaitTime: 1s #终止拉取数据的等待时间 responseWaitTime: 2s #心跳发送间隔时间 aliveTimeInterval: 5s #心跳雄安锡的超时时间 aliveExpirationTimeout: 25s #断线后重连的时间间隔 reconnectInterval: 2 #节点配组织外感知的地址，默认为空，表示不被外部感知 externalEndpoint: peer0.org1.simpe-network.com:7051 election: startupGracePeriod: 15s membershipSampleInterval: 1s leaderAliveThreshold: 10s leaderElectionDuration: 5s pvtData: maxPeers: 3 minAck: 3 events: #事件监听地址 address: 0.0.0.0:7053 #事件消息缓存数，超过该值则被阻塞 buffersize: 100 #队列阻塞的超时时间 timeout: 10ms tls: #是否使能tls通信 enabled: false #服务器身份验证证书 cert: file: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/server.crt #服务器私钥 key: file: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/server.key #服务器根证书 rootcert: file: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/tls/ca.crt #tls握手时指定服务器名称 serverhostoverride: #账本数据文件存放路径 fileSystemPath: /home/zym/fabric-ws/simple-demo/peer0-org1/production #加密机制相关的配置 BCCSP: Default: SW SW: Hash: SHA2 Security: 256 FileKeyStore: KeyStore: #当前节点的msp路径 mspConfigPath: /home/zym/fabric-ws/simple-demo/crypto-config/peerOrganizations/org1.simple-network.com/peers/peer0.org1.simple-network.com/msp #当前节点名称 localMspId: Org1MSP profile: #是否开启了go profile enabled: false #go profile获取地址 listenAddress: 0.0.0.0:6060 handlers: authFilter: "DefaultAuth" decorator: "DefaultDecorator" 2.1.3 vm相关的配置12345678910111213141516171819202122232425262728vm: #docker服务器的daemon的地址 endpoint: unix:///var/run/docker.sock docker: tls: #是否启动docker的tls通信 enabled: false ca: file: docker/ca.crt cert: file: docker/tls.crt key: file: docker/tls.key #是否将docker的消息绑定到指定的输出 attachStdout: false hostConfig: #chaincode容器的网络命名模式 NetworkMode: host Dns: LogConfig: #docker日志配置信息 Type: json-file Config: max-size: "50m" max-file: "5" Memory: 2147483648 2.1.4 chaincode相关的配置12345678910111213141516171819202122232425262728293031323334353637383940414243chaincode: #chaincode中peer服务器地址 peerAddress: id: path: name: #本地编译环境为docker镜像 builder: $(DOCKER_NS)/fabric-ccenv:$(ARCH)-$(PROJECT_VERSION) #go语言版本的chaincode的基础镜像 golang: runtime: $(BASE_DOCKER_NS)/fabric-baseos:$(ARCH)-$(BASE_VERSION) #car格式的chaincode生成镜像文件时的基础镜像 car: runtime: $(BASE_DOCKER_NS)/fabric-baseos:$(ARCH)-$(BASE_VERSION) #java版本的chaincode基础镜像 java: Dockerfile: | from $(DOCKER_NS)/fabric-javaenv:$(ARCH)-$(PROJECT_VERSION) #启动chaincode容器时的超时时间，超过这个时间认为启动失败 startuptimeout: 300s #执行Invoke和Init方法时的超时时间，超过这个时间认定执行失败 executetimeout: 30s #chaincode运行模式，net为网络模式，dev为开发模式，dev模式下，可以在容器外运行chaincode mode: net #peer节点和chaincode节点的心跳时间的保持时间，如果这个之小于等于0，相当于关闭心跳保持 keepalive: 0 #系统chaincode的开关 system: cscc: enable lscc: enable escc: enable vscc: enable qscc: enable #chaincode的模块日志级别和日志格式 logging: level: info shim: warning format: '%&#123;color&#125;%&#123;time:2006-01-02 15:04:05.000 MST&#125; [%&#123;module&#125;] %&#123;shortfunc&#125; -&gt; %&#123;level:.4s&#125; %&#123;id:03x&#125;%&#123;color:reset&#125; %&#123;message&#125;' 2.1.5 ledger相关的配置12345678910111213141516171819ledger: blockchain: state: #数据库类型，目前支持golevedb和CouchDB stateDatabase: goleveldb #如果上面配置了CouchDB，则下面couchDB相关的配置生效 couchDBConfig: couchDBAddress: 127.0.0.1:5984 username: password: maxRetries: 3 maxRetriesOnStartup: 10 requestTimeout: 35s queryLimit: 10000 #是否使能历史状态数据库 history: enableHistoryDatabase: true]]></content>
      <categories>
        <category>区块链</category>
        <category>Fabric</category>
      </categories>
      <tags>
        <tag>Fabric</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决go get 命令 timeout错误的方法]]></title>
    <url>%2F2019%2F10%2F10%2Fgo%2F2019-10-10-%E8%A7%A3%E5%86%B3%20go%20get%20%E5%91%BD%E4%BB%A4timeout%20%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在执行go get 命令下载 golang.org/x 相关的包时经常报timeout错误。例如： 12package golang.org/x/time/rate: unrecognized import path &quot;golang.org/x/time/rate&quot; (https fetch: Get https://golang.org/x/time/rate?go-get=1: dial tcp 216.239.37.1:443: i/o timeout) 这是因为国内网络对https://golang.org/网站限制的愿意造成的。 安装依赖包golang.org/x 的包的解决方法是：*（1）去https://github.com/golang/寻找time/rate，找到GitHub地址是：https://github.com/golang/time.git*（2）执行以下命令 1234$mkdir -p $GOPATH/src/golang.org/x/$cd $GOPATH/src/golang.org/x/$git clone https://github.com/golang/time.git time $go install time 例如:package golang.org/x/net/context: unrecognized 去github查找，找到的地址为： https://github.com/golang/net.git然后执行命令：$mkdir -p $GOPATH/src/golang.org/x/$cd $GOPATH/src/golang.org/x/$git clone https://github.com/golang/net.git net$go install net]]></content>
      <categories>
        <category>GO</category>
      </categories>
      <tags>
        <tag>GO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Redis 集群安装]]></title>
    <url>%2F2019%2F08%2F04%2Fdocker%2F2019-08-04-docker%20redis%20%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[拉取redis镜像1docker pull redis:5.0.3 增加配置文件redis-cluster.tmpl在用户目录下创建文件 ${userpath}/redis-cluster/redis-cluster.tmpl 123456789port $&#123;PORT&#125;protected-mode nocluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000cluster-announce-ip 192.168.XX.XX //宿主机服务器IPcluster-announce-port $&#123;PORT&#125;cluster-announce-bus-port 1$&#123;PORT&#125;appendonly yes cluster-announce-ip 为宿主机服务器IP 创建redis配置文件在redis-cluster目录下创建并执行批处理命令，用于创建redis配置文件。创建端口号为从7000 到 7005 的配置文件for port in seq 7000 7005; do mkdir -p ./${port}/conf &amp;&amp; PORT=${port} envsubst &lt; ./redis-cluster.tmpl &gt; ./${port}/conf/redis.conf &amp;&amp; mkdir -p ./${port}/data; done 创建redis集群的Docker network1docker network create redis-net 启动Redis容器将以下批处理命令中${userpath}替换成你的真实路径。执行批处理命令以启动容器。 1234567for port in `seq 7000 7005`; do \ docker run -d -ti -p $&#123;port&#125;:$&#123;port&#125; -p 1$&#123;port&#125;:1$&#123;port&#125; \ -v $&#123;userpath&#125;/redis_cluster/$&#123;port&#125;/conf/redis.conf:/usr/local/etc/redis/redis.conf \ -v $&#123;userpath&#125;/redis_cluster/$&#123;port&#125;/data:/data \ --restart always --name redis-$&#123;port&#125; --net redis-net \ --sysctl net.core.somaxconn=1024 redis:tag redis-server /usr/local/etc/redis/redis.conf; \done 搭建集群查看集群网络中的容器ip地址可以逐个查看 查看7000～7005这6个redis容器的IP，命令行如下： 123456789101112131415161718192021222324252627 docker inspect redis7000 | grep IPAddress``` 查询结果如下： ```text[root@localhost ~]# docker inspect redis7000 | grep IPAddress &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;192.168.0.2&quot;, [root@localhost ~]#[root@localhost ~]# docker inspect redis7001 | grep IPAddress &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;192.168.0.3&quot;, [root@localhost ~]#[root@localhost ~]# docker inspect redis7002 | grep IPAddress &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;192.168.0.4&quot;, [root@localhost ~]#[root@localhost ~]# docker inspect redis7003 | grep IPAddress &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;192.168.0.5&quot;, [root@localhost ~]# docker inspect redis7004 | grep IPAddress &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;192.168.0.6&quot;, [root@localhost ~]#[root@localhost ~]# docker inspect redis7005 | grep IPAddress &quot;SecondaryIPAddresses&quot;: null, &quot;IPAddress&quot;: &quot;172.17.0.7&quot;, [root@localhost ~]# 也可以使用批处理命令查看IP列表 123for port in `seq 7000 7005`; do \ echo -n &quot;$(docker inspect --format &apos;&#123;&#123; (index .NetworkSettings.Networks &quot;redis-net&quot;).IPAddress &#125;&#125;&apos; &quot;redis-$&#123;port&#125;&quot;)&quot;:$&#123;port&#125; &apos; &apos; ; \done 得到如下几个ip端口列表： 1192.168.0.2:7000 192.168.0.3:7001 192.168.0.4:7002 192.168.0.5:7003 192.168.0.6:7004 192.168.0.7:7005 创建集群Redis 5.0版本开始，搭建集群已经不再使用ruby了,而是直接使用redis-cli来创建集群。进入其中一个Redis容器。 1docker exec -it redis-7005 /bin/bash 在docker容器内执行集群命令，注意需要用到上一步得到的IP地址。 1redis-cli --cluster create 192.168.0.2:7000 192.168.0.3:7001 192.168.0.4:7002 192.168.0.5:7003 192.168.0.6:7004 192.168.0.7:7005 --cluster-replicas 1]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker离线安装]]></title>
    <url>%2F2019%2F08%2F01%2Fdocker%2F2019-08-01-docker%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Docker离线安装安装docker安装步骤如下： （1）拷贝docker 到 /usr/bin （2）修改Docker存储路径 1234service docker stopcd /var/lib/mv docker/*/home/dockerfilerm -rf docker (3)进入/home/dockerfile创建软连接12ln -s/home/dockerfile/ /var/lib/dockerservice docker start 开启远程访问打开服务配置文件 1vi /lib/systemd/system/docker.service 在文件中添加以下内容 1234567891011121314151617181920212223242526272829303132333435363738[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPID# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.#TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60sExecStart=ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock[Install]WantedBy=multi-user.target 开启docker随系统启动模式1systemctl enable docker 配置仓库管理地址这个步骤主要用于开启docker 仓库，如果您不需要将服务器作为docker仓库，可以跳过这个步骤。 12echo &apos;export DOCKER_HOST=tcp://0.0.0.0:2375&apos; &gt;&gt; /etc/profile source /etc/profile 创建docker仓库12docker pull registrydocker run -d -p 5000:5000 --restart=always --privileged=true -v /opt/registry:/tmp/registry registry 参数说明 -d 后台执行 -p 端口映射, 宿主机80端口映射给容器的5000端口 –restart=always 容器意外关闭后, 自动重启(如果重启docker服务, 带这个参数的, 能自动启动为Up状态, 不带这个的,不会自动启动) -v /opt/registry:/tmp/registry 默认情况下，会将仓库存放于容器内的/tmp/registry目录下，指定本地目录挂载到容器 -privileged=true 在CentOS7中，安全模块selinux把权限禁掉了，参数给容器加特权，如果不加上这个参数，在传镜像的过程中会报权限错误(OSError: [Errno 13] Permission denied: ‘/tmp/registry/repositories/liibrary’)或者（Received unexpected HTTP status: 500 Internal Server Error） 镜像仓库配置修改/etc/sysconfig/docker，在已有参数的在后面追加增加以下启动选项 ，保存并重启docker。 CentOS 7系统 OPTIONS=’–insecure-registry 192.168.44.240:5000’ CentOS 6系统 other_args=’–insecure-registry 192.168.44.240:5000’通过修改以上配置，让你的私有仓库支持 http，因为从 docker1.3.2 开始，docker registry 默认都是使用 https 协议而不使用 http]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清除docker无用镜像]]></title>
    <url>%2F2019%2F07%2F31%2Fdocker%2F2019-07-31-%E6%B8%85%E9%99%A4docker%E6%97%A0%E7%94%A8%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[清除docker无用镜像在docker镜像列表中我们经常会看到一堆tag为 &lt;none&gt; 的镜像，已经没有在使用，但随着提交次数增加，这些僵尸的占用了大量的磁盘空间，有必要做一次清理。可以使用以下命令清理none镜像 1docker rmi -f $(docker images | grep &quot;&lt;none&gt;&quot; | awk &quot;&#123;print \$3&#125;&quot;) 使用以下命令清理已经停止运行的docker容器 1docker rm $(docker ps --all -q -f status=exited)]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.12 Springboot&VUE开发实践（SpringBoot缓存处理）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.12SpringBoot%20%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.12 缓存处理1.12.1 缓存配置SpringBoot2.0 的缓存可以使用注解方式实现。 （1） 修改pom文件添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; （2） 修改application-dev.properties配置文件添加配置“spring.cache.type=redis” （3） 添加@EnableCaching开启缓存注解 1234567891011@EnableCaching@ServletComponentScan@SpringBootApplication(scanBasePackages = &#123;"com.zone7.demo.helloworld"&#125;)public class HelloworldApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HelloworldApplication.class, args); &#125;&#125; 1.12.2 注解说明在需要使用缓存的方法上面添加以下注解： - @Cacheable 将方法的运行结果进行缓存；第二次再要相同的数据，直接从缓存中获取，不再调用方法； - @CacheEvict 移除缓存 - @CachePut 修改了数据库的某个数据，同时更新缓存 以下对这三个注解的属性展开介绍： (1) @CacheableCacheable中的几个属性： 1)cacheNames/value:指定缓存组件的名字， 数组的方式，可以指定多个缓存组件名称。 2)key: 缓存数据使用的key，默认使用方法参数的值作为key。也可以自己指定，通过编写SpEL指定key的值；如：#root.methodName 、#id等。 3)keyGenerator: key的生成器，可以自己编写key的生成器组件。注意：在使用时key和keyGenerator二选一。 4)cacheManager: 指定缓存管理器。 5)condition： 指定符合条件的情况下才缓存；如： condition = “#id&gt;0” “#a0&gt;1”才进行缓存。 6)unless: 否定缓存； 当unless指定的条件为true,方法的返回值就不会缓存；如：可以获取到结果进行判断unless = “#result == null “ 当方法结果为null时，不缓存。 7)sync: 是否使用异步模式 (2) @CacheEvit @CacheEvit：缓存清除 @CacheEvit和@Cacheable的相同属性就不再赘述。 1)allEntries = true 每次删除，将指定缓存中的所有数据全都删除。 2)beforeInvocation=false ,缓存的清除是否是在方法之前执行，默认false, 即在方法之后清除，当方法执行出现异常时，缓存不会清除。 3)beforeInvocation=true ,方法之前清除，无论方法执行是否出现异常，缓存都会清除。 (3) @CachePut运行时机：先调用目标方法，将目标方法的结果缓存起来，属性与@Cacheable相同。此外还有@CacheConfig：可以标注在类上，抽取出相同的属性，简化代码。12345678910@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CacheConfig &#123; String[] cacheNames() default &#123;&#125;; String keyGenerator() default ""; String cacheManager() default ""; String cacheResolver() default "";&#125; 1.12.3 缓存使用我们在服务层实现类中增加缓存注解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133package com.zone7.demo.helloworld.sys.service.impl;import com.zone7.demo.helloworld.commons.exception.AddOPException;import com.zone7.demo.helloworld.commons.exception.DeleteOPException;import com.zone7.demo.helloworld.commons.exception.UpdateOPException;import com.zone7.demo.helloworld.sys.dao.SysUserMapper;import com.zone7.demo.helloworld.sys.pojo.SysUser;import com.zone7.demo.helloworld.sys.service.SysUserService;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import com.zone7.demo.helloworld.utils.MD5Util;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cache.annotation.CacheConfig;import org.springframework.cache.annotation.CacheEvict;import org.springframework.cache.annotation.CachePut;import org.springframework.cache.annotation.Cacheable;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import java.util.ArrayList;import java.util.List;/** * SysUserServiceImpl * * @author: zone7 * @time: 2019.02.17 */@Service@CacheConfig(cacheNames = "users")public class SysUserServiceImpl implements SysUserService &#123; @Value("$&#123;system.default.password&#125;") private String defaultPassword; @Autowired private SysUserMapper sysUserMapper; @Autowired private StringRedisTemplate stringRedisTemplate; @Override @Transactional(rollbackFor = AddOPException.class) @CachePut public SysUserVo save(SysUserVo userVo) &#123; try &#123; String password = defaultPassword; String md5Password = MD5Util.encode(password); SysUser sysUser = SysUser.builder() .name(userVo.getName()).password(md5Password) .phone(userVo.getPhone()) .department(userVo.getDepartment()) .build(); // 存储用户信息 sysUserMapper.insertSelective(sysUser); SysUserVo vo=new SysUserVo(); BeanUtils.copyProperties(sysUser,vo); return vo; &#125; catch (Exception e) &#123; throw new AddOPException("新增用户操作出错，错误原因: " + e.getMessage()); &#125; &#125; @Override @Transactional(rollbackFor = UpdateOPException.class) @CachePut public void update(SysUserVo userVo) &#123; try &#123; SysUser after = SysUser.builder() .id(userVo.getId()) .name(userVo.getName()) .phone(userVo.getPhone()) .department(userVo.getDepartment()).build(); sysUserMapper.updateByPrimaryKeySelective(after); &#125; catch (Exception e) &#123; throw new UpdateOPException("更新用户操作出错，错误原因: " + e.getMessage()); &#125; &#125; @Override @Cacheable public SysUserVo findById(Integer id) &#123; SysUser user = sysUserMapper.selectByPrimaryKey(id); SysUserVo vo=new SysUserVo(); BeanUtils.copyProperties(user,vo); return vo; &#125; @Override public List&lt;SysUserVo&gt; findByName( String name) &#123; List&lt;SysUser&gt; users = sysUserMapper.findByName(name); List&lt;SysUserVo&gt; userList = new ArrayList&lt;SysUserVo&gt;(); users.forEach(sysUser -&gt; &#123; // 查询角色信息 SysUserVo vo=new SysUserVo(); BeanUtils.copyProperties(sysUser,vo); userList.add(vo); &#125;); return userList; &#125; @Override @Transactional(rollbackFor = DeleteOPException.class) @CacheEvict public void delete(Integer id) &#123; try &#123; sysUserMapper.deleteByPrimaryKey(id); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new DeleteOPException("删除用户操作出错，错误原因: " + e.getMessage()); &#125; &#125;&#125; 通过Postman测试执行两次findById操作只有第一次进入方法内部执行，后续的执行都直接返回缓存中的数据。]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 Springboot&VUE开发实践（VUE前端开发）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%882%20VUE%20%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%EF%BC%89%2F</url>
    <content type="text"><![CDATA[2 前端开发框架VUE开发2.1 VUE简介Vue框架设计采用的是MVVM设计模式MVVM是Model-View-ViewModel的简写，主要包括view（视图）、model（模型）、ViewModel（视图模型）。模型指的是后端传递的数据；视图指的是所看到的页面；视图模型是mvvm模式的核心，它是连接view和model的桥梁。它的两个主要作用是：一是将模型转化成视图，即将后端传递的数据转化成所看到的页面。实现的方式是：数据绑定。二是将视图转化成模型，即将所看到的页面转化成后端的数据。实现的方式是：DOM 事件监听。这两个方向的实现我们称之为数据的双向绑定。MVVM流程图如下： 在VUE项目开发时我们不需要关注ViewModel层，这是Vue.js的内置功能，只需要关注视图层和模型层即可。vue通过一个尽量简单的api来提供api提供反应式的数据绑定和可组合、复用的视图组件，不是一个大而全的框架。快速开发原型，混合其他的库做更多的事情。 2.2 安装及快速入门Web1.0时代网页是“只读的”；在Web 1.0之后，互联网的第二次迭代被称作Web 2.0，也就是“可读写”网络，形形色色的社交网站和点评网站，是Web 2.0的代表； Web 3.0时代，技术的发展带来的是在线应用和网站可以接收到已经在网络上的信息，并将新的信息和数据反馈给用户，网站因为有了自主学习能力，而变得更加智能。 随着web技术的发展，前端技术也从原来的操作DOM的时代，发展到如今围绕着操作数据的阶段，之前大家常用的前端框架是JQuery、Bootstrap框架， 而今天大家用得更多的是React、Vue、Angular三大主流框架，这三个框架各有各的优势，而且都较为成熟。vue作为三大前端框架之一，社区比较活跃，应用也已经十分广泛。下面主要介绍vue框架的安装和开发。 Step1：安装node.js安装完node.js之后，npm也会自动安装查询是否安装成功的命令：node -vnpm -v Step2：安装脚手架工具vue-cli命令如下：npm install –global vue-cli Step3：全局安装Webpak命令如下：npm install -g webpacknpm install -g webpack-cli查看版本：webpack -v Step4：VUE项目初始化vue项目初始化命令如下：vue init webpack helloworld注：安装过程 中有个选项（Use ESLint to line your code ?选择 No ） 初始化完成后的vue项目目录如下： Step5: 安装依赖进入到Helloworld目录下，使用npm install 安装package.json包中的依赖命令如下：cd Helloworldnpm install Step6：运行项目执行下面命令运行项目：npm run dev Step7：停止项目ctrl+c，即可停止项目的运行 2.3 VUE项目目录说明build：项目构建(webpack)相关代码config：配置目录，包括端口号等node_modules：npm加载的项目依赖块src：这里是我们要开发的目录，基本上要做的事情都在这个目录里。里面包含了几个目录及文件：assets: 放置一些图片，如logo等components：该目录里存放的我们的开发文件组件，主要的开发文件都存放在这里了App.vue：项目入口文件main.js：项目的核心文件router：路由配置目录static：放置一些静态资源文件test：初始测试目录，可删除index.html：首页入口文件package.json：项目配置文件README.md：项目的说明文档，markdown 格式 2.4 VUE生命周期VUE的运行过程都在node环境下进行，执行生命周期如下图所示： VUE的执行过程包括以下几个步骤： (1)在执行npm run dev的时候，首先在当前文件夹下的项目中找package.json文件,启动默认端口是8080。 (2)执行src的main.js文件，在该文件中创建一个Vue的实例，入参包括要渲染的元素、路由、绑定的组件以及模版。 (3)渲染模板并执行App.vue组件在App.vue组件中有一个router-view，router-view对应的路由配置在src/router目录下，该文件夹下有个index.js文件，该文件用于配置路由词典，指定了路由地址是空，加载HelloWorld组件。 2.5 第一个工程Step1:在src下创建views文件夹，并在src/views下创建.vue结尾的文件 布局页面 Layout.vue 页面导航菜单top.vue 首页main.vue 关于页面about.vue (1)src/views/Layout.vue 12345678910111213141516171819202122232425&lt;template&gt; &lt;div&gt; &lt;div&gt; &lt;top&gt;&lt;/top&gt; &lt;/div&gt; &lt;div&gt; &lt;router-view :key="key" /&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import Top from '@/views/top' import Main from '@/views/main' import About from '@/views/about' export default &#123; name: 'Layout', components: &#123; Top, About, Main &#125; &#125;&lt;/script&gt; (2)src/views/top.vue 1234567891011121314151617181920212223242526272829&lt;template&gt; &lt;div class="top navbar-fixed-top"&gt; &lt;div class="container"&gt; &lt;div class="row"&gt; &lt;div class="col-xs-2"&gt;&lt;/div&gt; &lt;div class="col-xs-8 text-center"&gt; &lt;router-link :to="&#123;name:'Main'&#125;"&gt;&lt;strong&gt;首页&lt;/strong&gt;&lt;/router-link&gt; &lt;router-link :to="&#123;name:'About'&#125;"&gt;&lt;strong&gt;关于&lt;/strong&gt;&lt;/router-link&gt; &lt;/div&gt; &lt;div class="col-xs-2"&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: 'Top', data()&#123; return &#123; message: '欢迎使用zone7 框架' &#125; &#125; &#125;&lt;/script&gt; (3)src/views/main.vue 1234567891011121314151617&lt;template&gt; &lt;div&gt; &#123;&#123;message&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: 'Main', data()&#123; return &#123; message: 'Hello World 这是首页' &#125; &#125; &#125;&lt;/script&gt; (4)src/views/about.vue 1234567891011121314151617&lt;template&gt; &lt;div&gt; &#123;&#123;message&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'About', data () &#123; return &#123; message: '欢迎使用Zone7 框架' &#125; &#125;&#125;&lt;/script&gt; Step2:修改src/router/index.js 添加页面路由123456789101112131415161718192021222324252627282930import Vue from &apos;vue&apos;import Router from &apos;vue-router&apos;import Main from &apos;@/views/main&apos;import Layout from &apos;@/views/Layout&apos;Vue.use(Router)export default new Router(&#123; routes: [ &#123; path: &apos;&apos;, component: Layout, redirect: &apos;main&apos;, children: [ &#123; path: &apos;main&apos;, component: () =&gt; import(&apos;@/views/main&apos;), name: &apos;Main&apos;, meta: &#123; title: &apos;首页&apos;, icon: &apos;dashboard&apos;, noCache: true, affix: true &#125; &#125;, &#123; path: &apos;about&apos;, component: () =&gt; import(&apos;@/views/about&apos;), name: &apos;About&apos;, meta: &#123; title: &apos;关于&apos;, icon: &apos;about&apos;, noCache: true, affix: true &#125; &#125;, ] &#125; ]&#125;) Step3：运行npm run dev]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.11 Springboot&VUE开发实践（SpringBoot日志处理）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.11SpringBoot%20%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.11 日志处理SpringBoot使用Commons Logging进行所有内部日志记录，但底层日志实现保持开放状态。为Java Util Logging，Log4j2和Logback提供了默认配置。SpringBoot能自动适配所有的日志，这里主要介绍slf4j+logback的实现，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可。 SpringBoot默认帮我们配置好了日志，我们直接使用即可。例如我们可以在代码中使用以下代码来新建日志类。private static final Logger logger = LoggerFactory.getLogger(MongoDBServiceImpl.class); 使用日志类打印日志信息： 12345678// 级别由低到高 trace&lt;debug&lt;info&lt;warn&lt;errorlogger.trace("这是一个trace日志...");logger.debug("这是一个debug日志...");// SpringBoot默认是info级别，只会输出info及以上级别的日志logger.info("这是一个info日志...");logger.warn("这是一个warn日志...");logger.error("这是一个error日志..."); 另外，可以通过application-dev.properties 来配置日志级别和输出文件。 123456789#================== slf4j日志配置 ===================## 路径logging.path=/Users/zgq/logslogging.file=zone7.log#location of config file (default classpath:logback.xml for logback)#logging.config=# levels for loggers, e.g. &quot;logging.level.org.springframework=DEBUG&quot; (TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF)logging.level.com.zone7=INFO]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.9 Springboot&VUE开发实践（SpringBoot整合Oauth2.0）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.9SpringBoot%20%E6%95%B4%E5%90%88Oauth2.0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.9 整合Oauth2.01.9.1 Oauth2.0介绍在实践之前我们先来了解下oauth2.0，OAuth是一个关于授权（authorization）的开放网络标准，在全世界得到广泛应用，目前的版本是2.0版。OAuth2.0服务提供者实际上分为：“授权服务 Authorization Service ”和“资源服务Resource Service”。Oauth2.0 的运行流程如下图所示： *（A）用户打开客户端，客户端要求用户给予授权。*（B）用户同意给予客户端授权。*（C）客户端使用上一步获得的授权（一般是Code），向认证服务器申请令牌TOKEN。*（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。*（E）客户端使用令牌，向资源服务器申请获取资源（用户信息等）。*（F）资源服务器确认令牌无误，同意向客户端开放资源。图中服务端的三个组件分别为： Resource Owner：即指需要授权访问的资源，比如用户昵称，头像 Authorization Server：鉴权服务，核心鉴权逻辑 Resource Server：资源服务Oauth2.0 定义了五种授权方式： 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 扩展模式（Extension） 1.9.2 Oauth2.0授权模式1.9.2.1 授权码模式（authorization_code）授权码模式是功能最完整、流程最严密的授权模式。他的特点是通过客户端的后台服务器，与”服务提供商”的认证服务器进行互动。以微信公众平台公众号网页应用开发流程为例。 步骤如下： （A）用户访问客户端，客户端将用户导向认证服务器。 （B）用户选择是否给予客户端授权。 （C）若用户给予授权，认证服务器将用户导向客户端指定的”重定向URI”（redirection URI），同时附上授权码code。 （D）客户端收到授权码code，附上早先的”重定向URI”，向认证服务器申请token。这一步是在客户端的后台的服务器上完成的，对用户不可见。 （E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。 授权码模式的几个重要参数如下： response_type：表示授权类型，必选项，此处的值固定为”code” appid：表示客户端的ID，必选项 redirect_uri：表示重定向URI，可选项 scope：表示申请的权限范围，可选项 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。用于防止恶意攻击 授权码模式的URL以及参数应用步骤如下： （1）引导用户跳转到授权页面：http://localhost:8080/oauth/authorize?client_id=client&amp;redirect_uri=REDIRECT_URI&amp;response_type=code&amp;scope=SCOPE&amp;state=STATE#wechat_redirect参数： client_id 客户唯一标识 redirect_uri 授权后重定向的回调链接地址， 请使用 urlEncode 对链接进行处理 response_type 返回类型，请填写code scope 应用授权作用域，有snsapi_base 、snsapi_userinfo 两种 state 重定向后会带上state参数，开发者可以填写a-zA-Z0-9的参数值，最多128字节 （2）通过code获取Tokenhttp://localhost:8080/oauth/token? client_id=client&amp;secret=secret&amp;code=CODE&amp;grant_type=authorization_code参数： client_id 客户唯一标识 secret 密钥 code 填写获取的code参数（存在有效期，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系） grant_type 填写为authorization_code 返回结果： 1234567&#123;"access_token":"ACCESS_TOKEN", //网页授权接口调用凭证,注意：此access_token与基础支持的access_token不同"expires_in":7200, // access_token接口调用凭证超时时间，单位（秒）"refresh_token":"REFRESH_TOKEN", //用户刷新access_token"client_id":"client", //用户唯一标识"scope":"all" //用户授权的作用域，使用逗号（,）分隔 &#125; access_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 1.9.2.2 简化模式（implicit）简化模式是不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过”授权码”步骤。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。 步骤如下： （A）客户端将用户导向认证服务器。 （B）用户决定是否给于客户端授权。 （C）若用户授权，认证服务器将用户导向客户端指定的”重定向URI”，并在URI的Hash部分包含了访问令牌。 （D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。 （E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。 （F）浏览器执行上一步获得的脚本，提取出令牌。 （G）浏览器将令牌发给客户端。 下面是上面这些步骤所需要的参数。 A步骤中，客户端发出的HTTP请求，包含以下参数： response_type：表示授权类型，此处的值固定为”token”，必选项。 client_id：表示客户端的ID，必选项。 redirect_uri：表示重定向的URI，可选项。 scope：表示权限范围，可选项。 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值 例如： 12345GET /authorize?response_type=token&amp;client_id=s6BhdRkqt3&amp;state=xyz&amp;redirect_uri=http://www.baidu.com HTTP/1.1Host: www.baidu.com C步骤中，认证服务器回应客户端的URI，包含以下参数： access_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。例如：12HTTP/1.1 302 FoundLocation: http://www.baidu.com#access_token=9e64da25-105c-4d20-a8b5-606c553c9b33&amp;token_type=bearer&amp;expires_in=829 认证服务器用HTTP头信息的Location栏，指定浏览器重定向的网址。注意，在这个网址的Hash部分包含了令牌。根据上面的D步骤，下一步浏览器会访问Location指定的网址，但是Hash部分不会发送。接下来的E步骤，服务提供商的资源服务器发送过来的代码，会提取出Hash中的令牌。 1.9.2.3 密码模式（Password）向客户端提供自己的用户名和密码，客户端使用这些信息，向”服务商提供商”索要授权。在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。 步骤如下： （A）用户向客户端提供用户名和密码。 （B）客户端将用户名和密码发给认证服务器，向后者请求令牌。 （C）认证服务器确认无误后，向客户端提供访问令牌。在B步骤中，客户端发出的HTTP请求，包含以下参数： grant_type：表示授权类型，此处的值固定为”password”，必选项。 username：表示用户名，必选项。 password：表示用户的密码，必选项。 scope：表示权限范围，可选项。 例如： 123456POST /oauth/token HTTP/1.1Host: localhostAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=password&amp;username=admin&amp;password=111111 C步骤中，认证服务器向客户端发送访问令牌，例子： 123456789101112HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache&#123; &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;, &quot;token_type&quot;:&quot;example&quot;, &quot;expires_in&quot;:3600, &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;, &quot;example_parameter&quot;:&quot;example_value&quot;&#125; 整个过程中，客户端不得保存用户的密码。 1.9.2.4 客户端模式（client_credentials）客户端模式下，并不存在对个体用户授权的行为，被授权的主体为client。因此，该模式可用于对某类用户进行集体授权。 申请该模式时，需要在HTTP request entity-body中提交以下信息。 12345678POST /oauth/tokencontent-type: application/x-www-form-urlencodeduser-agent: PostmanRuntime/7.1.1accept: */*host: localhost:8080accept-encoding: gzip, deflatecontent-length: 74grant_type=client_credentialsscope=allclient_id=zgqclient_secret=secret 若申请成功，服务器将返回access token和token有效时间。 123456789101112HTTP/1.1 200status: 200cache-control: no-storepragma: no-cachex-content-type-options: nosniffx-xss-protection: 1; mode=blockx-frame-options: DENYcontent-type: application/json;charset=UTF-8transfer-encoding: chunkeddate: Thu, 20 Jun 2019 09:01:58 GMT&#123;&quot;access_token&quot;:&quot;43f856cb-2976-4a73-85f3-75638c32f8d7&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;expires_in&quot;:1199,&quot;scope&quot;:&quot;all&quot;&#125; 1.9.2.5 扩展模式扩展模式也叫自定义模式。Oauth2.0的规范中要求 “grant type”参数必须为URI。对于其他申请数据，可以根据需求进行自定义。这里不对这个部分做深入讨论，如果需要可以进一步查看Oauth2.0 相关文档。 1.9.2.6 令牌更新在用户访问的时候，客户端的”访问令牌”如果已经过期，则需要使用”更新令牌”申请一个新的访问令牌。客户端可以发出更新令牌的HTTP请求进行令牌更新。令牌更新请求包含以下参数： grant_type：表示使用的授权模式，此处的值固定为”refresh_token”，必选项。 refresh_token：表示早前收到的更新令牌，必选项。 scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。 client_id： 客户唯一标识 client_secret：密钥 例如：请求内容： 12POST /oauth/tokenrefresh_token=67ced428-1011-4da5-ae54-f3b98cb46b01&amp;grant_type=refresh_token&amp;scope=all&amp;client_id=zgq&amp;token_type=bearer&amp;client_secret=secret 返回内容： 12HTTP/1.1 200&#123;&quot;access_token&quot;:&quot;ab827d16-0a6b-4cdd-abaa-ad6535de9881&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;67ced428-1011-4da5-ae54-f3b98cb46b01&quot;,&quot;expires_in&quot;:11999,&quot;scope&quot;:&quot;all&quot;&#125; 1.9.3 SpringBoot整合Oauth2.0 和Spring Security1.9.3.1 Step1：创建Oauth2.0所需要的三个表Mysql脚本如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243-- ------------------------------ Table structure for oauth_access_token-- ----------------------------DROP TABLE IF EXISTS `oauth_access_token`;CREATE TABLE `oauth_access_token` ( `token_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `token` blob NULL, `authentication_id` varchar(250) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `user_name` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `client_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `authentication` blob NULL, `refresh_token` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`authentication_id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Table structure for oauth_client_details-- ----------------------------DROP TABLE IF EXISTS `oauth_client_details`;CREATE TABLE `oauth_client_details` ( `client_id` varchar(250) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `resource_ids` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `client_secret` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `scope` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `authorized_grant_types` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `web_server_redirect_uri` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `authorities` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `access_token_validity` int(11) NULL DEFAULT NULL, `refresh_token_validity` int(11) NULL DEFAULT NULL, `additional_information` varchar(4096) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `autoapprove` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`client_id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Table structure for oauth_refresh_token-- ----------------------------DROP TABLE IF EXISTS `oauth_refresh_token`;CREATE TABLE `oauth_refresh_token` ( `token_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `token` blob NULL, `authentication` blob NULL) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; 1.9.3.2 Step2：添加POM配置123456789101112131415161718192021&lt;!--安全验证相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;2.0.14.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-jwt&lt;/artifactId&gt;&lt;/dependency&gt; 1.9.3.3 Step3：配置数据源在采用数据库存储的Oauth认证信息时需要使用数据源访问数据库。需要在application-dev.properties 文件中增加以下配置。 123456789101112131415161718192021222324#DataSourcespring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.driver-class-name = com.mysql.cj.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/splus?serverTimezone=Asia/Shanghai&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8spring.datasource.username = rootspring.datasource.password = root初始化大小，最小，最大spring.datasource.initialSize=5spring.datasource.minIdle=5spring.datasource.maxActive=20# 配置获取连接等待超时的时间spring.datasource.maxWait=60000# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.timeBetweenEvictionRunsMillis=60000# 配置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.minEvictableIdleTimeMillis=300000spring.datasource.validationQuery=SELECT 1 FROM DUALspring.datasource.testWhileIdle=truespring.datasource.testOnBorrow=falsespring.datasource.testOnReturn=false# 打开PSCache，并且指定每个连接上PSCache的大小spring.datasource.poolPreparedStatements=truespring.datasource.maxPoolPreparedStatementPerConnectionSize=20 同时还需要使用注解配置DataSource组件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214import com.alibaba.druid.pool.DruidDataSource;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import javax.sql.DataSource;import java.sql.SQLException;/** * DruidDataSourceConfig * Druid数据源管理配置类 * * @author: zone7 * @time: 2018.08.20 */@Configuration@ConfigurationProperties(prefix = "spring.datasource")public class DruidDataSourceConfig &#123; private String url; private String username; private String password; private String driverClassName; private int initialSize; private int minIdle; private int maxActive; private int maxWait; private int timeBetweenEvictionRunsMillis; private int minEvictableIdleTimeMillis; private String validationQuery; private boolean testWhileIdle; private boolean testOnBorrow; private boolean testOnReturn; private boolean poolPreparedStatements; private int maxPoolPreparedStatementPerConnectionSize; private String filters; private String connectionProperties; // 解决 spring.datasource.filters=stat,wall,log4j 无法正常注册 @Bean @Primary // 在同样的DataSource中，首先使用被标注的DataSource public DataSource dataSource() &#123; DruidDataSource datasource = new DruidDataSource(); datasource.setUrl(url); datasource.setUsername(username); datasource.setPassword(password); datasource.setDriverClassName(driverClassName); // configuration datasource.setInitialSize(initialSize); datasource.setMinIdle(minIdle); datasource.setMaxActive(maxActive); datasource.setMaxWait(maxWait); datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); datasource.setValidationQuery(validationQuery); datasource.setTestWhileIdle(testWhileIdle); datasource.setTestOnBorrow(testOnBorrow); datasource.setTestOnReturn(testOnReturn); datasource.setPoolPreparedStatements(poolPreparedStatements); datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); try &#123; datasource.setFilters(filters); &#125; catch (SQLException e) &#123; System.err.println("druid configuration initialization filter: " + e); &#125; datasource.setConnectionProperties(connectionProperties); return datasource; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getDriverClassName() &#123; return driverClassName; &#125; public void setDriverClassName(String driverClassName) &#123; this.driverClassName = driverClassName; &#125; public int getInitialSize() &#123; return initialSize; &#125; public void setInitialSize(int initialSize) &#123; this.initialSize = initialSize; &#125; public int getMinIdle() &#123; return minIdle; &#125; public void setMinIdle(int minIdle) &#123; this.minIdle = minIdle; &#125; public int getMaxActive() &#123; return maxActive; &#125; public void setMaxActive(int maxActive) &#123; this.maxActive = maxActive; &#125; public int getMaxWait() &#123; return maxWait; &#125; public void setMaxWait(int maxWait) &#123; this.maxWait = maxWait; &#125; public int getTimeBetweenEvictionRunsMillis() &#123; return timeBetweenEvictionRunsMillis; &#125; public void setTimeBetweenEvictionRunsMillis(int timeBetweenEvictionRunsMillis) &#123; this.timeBetweenEvictionRunsMillis = timeBetweenEvictionRunsMillis; &#125; public int getMinEvictableIdleTimeMillis() &#123; return minEvictableIdleTimeMillis; &#125; public void setMinEvictableIdleTimeMillis(int minEvictableIdleTimeMillis) &#123; this.minEvictableIdleTimeMillis = minEvictableIdleTimeMillis; &#125; public String getValidationQuery() &#123; return validationQuery; &#125; public void setValidationQuery(String validationQuery) &#123; this.validationQuery = validationQuery; &#125; public boolean isTestWhileIdle() &#123; return testWhileIdle; &#125; public void setTestWhileIdle(boolean testWhileIdle) &#123; this.testWhileIdle = testWhileIdle; &#125; public boolean isTestOnBorrow() &#123; return testOnBorrow; &#125; public void setTestOnBorrow(boolean testOnBorrow) &#123; this.testOnBorrow = testOnBorrow; &#125; public boolean isTestOnReturn() &#123; return testOnReturn; &#125; public void setTestOnReturn(boolean testOnReturn) &#123; this.testOnReturn = testOnReturn; &#125; public boolean isPoolPreparedStatements() &#123; return poolPreparedStatements; &#125; public void setPoolPreparedStatements(boolean poolPreparedStatements) &#123; this.poolPreparedStatements = poolPreparedStatements; &#125; public int getMaxPoolPreparedStatementPerConnectionSize() &#123; return maxPoolPreparedStatementPerConnectionSize; &#125; public void setMaxPoolPreparedStatementPerConnectionSize(int maxPoolPreparedStatementPerConnectionSize) &#123; this.maxPoolPreparedStatementPerConnectionSize = maxPoolPreparedStatementPerConnectionSize; &#125; public String getFilters() &#123; return filters; &#125; public void setFilters(String filters) &#123; this.filters = filters; &#125; public String getConnectionProperties() &#123; return connectionProperties; &#125; public void setConnectionProperties(String connectionProperties) &#123; this.connectionProperties = connectionProperties; &#125;&#125; 1.9.3.4 Step4：新建Spring安全用户明细用户明细类必须继承org.springframework.security.core.userdetails.User 123456789101112131415161718192021222324252627import com.zone7.admin.sys.pojo.SysUser;import org.springframework.security.core.authority.SimpleGrantedAuthority;import org.springframework.security.core.userdetails.User;import java.util.Arrays;import java.util.Collections;import java.util.List;public class MyUserDetails extends User&#123; private static List grants = Arrays.asList(new SimpleGrantedAuthority("ROLE_ADMIN")); private UserDto user; public MyUserDetails(UserDto user) &#123; super(user.getUsername(), user.getPassword(), true, true, true, true, grants); this.user = user; &#125; public UserDto getUser() &#123; return user; &#125; public void setUser(UserDto user) &#123; this.user = user; &#125;&#125; 1.9.3.5 Step5：新建用户验证服务用于加载用户信息，当Oauth2.0的 authorization_code或者password授权模式的时候需要使用这个类验证用户信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import com.zone7.admin.sys.dto.MyUserDetails;import com.zone7.admin.sys.dto.UserDto;import com.zone7.admin.sys.pojo.SysUser;import com.zone7.admin.sys.service.SysUserService;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.security.core.GrantedAuthority;import org.springframework.security.core.authority.SimpleGrantedAuthority;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.core.userdetails.UsernameNotFoundException;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.List;/** * @ClassName: UserDetailsServiceImpl * @Description: TODO * @Author: zgq * @Date: 2019/6/19 21:16 * @Version: 1.0 */@Componentpublic class UserDetailsServiceImpl implements UserDetailsService &#123; @Autowired private SysUserService sysUserService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; SysUser user = sysUserService.findByKeyword(username); if(user==null)&#123; throw new UsernameNotFoundException("用户不存在!"); &#125;else&#123; return UserDetailConverter.convert(user); &#125; &#125; private static class UserDetailConverter &#123; static UserDetails convert(SysUser user) &#123; UserDto dto=new UserDto(); BeanUtils.copyProperties(user,dto); return new MyUserDetails(dto); &#125; &#125;&#125; 1.9.3.6 Step6：新增密钥编码解码器主要用于密码验证 1234567891011121314151617181920import com.zone7.admin.utils.SHA256Util;import org.springframework.security.crypto.password.PasswordEncoder;/** * 密钥编码器 * @Authod zone7 */public class Sha256PasswordEncoder implements PasswordEncoder &#123; @Override public String encode(CharSequence charSequence) &#123; return SHA256Util.getSHA256StrJava(charSequence.toString()); &#125; @Override public boolean matches(CharSequence charSequence, String s) &#123; return s.equals(SHA256Util.getSHA256StrJava(charSequence.toString())); &#125;&#125; 1.9.3.7 Step7：新增配置类 (1) Oauth2.0授权配置类AuthorizationServerConfigurerAdapter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package com.zone7.admin.config.oauth2;import com.zone7.admin.sys.service.impl.UserDetailsServiceImpl;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.core.annotation.Order;import org.springframework.http.HttpMethod;import org.springframework.security.authentication.AuthenticationManager;import org.springframework.security.config.annotation.authentication.configurers.ldap.LdapAuthenticationProviderConfigurer;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerSecurityConfigurer;import org.springframework.security.oauth2.provider.ClientDetailsService;import org.springframework.security.oauth2.provider.client.JdbcClientDetailsService;import org.springframework.security.oauth2.provider.token.DefaultTokenServices;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JdbcTokenStore;import javax.sql.DataSource;import java.util.concurrent.TimeUnit;/** * 授权服务配置 */@Configuration@EnableAuthorizationServer@Order(7)public class OAuth2ServerConfig extends AuthorizationServerConfigurerAdapter &#123; @Bean // 声明TokenStore实现 public TokenStore tokenStore() &#123; return new JdbcTokenStore(dataSource); &#125; @Bean // 声明 ClientDetails实现 public ClientDetailsService clientDetails() &#123; return new JdbcClientDetailsService(dataSource); &#125; /** * 注入authenticationManager * 来支持 password grant type */ @Autowired private AuthenticationManager authenticationManager; @Autowired private DataSource dataSource; @Autowired private TokenStore tokenStore; @Autowired private ClientDetailsService clientDetails; @Autowired private UserDetailsServiceImpl userDetailsService; @Bean @Primary public DefaultTokenServices tokenServices() &#123; DefaultTokenServices tokenServices = new DefaultTokenServices(); tokenServices.setSupportRefreshToken(true); tokenServices.setTokenStore(tokenStore); return tokenServices; &#125; @Override public void configure(AuthorizationServerSecurityConfigurer oauthServer) throws Exception &#123; oauthServer .passwordEncoder(new MyPasswordEncoder()) .tokenKeyAccess("permitAll()") //url:/oauth/token_key,exposes public key for token verification if using JWT tokens .checkTokenAccess("isAuthenticated()") //url:/oauth/check_token allow check token .allowFormAuthenticationForClients(); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; endpoints.authenticationManager(authenticationManager); endpoints.tokenStore(tokenStore()); endpoints.userDetailsService(userDetailsService); endpoints.setClientDetailsService(clientDetails); //配置TokenServices参数 DefaultTokenServices tokenServices = new DefaultTokenServices(); tokenServices.setTokenStore(endpoints.getTokenStore()); tokenServices.setSupportRefreshToken(true); tokenServices.setClientDetailsService(endpoints.getClientDetailsService()); tokenServices.setTokenEnhancer(endpoints.getTokenEnhancer()); tokenServices.setAccessTokenValiditySeconds((int) TimeUnit.DAYS.toSeconds(1)); // 1天 endpoints.tokenServices(tokenServices); &#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients.jdbc(dataSource).passwordEncoder(new MyPasswordEncoder()); &#125; &#125; (2) 资源配置类ResourceServerConfigurerAdapter 123456789101112131415161718192021222324252627import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer;import org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configurers.ResourceServerSecurityConfigurer;/** * 资源服务配置 */@Configuration@EnableResourceServerpublic class ResourceServerConfig extends ResourceServerConfigurerAdapter &#123; @Override public void configure(HttpSecurity http) throws Exception &#123; http.requestMatchers().antMatchers("/api/**") .and() .authorizeRequests().antMatchers("/api/**").authenticated(); &#125; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &#123; resources.resourceId("resourcesId").stateless(true); &#125; &#125; (3) WEB安全配置类WebSecurityConfigurerAdapter 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import com.zone7.admin.sys.service.impl.UserDetailsServiceImpl;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.core.annotation.Order;import org.springframework.security.authentication.AuthenticationManager;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.builders.WebSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, proxyTargetClass = true)@Order(100)public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable(); http.anonymous().disable(); http.requestMatchers().antMatchers("/oauth/**","/login/**","/logout/**") .and() .authorizeRequests() .antMatchers("/oauth/**","/login/**","/logout/**").authenticated() .and() .formLogin().permitAll(); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; //设置静态资源不要拦截 web.ignoring().antMatchers("/js/**","/cs/**","/images/**"); &#125; @Autowired private UserDetailsServiceImpl userDetailsService; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService(userDetailsService).passwordEncoder(new Sha256PasswordEncoder());// auth.inMemoryAuthentication().passwordEncoder(new Sha256PasswordEncoder())// .withUser("admin").password("123456").roles("ADMIN","USER").and()// .withUser("user").password("111").roles("USER"); &#125; /** * 需要配置这个支持password模式 support password grant type * @return * @throws Exception */ @Override @Bean public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125;&#125; 1.9.3.8 Step8：测试启动数据和应用程序，使用Postman首先添加一个http请求，请求地址为资源配置类中配置的路径，例如： 点击Get New Access Token 按钮。分别使用不同的授权模式测试授权服务器获取令牌的功能。 点击Request Token 得到Token]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
        <tag>oauth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.13 Springboot&VUE开发实践（SpringBoot用户权限）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.13SpringBoot%20%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.13 前端用户权限在用户登陆成功后将用户信息保存到session中，并在后续的访问过程中进行验证以及有针对用户和功能的权限过滤。 (1) 用户授权 123456789101112131415161718192021222324252627282930313233343536@ApiOperation(value = "登录接口", notes = "用户登录接口，登录之后才可访问其他接口")@RequestMapping(value = "/login",method = RequestMethod.POST)public ResponseData login(UserLoginVo userLoginVo, HttpSession session) &#123; String username = userLoginVo.getUsername(); String password = userLoginVo.getPassword(); SysUser sysUser = sysUserService.findByKeyword(username); if (StringUtils.isBlank(username)) &#123; return ResponseData.errorMessage("用户名不能为空"); &#125; else if (StringUtils.isBlank(password)) &#123; return ResponseData.errorMessage("登陆密码不能为空"); &#125; else if (sysUser == null) &#123; return ResponseData.errorMessage("查询不到指定用户"); &#125; else if (!sysUser.getPassword().equals(MD5Util.encode(password))) &#123; return ResponseData.errorMessage("用户名或密码错误"); &#125; else if (sysUser.getState() != 1) &#123; return ResponseData.errorMessage("用户已被冻结，请联系管理员"); &#125; else &#123; // LOGIN SUCCESS List&lt;SysRole&gt; roles = sysRoleUserService.getRoleListByUserId(sysUser.getId()); List&lt;SysAcl&gt; acls = sysCoreService.getAclListByUserId(sysUser.getId()); List&lt;SysAcl&gt; deniedAcls = sysCoreService.getDeniedAclListByUserId(sysUser.getId()); UserVo userVo = new UserVo(); BeanUtils.copyProperties(sysUser, userVo); userVo.setRoles(roles); userVo.setAcls(acls); userVo.setDeniedAcls(deniedAcls); session.setAttribute("user", userVo); &#125; Map&lt;String, String&gt; tokenMap = new HashMap&lt;String,String&gt;(); tokenMap.put("token", session.getId()); tokenMap.put("userId", sysUser.getId()); return ResponseData.success(tokenMap);&#125; (2) 安全过滤SpringBoot使用过滤器验证当前会话是否已经登陆过，并针对要访问的路径进行权限验证。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package com.zone7.admin.config.filter;import com.alibaba.fastjson.JSON;import com.google.common.collect.Sets;import com.zone7.admin.commons.response.ResponseCode;import com.zone7.admin.commons.response.ResponseData;import com.zone7.admin.sys.common.RequestHolder;import com.zone7.admin.sys.pojo.SysAcl;import com.zone7.admin.sys.vo.UserVo;import javax.servlet.*;import javax.servlet.annotation.WebFilter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.util.List;import java.util.Set;/** * RequestFilter * 请求过滤器 * 安全认证 * @author: zone7 * @time: 2019.02.19 */@WebFilter(filterName = "RequestFilter", urlPatterns = "/*")public class RequestFilter implements Filter &#123; private static Set&lt;String&gt; URL_WHITE_LIST = Sets.newHashSet(); @Override public void init(FilterConfig filterConfig) throws ServletException &#123; //忽略不过旅的路径 URL_WHITE_LIST.add("/unauth"); URL_WHITE_LIST.add("/login"); URL_WHITE_LIST.add("/static"); URL_WHITE_LIST.add("/actuator"); &#125; private boolean isWhiteUrl(String requestUrl)&#123; if (URL_WHITE_LIST.contains(requestUrl))&#123; return true; &#125; for(String str:URL_WHITE_LIST)&#123; if(requestUrl.startsWith(str))&#123; return true; &#125; &#125; return false; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; String requestUrl = request.getRequestURI(); if (isWhiteUrl(requestUrl)) &#123; filterChain.doFilter(servletRequest, servletResponse); return; &#125; UserVo userVo = (UserVo) request.getSession().getAttribute("user"); if (userVo == null) &#123; request.getRequestDispatcher("/unauth").forward(request, response); return; &#125; RequestHolder.add(userVo); RequestHolder.add(request); //如果有配置按钮权限，就验证，没有配置表示可以使用 //DeniedAcls为禁用的权限列表 List&lt;SysAcl&gt; acls = userVo.getDeniedAcls(); boolean hasPower=true; for(SysAcl acl:acls)&#123; if(acl.getUrl().equals(requestUrl) || ("/"+acl.getUrl()).equals(requestUrl))&#123; hasPower = false; break; &#125; &#125; if(!hasPower)&#123; ResponseData res = ResponseData.error(ResponseCode.ERROR_LOGIN_NOAUTH_ACL); String json = JSON.toJSONString(res); response.setCharacterEncoding("UTF-8"); response.setHeader("Content-type","application/json"); response.getWriter().println(json); response.getWriter().flush(); return; &#125; filterChain.doFilter(servletRequest, servletResponse); &#125; @Override public void destroy() &#123; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 Springboot&VUE开发实践（前后端整合开发）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%883%20%E5%89%8D%E5%90%8E%E7%AB%AF%E6%95%B4%E5%90%88%E5%BC%80%E5%8F%91%EF%BC%89%2F</url>
    <content type="text"><![CDATA[3 SpringBoot+VUE案例开发经过对SpringBoot及VUE的学习，我们已经对他们的开发流程有了一定的了解，我们将这两个框架进行整合，并实现一个简单的前后的开发案例“HelloWorld”。这个案例我们主要实现：（1）系统的登陆、退出；（2）用户的查询、新增、修改、删除。系统架构如下图所示： 从架构图中可以看到前端UI采用VUE框架开发， vue框架整合了mock、validator、vuex等组件。后端包括：控制层、业务服务层和数据访问层，基于SpringBoot2开发，控制层主要实现了rest的http服务以及权限控制；业务服务层主要用于实现业务逻辑，同时也具备了日志、事物、缓存等功能；数据访问层采用mybatis框架实现。本节案例开发采用mysql作为数据库。 3.1 后端开发3.1.1 创建工程后端框架采用SpringBoot2+mybatis+redis整合框架开发，可以参照我们在SpringBoot开发的第一个工程，我们创建一个helloworld的后端工程。结构如下： 3.1.2 工程配置SpringBoot工程的主要配置文件包括maven的POM文件和application.properties配置文件。 pom文件内容为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;helloworld&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0.1.RELEASE&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;commons-lang3.version&gt;3.8.1&lt;/commons-lang3.version&gt; &lt;commons-collections.version&gt;3.2.1&lt;/commons-collections.version&gt; &lt;redis.version&gt;2.9.0&lt;/redis.version&gt; &lt;fastjson.version&gt;1.2.21&lt;/fastjson.version&gt; &lt;swagger2.version&gt;2.2.2&lt;/swagger2.version&gt; &lt;oracle.version&gt;11.2.0.3&lt;/oracle.version&gt; &lt;mysql.version&gt;8.0.11&lt;/mysql.version&gt; &lt;druid-starte.version&gt;1.1.1&lt;/druid-starte.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.15&lt;/log4j.version&gt; &lt;net.minidev.json-smart.version&gt;2.2.1&lt;/net.minidev.json-smart.version&gt; &lt;net.minidev.asm.version&gt;1.0.2&lt;/net.minidev.asm.version&gt; &lt;httpclient.version&gt;4.5.2&lt;/httpclient.version&gt; &lt;shiro.version&gt;1.4.0&lt;/shiro.version&gt; &lt;shiro-redis.version&gt;3.1.0&lt;/shiro-redis.version&gt; &lt;mybatis-spring.version&gt;1.3.2&lt;/mybatis-spring.version&gt; &lt;mybatis-mapper.version&gt;3.4.0&lt;/mybatis-mapper.version&gt; &lt;mybatis-pagehelper.version&gt;1.2.10&lt;/mybatis-pagehelper.version&gt; &lt;guava.version&gt;18.0&lt;/guava.version&gt; &lt;jwt.verson&gt;0.9.0&lt;/jwt.verson&gt; &lt;docker.host&gt;http://127.0.0.1:2375&lt;/docker.host&gt; &lt;docker.repostory&gt;127.0.0.1:5000&lt;/docker.repostory&gt; &lt;docker.registry.name&gt;zone7&lt;/docker.registry.name&gt; &lt;docker.plugin.version&gt;0.4.13&lt;/docker.plugin.version&gt; &lt;skipDockerBuild&gt;false&lt;/skipDockerBuild&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 移除嵌入式tomcat插件，需要增加servlet-api，打包时打开注解 --&gt; &lt;!--&lt;exclusion&gt;--&gt; &lt;!--&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;--&gt; &lt;!--&lt;/exclusion&gt;--&gt; &lt;!-- 移除springboot自带的logback日志管理 --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 移除嵌入式tomcat插件，需要增加servlet-api，打包时打开注解 --&gt; &lt;!--&lt;dependency&gt;--&gt; &lt;!--&lt;groupId&gt;javax.servlet&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;--&gt; &lt;!--&lt;version&gt;3.1.0&lt;/version&gt;--&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;!--&lt;/dependency&gt;--&gt; &lt;!-- 引入依赖之后spring.aop.auto默认开启，不需要添加@EnableAspectJAutoProxy来启动 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--安全验证相关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;2.0.14.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-jwt&lt;/artifactId&gt; &lt;version&gt;1.0.10.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--解析JWT--&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;$&#123;jwt.verson&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 安全相关 --&gt; &lt;!-- log4j2日志管理 (springboot1.4以上不支持log4j) --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j2日志管理--&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.minidev&lt;/groupId&gt; &lt;artifactId&gt;json-smart&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.minidev&lt;/groupId&gt; &lt;artifactId&gt;asm&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit--&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;!-- mybatis通用mapper --&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-mapper.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis通用mapper --&gt; &lt;!-- mybatis pagehelper --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-pagehelper.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis pagehelper --&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;druid-starte.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;!--fastjson--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;$&#123;fastjson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--fastjson--&gt; &lt;!--oracle--&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt; &lt;version&gt;$&#123;oracle.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--oracle--&gt; &lt;!-- mysql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql --&gt; &lt;!--redis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--redis--&gt; &lt;!-- mongodb --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mongodb --&gt; &lt;!--swagger2--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger2.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger2.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger2--&gt; &lt;!--shiro--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--shiro redis支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.crazycake&lt;/groupId&gt; &lt;artifactId&gt;shiro-redis&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro-redis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--shiro--&gt; &lt;!--httpclient--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;$&#123;httpclient.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--httpclient--&gt; &lt;!-- 监控 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--guava--&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;$&#123;guava.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--guava--&gt; &lt;!-- rabbitmq --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- rabbitmq --&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;!--commons--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;$&#123;commons-lang3.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;$&#123;commons-collections.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;1.9.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--commons--&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.ezmorph&lt;/groupId&gt; &lt;artifactId&gt;ezmorph&lt;/artifactId&gt; &lt;version&gt;1.0.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 设置资源文件的编码方式 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.20.1&lt;/version&gt; &lt;configuration&gt; &lt;!-- 不指定单元测试 --&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;docker.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;push-image&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;imageName&gt;$&#123;docker.repostory&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;registryUrl&gt;$&#123;docker.repostory&#125;&lt;/registryUrl&gt; &lt;pushImage&gt;true&lt;/pushImage&gt; &lt;dockerHost&gt;$&#123;docker.host&#125;&lt;/dockerHost&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt; &lt;imageName&gt;$&#123;docker.repostory&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.properties配置文件，在这里我们将其配置为dev模式，同时在resources下增加一个application-dev.properties的配置文件，用于配置开发测试期间的参数。 文件application.properties 1spring.profiles.active=dev 文件application-dev.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#================== server ===================#server.port=8080#server.context-path=/springboot#================== mybatis =====================#mybatis.mapper-locations=classpath:mappers/**/*.xmlmybatis.configuration.map-underscore-to-camel-case=true#================ mybatis pagehelper ==============#pagehelper.helper-dialect=mysqlpagehelper.reasonable=truepagehelper.support-methods-arguments=truepagehelper.params=count=countSql#================== database ===================#spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/zone-demospring.datasource.username=rootspring.datasource.password=zgqspring.datasource.type=com.alibaba.druid.pool.DruidDataSource#初始化大小，最小，最大spring.datasource.initialSize=5spring.datasource.minIdle=5spring.datasource.maxActive=20# 配置获取连接等待超时的时间spring.datasource.maxWait=60000# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.timeBetweenEvictionRunsMillis=60000# 配置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.minEvictableIdleTimeMillis=300000spring.datasource.validationQuery=SELECT 1 FROM DUALspring.datasource.testWhileIdle=truespring.datasource.testOnBorrow=falsespring.datasource.testOnReturn=false# 打开PSCache，并且指定每个连接上PSCache的大小spring.datasource.poolPreparedStatements=true #================== redis ===================## redis 单节点地址spring.redis.host=localhost# redis 集群#spring.redis.cluster.nodes=192.168.177.128:7001,192.168.177.128:7002,192.168.177.128:7003#spring.redis.cluster.max-redirects=3# Redis 数据库spring.redis.database=0# Redis 端口spring.redis.port=6379# Redis 密码spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.jedis.pool.max-active=8 # 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.jedis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.jedis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.jedis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=3000#================== cache ===================#spring.cache.type=redis#================== RabbitMq ===================#spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=adminspring.rabbitmq.listener.concurrency=10spring.rabbitmq.listener.max-concurrency=20spring.rabbitmq.listener.prefetch=50#================== RabbitMq 队列配置 ===================#mq.env=localbasic.info.mq.exchange.name=$&#123;mq.env&#125;:basic:info:mq:exchangebasic.info.mq.routing.key.name=$&#123;mq.env&#125;:basic:info:mq:routing:keybasic.info.mq.queue.name=$&#123;mq.env&#125;:basic:info:mq:queue#================== mongoDB 配置 ===================#spring.data.mongodb.host=localhostspring.data.mongodb.port=27017spring.data.mongodb.database=test#================== slf4j日志配置 ===================## 路径logging.path=/Users/zgq/logslogging.file=helloworld.log#location of config file (default classpath:logback.xml for logback)#logging.config=# levels for loggers, e.g. &quot;logging.level.org.springframework=DEBUG&quot; (TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF)logging.level.com.zone7=INFO#================== 默认密码 ===================#system.default.password=123456#================== 监控 ===================##actuator端口management.server.port=8310#修改访问路径，2.0之前默认是/，2.0默认是/actuatormanagement.endpoints.web.base-path=/actuator#开放所有页面节点 ，默认只开启了health、info两个节点management.endpoints.web.exposure.include=*#显示健康具体信息，默认不会显示详细信息management.endpoint.health.show-details=always 3.1.3 代码开发3.1.3.1 用户安全验证首先我们沿用第一章的SpringBoot工程，在 “/src/main/java/com/zone7/demo/helloworld/config/filter”下新增加一个安全过滤器，在实际应用中可以采用Oauth2、SpringSecurity或者Shiro来实现，这里只使用了session保存用户状态，并通过一个Filter的实现类来获取用户是否处于登陆状态来控制系统的安全访问。代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.zone7.demo.helloworld.config.filter;import com.google.common.collect.Sets;import com.zone7.demo.helloworld.sys.common.RequestHolder;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import javax.servlet.*;import javax.servlet.annotation.WebFilter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.util.List;import java.util.Set;/** * RequestFilter * 请求过滤器 * 安全认证 * @author: zone7 * @time: 2019.02.19 */@WebFilter(filterName = "RequestFilter", urlPatterns = "/*")public class RequestFilter implements Filter &#123; private static Set&lt;String&gt; URL_WHITE_LIST = Sets.newHashSet(); @Override public void init(FilterConfig filterConfig) throws ServletException &#123; //忽略不过旅的路径 URL_WHITE_LIST.add("/unauth"); URL_WHITE_LIST.add("/login"); URL_WHITE_LIST.add("/logout"); URL_WHITE_LIST.add("/sys/unauth"); URL_WHITE_LIST.add("/sys/login"); URL_WHITE_LIST.add("/sys/logout"); URL_WHITE_LIST.add("/static"); URL_WHITE_LIST.add("/actuator"); URL_WHITE_LIST.add("/oauth");//oauth2.0默认接口 URL_WHITE_LIST.add("/api"); // 外部接口采用oauth进行权限验证 &#125; private boolean isWhiteUrl(String requestUrl)&#123; if (URL_WHITE_LIST.contains(requestUrl))&#123; return true; &#125; for(String str:URL_WHITE_LIST)&#123; if(requestUrl.startsWith(str))&#123; return true; &#125; &#125; return false; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; String requestUrl = request.getRequestURI(); if (isWhiteUrl(requestUrl)) &#123; filterChain.doFilter(servletRequest, servletResponse); return; &#125; SysUserVo userVo = (SysUserVo) request.getSession().getAttribute("user"); if (userVo == null) &#123; request.getRequestDispatcher("/unauth").forward(request, response); return; &#125; RequestHolder.add(userVo); RequestHolder.add(request); filterChain.doFilter(servletRequest, servletResponse); &#125; @Override public void destroy() &#123; &#125;&#125; 3.2 前端开发采用vue-cli 命令生成工程脚手架（创建命令：vue init webpack helloworld_web），前端工程的名称为“helloworld_web” 。采用IDEA工具打开工程，默认的结构如下图所示： 工程目录默认有了router、compotent、assets，我们还需要增加api、views、store、utils目录。api目录用于存放采用mock实现的前后端交互脚本，views用于存放功能页面vue模板，store用于存放采用vuex实现的状态管理功能，utils用于存放通用工具脚本。工程目录结构如下图所示：]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.14 Springboot&VUE开发实践（SpringBoot单元测试）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.14SpringBoot%20%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.14 单元测试1.14.1 配置修改配置文件pom.xml，一般使用idea新建一个SpringBoot web项目时，一般都会自动引入此依赖，如果没有，请手动添加依赖。 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 1.14.2 编写测试代码新建一个测试类，测试service中的两个方法 123456789101112131415161718192021222324252627282930313233343536373839package com.zone7.demo.helloworld;import com.zone7.demo.helloworld.sys.service.SysUserService;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.util.Assert;import java.util.List;@RunWith(SpringRunner.class)@SpringBootTestpublic class HelloworldApplicationTests &#123; @Autowired private SysUserService sysUserService; @Test public void testFindByName() &#123; List&lt;SysUserVo&gt; users = sysUserService.findByName("zone7"); System.out.println("查询到用户数："+users.size()); &#125; @Test public void testSave() &#123; SysUserVo user = new SysUserVo(); user.setName("testuser"); user.setPassword("123"); user.setPhone("111111111111"); sysUserService.save(user); List&lt;SysUserVo&gt; users = sysUserService.findByName("testuser"); Assert.notEmpty(users,"保存失败"); &#125;&#125; 代码中使用@Autowired引入你想测试的类，在测试方法上加@Test注解。 1.14.3 执行单元测试通过点击方法前的小标执行测试，操作如下图所示： 1.14.4 打包测试开发完成之后，有可能我们已经写了一百多个测试用例类，我并不能每个类都点击进去一个个执行，SpringBoot提供了打包测试的方式：用一个类，把所有的测试类整理进去，然后直接运行这个类，所有的测试类都会执行。 我这里建了两个测试类，分别是EntFileTest,EntFileTest2，现在我打包进TestSuits，让他们一次运行，代码如下： 123456789101112131415161718package com.zone7.demo.helloworld;import org.junit.runner.RunWith;import org.junit.runners.Suite; /** * Created by zone7 * Date 2019/6/2 * Description:打包测试 */@RunWith(Suite.class)@Suite.SuiteClasses(&#123;SysuserControllerTests.class,SysuserServiceTests.class&#125;)public class TestSuits &#123; //不用写代码，只需要类顶级注解即可&#125; 当一个测试类中有1个方法暂时不想测测试，想在打包测试过程中跳过该方法，怎么办？这里有一个忽略注解@Ignore(“not ready yet”)，写在方法上，可以忽略这个测试方法，写在类上，可以忽略这个类。 此时，运行打包测试类TestSuits，SysuserServiceTests.testFindByName()方法就会忽略执行。]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.15 Springboot&VUE开发实践（SpringBoot应用部署）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.15SpringBoot%20%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.15 打包部署1.15.1 Docker化部署随着系统数量越来越多、复杂度越来越高，传统的运维方式耗时耗力而且还容易出现故障。采用Docker化部署，为应用开发和运维带了了非常多的好处，可以简化配置、隔离应用、提升开发效率、让交付物标准化，为实现开发运维流水线管理提供了很好的基础。 (1) 环境准备安装过程这里不深入介绍，确认服务器上Docker 已启动，并且安装了docker仓库、开启了docker远程服务，通过docker –v 确认安装成功和当前版本。 安装docker私有仓库的过程如下： 123456&gt;docker pull registrydocker run -d -p 5000:5000 --restart=always -h registry \--name registry \-v /Users/zgq/docker/volumes/registry:/tmp/registry \registry 12&gt;docker exec -it registry sh #进入容器&gt; Ctrl-p Ctrl-q#退出 查看仓库内容 1&gt;curl -XGET http://IP:5000/v2/_catalog 确认服务器开启了远程服务 (a)Linux环境编辑docker.service：1vim /usr/lib/systemd/system/docker.service 添加下面参数： 1ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock \ 重启Docker： 123systemctl daemon-reload // 1，加载docker守护线程systemctl restart docker // 2，重启docker• (b)Mac环境安装socat：1brew install socat 启动： 1socat -d TCP-LISTEN:2375,range=127.0.0.1/32,reuseaddr,fork UNIX:/var/run/docker.sock docker远程服务的默认端口号为2375，可以在本机使用以下命令查看仓库的镜像： 1docker –H IP:2375 images (2)SpringBoo配置 Step1 : 配置POM文件* 默认情况下，Pom插件通过访问IP:2375来连接服务器上的docker，docker的镜像上传。我们需要修改POM文件，添加docker 插件来实现。以下例子仓库所在地址为本机。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;docker.host&gt;http://127.0.0.1:2375&lt;/docker.host&gt;&lt;docker.repostory&gt;127.0.0.1:5000&lt;/docker.repostory&gt;&lt;docker.registry.name&gt;zone7&lt;/docker.registry.name&gt;&lt;docker.plugin.version&gt;0.4.13&lt;/docker.plugin.version&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;docker.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;push-image&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;imageName&gt;$&#123;docker.repostory&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;registryUrl&gt;$&#123;docker.repostory&#125;&lt;/registryUrl&gt; &lt;pushImage&gt;true&lt;/pushImage&gt; &lt;dockerHost&gt;$&#123;docker.host&#125;&lt;/dockerHost&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt; &lt;imageName&gt;$&#123;docker.repostory&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt;&lt;/plugin&gt; Step2 : 配置Dockerfile文件 我们还需要在src/main/docker下创建Dockerfile文件，文件内容如下： 123456789101112FROM livingobjects/jre8VOLUME /tmpADD app.jar app.jarRUN echo &quot;export LC_ALL=zh_CN.UTF-8&quot; &gt;&gt; /etc/profileENV LANG=&quot;zh_CN.UTF-8&quot;#RUN apk add -U tzdata#RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime#RUN echo &apos;Asia/Shanghai&apos; &gt;/etc/timezoneENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]EXPOSE 8080 Step3：执行打包发布命令接下来我们在IDEA的控制台执行命令： 1mvn clean package docker:build 通过下面命令查看镜像是否发布成功。 1docker –H 127.0.0.1:2375 images 例如： Step4：启动Docker镜像运行容器 1docker run -d -p 8080:8080 127.0.0.1:5000/zone7/zone7-rule:2.0.3.RELEASE /bin/bash 查看启动日志 1docker logs -f -t --tail 100 65a9d1e9621f Step5：查看SpringBoot应用启动情况执行命令： 1docker exec –it /bin/bash 通过进程我们看到SpringBoot应用已经启动。 1.15.2 Web容器部署采用War方式部署需要先进行打包，然后再部署到Tomcat或者weblogic 等WEB容器，在IDEA环境下打War十分简单，操作如下图所示。 然后执行build artifacts即可 也可以使用Maven打包，只需要修改POM文件的package参数为war： 12 war 然后执行“mvn clean package” 命令即可。]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.4 Springboot&VUE开发实践（SpringBoot第一个工程）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.4SpringBoot%20%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%B7%A5%E7%A8%8B%20%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.4 第一个工程1.4.1 step1:创建springboot项目HelloWorld （1）打开File-&gt;New-&gt;Module…新建模块 （2）选择Spring Initializr ，注意SDK使用1.8，点击Next （3）设置工程Group和Artifact，点击Next （4）添加Spring Web Starter依赖，点击Next （5）保存工程 （6）项目结构如下图所示： 1.4.2 Step2:理解工程结构创建完工程之后，我们可以看到工程目录中包含了一个完整的结构，比较重要的目录包括：src、test两个目录分别表示源代码和测试代码所在目录， src/main/java 为java代码路径，其中HelloworldApplication 是App 启动类。src/main/resources/application.properties 为工程配置文件，大多数情况下工程只需要一个配置文件即可。另外，在根目录下我们看到一个pom.xml ，这个文件是maven工程的重要配置文件，主要用于配置工程信息、依赖包、构建插件等（关于Maven知识点可上网查资料，这里不作深入介绍）。我们认真查看一下pom文件有利于理解springBoot的依赖关系： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.zone7.demo&lt;/groupId&gt; &lt;artifactId&gt;helloworld&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;helloworld&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 从pom文件可确认我们的工程继承至spring-boot-starter-parent的版本号为：2.1.5.RELEASE，SpringBoot的主要依赖包为：spring-boot-starter-web 1.4.3 Step3:配置工程 （1）打开配置文件application.properties，Springboot也兼容application.yml录入： **spring.profiles.active=dev**spring.profiles.active=dev表示运行模式为开发模式，系统将使用application-dev.properties配置文件。 （2）在src/main/resources目录下新建application-dev.properties 配置文件，并添加配置： **server.port=8080 #端口号为8080** 1.4.4 Step4:开发测试控制层在com.zone7.demo.helloworld 下创建包sys.controller，这里sys 表示子系统子模块的名称，在实际项目中可以根据功能模块划分包结构。在controller包中新建TestController类。 编写测试代码： 123456789101112131415161718192021package com.zone7.demo.helloworld.sys.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; /** * @Author: zone7 * @Date: 2019/06/17 * @Version 1.0 */@RestController@RequestMapping("/test")public class TestController &#123; @GetMapping("/show/&#123;name&#125;") public String show(@PathVariable String name)&#123; return "hi, " +name +" , 你好！我是 zone7"; &#125; &#125; SpringBoot通过给类添加注解 @RestController 表示Java类为控制层类；通过给方法添加@GetMapping 、@PostMapping、@DeleteMapping、@PutMapping 等注解表示http协议的四个操作。也可以给类添加@RequestMapping注解，表示该类下面所有路径都是以该注解的路径开始。例如上例： @RequestMapping(“/test”)表示TestController类的所有方法对应的url都是以/test开始，show方法对应的url为： http://IP:PORT/test/show/{name}。Mapping注解中的参数{name} 可映射为方法入参。 1.4.5 Step5:运行工程 (1)java 运行HelloworldApplication (2)打开浏览器访问控制层，效果如下图所示： 1.4.6 总结通过第一个工程的学习，我们了解到Springboot的开发过程主要就是配置、开发、测试三个内容： （1） 配置 pom配置：通过添加依赖增加相关的组件功能。 application-dev.properties配置：默认情况下springboot的配置文件入口是application.yml 或者application.properties，这里我们对开发过程和生产过程的配置文件进行了分离，后续的案例开发也将延用这个模式。 注解配置：通过注解配置系统的安全过滤、日志过滤、全局异常等功能。 （2） 业务模块开发根据开发规范开发持久层、服务层、控制层（不同行业、不同团队制定的开发规范也许不同） （3） 测试]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.5 Springboot&VUE开发实践（SpringBoot 整合Mybatis）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.5SpringBoot%20%E6%95%B4%E5%90%88Mybatis%20%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.5 整合Mybatis1.5.1 配置工程SpringBoot2.* 整合Mybatis 总体工作流程为： (1)修改POM文件，添加Maven依赖 123456789101112131415161718192021222324252627282930313233343536373839&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatis --&gt;&lt;!-- mybatis通用mapper --&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-mapper.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatis通用mapper --&gt;&lt;!-- mybatis pagehelper分页支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-pagehelper.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatis pagehelper --&gt;&lt;!—阿里的druid 数据库连接池 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;druid-starte.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--druid--&gt;&lt;!— mysql驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql --&gt; (2)修改配置文件 application-dev.properties 1234567891011121314151617181920212223242526272829#================== mybatis =====================#mybatis.mapper-locations=classpath:mappers/**/*.xmlmybatis.configuration.map-underscore-to-camel-case=true#================ mybatis pagehelper 分页配置 ==============#pagehelper.helper-dialect=mysqlpagehelper.reasonable=truepagehelper.support-methods-arguments=truepagehelper.params=count=countSql#================== 数据源配置database ===================#spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/zone7-demospring.datasource.username=rootspring.datasource.password=zgqspring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.druid.initial-size=5spring.datasource.druid.min-idle=5spring.datasource.druid.max-active=20 spring.datasource.druid.max-wait=60000 spring.datasource.druid.time-between-eviction-runs-millis=60000 spring.datasource.druid.min-evictable-idle-time-millis=300000spring.datasource.druid.validation-query=&apos;select &apos;x&apos;spring.datasource.druid.test-while-idle=truespring.datasource.druid.test-on-borrow=falsespring.datasource.druid.test-on-return=false spring.datasource.druid.pool-prepared-statements=truespring.datasource.druid.max-pool-prepared-statement-per-connection-size=20 spring.datasource.druid.filters=stat,wall 1.5.2 创建数据库我们以mysql数据库为例，创建一个系统用户表。 1234567891011CREATE TABLE `zone7-demo`.`sys_user` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'id', `name` varchar(50) NOT NULL COMMENT '用户名', `password` varchar(255) COMMENT '密码', `phone` varchar(20) COMMENT '电话', `score` int(11) COMMENT '积分', `star` int(11) COMMENT '星级', `department` varchar(50) COMMENT '部门名称', PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_bin AUTO_INCREMENT=1000; 1.5.3 代码生成mybatis 代码生成方式可以使用命令行方式和IDE方式，我们可以采用IDE执行逆向生成。相关配置和生成代码步骤如下所示： (1) 在工程根目录新建专门用于逆袭工程相关的文件夹 (2) 配置Pom文件增加plugin 1234567891011121314&lt;!-- mybatis generator 自动生成代码插件 --&gt;&lt;plugin&gt;&lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;&lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;&lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt; $&#123;basedir&#125;/generator_tool/mybatis-generator-sys.xml &lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt;&lt;/plugin&gt; (3) 配置pom.xml中generator 插件所对应的配置文件${basedir}/generator_tool/mybatis-generator-sys.xml，详细配置说明可查看以下配置文件注释内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;!-- TODO: 1.数据库驱动包位置 --&gt; &lt;!-- 在MBG工作的时候，需要额外加载的依赖包，location属性指明加载jar/zip包的全路径 --&gt; &lt;classPathEntry location="/Users/zgq/IdeaProjects/demo/helloworld/generator_tool/libs/mysql-connector-java-8.0.11.jar"/&gt; &lt;!-- context:生成一组对象的环境 id:必选，上下文id，用于在生成错误时提示 defaultModelType:指定生成对象的样式 1，conditional：类似hierarchical； 2，flat：所有内容（主键，blob）等全部生成在一个对象中； 3，hierarchical：主键生成一个XXKey对象(key class)，Blob等单独生成一个对象，其他简单属性在一个对象中(record class) targetRuntime: 1，MyBatis3：默认的值，生成基于MyBatis3.x以上版本的内容，包括XXXBySample； 2，MyBatis3Simple：类似MyBatis3，只是不生成XXXBySample； introspectedColumnImpl：类全限定名，用于扩展MBG --&gt; &lt;context id="DB2Tables" targetRuntime="MyBatis3"&gt; &lt;!--是否使用Lombok标准生成实体类 需要开发自定义LombokPlugin ，暂时不用 --&gt; &lt;!--&lt;plugin type="org.mybatis.generator.plugins.LombokPlugin"&gt;--&gt; &lt;!--&lt;property name="hasLombok" value="true"/&gt;--&gt; &lt;!--&lt;/plugin&gt;--&gt; &lt;!--去掉生成类的注释--&gt; &lt;commentGenerator&gt; &lt;property name="suppressDate" value="true"/&gt; &lt;property name="suppressAllComments" value="true"/&gt; &lt;/commentGenerator&gt; &lt;!-- TODO: 2.数据库链接URL、用户名、密码 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost:3306/zone7-demo" userId="root" password="zgq"&gt; &lt;/jdbcConnection&gt; &lt;!-- java类型处理器 用于处理DB中的类型到Java中的类型，默认使用JavaTypeResolverDefaultImpl； 注意一点，默认会先尝试使用Integer，Long，Short等来对应DECIMAL和 NUMERIC数据类型； --&gt; &lt;javaTypeResolver type="org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl"&gt; &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型 false：默认, scale&gt;0;length&gt;18：使用BigDecimal; scale=0;length[10,18]：使用Long； scale=0;length[5,9]：使用Integer； scale=0;length&lt;5：使用Short； --&gt; &lt;property name="forceBigDecimals" value="false"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- TODO: 3.生成模型的包名和位置 --&gt; &lt;!-- java模型创建器，是必须要的元素 负责：1，key类（见context的defaultModelType）；2，java类；3，查询类 targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制； targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 --&gt; &lt;javaModelGenerator targetPackage="com.zone7.demo.helloworld.sys.pojo" targetProject="/Users/zgq/IdeaProjects/demo/helloworld/src/main/java"&gt; &lt;!-- for MyBatis3/MyBatis3Simple 自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； --&gt; &lt;property name="constructorBased" value="false"/&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- 设置一个根对象， 如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项 注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括： 1，属性名相同，类型相同，有相同的getter/setter方法； --&gt; &lt;!--&lt;property name="rootClass" value=""/&gt;--&gt; &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 --&gt; &lt;property name="trimStrings" value="true"/&gt; &lt;/javaModelGenerator&gt;&lt;!-- TODO: 4.生成的映射文件包名和位置 --&gt;&lt;!-- 这里的目标包和路径必须与application.properties配置的mybatis.mapper-locations=classpath:mappers/**/*.xml 一致，一般我们存放在resources/mappers目录下 --&gt;&lt;sqlMapGenerator targetPackage="mappers.sys" targetProject="/Users/zgq/IdeaProjects/demo/helloworld/src/main/resources"&gt; &lt;property name="enableSubPackages" value="true"/&gt;&lt;/sqlMapGenerator&gt; &lt;!-- TODO: 5.生成DAO的包名和位置 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.zone7.demo.helloworld.sys.dao" targetProject="/Users/zgq/IdeaProjects/demo/helloworld/src/main/java"&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;/javaClientGenerator&gt; &lt;!-- TODO: 6.要生成那些表(更改tableName和domainObjectName就可以) --&gt; &lt;table tableName="SYS_USER" domainObjectName="SysUser" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false"/&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; (4) 执行代码生成命令 首先打开Edit Configurations… , 执行RUN生成代码，也可以使用java 命令生成代码。 方式一、Java命令java -jar libs/mybatis-generator-core-1.3.5.jar -configfile mybatis-generator-rule.xml -overwrite 方式二、配置mvn命令 配置Command Line： mybatis-generator:generate -e 执行完生成代码效果如下： 1.5.4 案例开发以下部分以《用户管理模块》为例，开发持久层、服务层和控制层，并通过Postman测试。 1.5.4.1 增加配置类在包com.zone7.demo.helloworld.commons 中新增mapper包，并新建通用Mapper“BaseMapper.java”。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.zone7.demo.helloworld.commons.mapper;import tk.mybatis.mapper.common.Mapper;/** * BaseMapper * mybatis通用mapper * * @author: zone7 * @time: 2019.01.02 */public interface BaseMapper&lt;T&gt; extends Mapper&lt;T&gt; &#123;&#125;在com.zone7.demo.helloworld.config中新建mybatis包，并新增MyBatisMapperScannerConfig.java 作为扫描类。package com.zone7.demo.helloworld.config.mybatis;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import tk.mybatis.spring.mapper.MapperScannerConfigurer;import java.util.Properties;/** * MyBatisMapperScannerConfig * mybatis mapper扫描配置 * * @author: zone7 * @time: 2019.01.02 */@Configurationpublic class MyBatisMapperScannerConfig &#123; /** * 配置mybatis通用mapper * * @return */ @Bean public MapperScannerConfigurer mapperScannerConfigurer() &#123; MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer(); mapperScannerConfigurer.setSqlSessionFactoryBeanName("sqlSessionFactory"); //扫描该路径下的mapper mapperScannerConfigurer.setBasePackage("com.zone7.demo.helloworld.sys.dao, com.zone7.demo.helloworld.*.dao"); Properties properties = new Properties(); //通用mapper properties.setProperty("mappers", "com.zone7.demo.helloworld.commons.mapper.BaseMapper"); properties.setProperty("notEmpty", "false"); mapperScannerConfigurer.setProperties(properties); return mapperScannerConfigurer; &#125;&#125; 代码中mapperScannerConfigurer.setBasePackage(“com.zone7.demo.helloworld.sys.dao, com.zone7.demo.helloworld..dao”)的参数为需要扫描的mapper所在的包名，可以使用 作为通配符。 1.5.4.2 持久层开发 (1)修改SysUser.java 添加注解@Builder 12345678910111213141516171819202122232425262728import lombok.Builder;import lombok.Getter;import lombok.Setter;import lombok.ToString;/*** Created by Mybatis Generator 2019/06/18*/@Builder@Getter@Setter@ToStringpublic class SysUser &#123; private Integer id; private String name; private String password; private String phone; private Integer score; private Integer star; private String department;&#125; (2)修改SysUserMapper.java 添加函数SysUser findByName(String name); 12345678910111213141516171819202122232425262728293031package com.zone7.demo.helloworld.sys.dao;import com.zone7.demo.helloworld.sys.pojo.SysUser;import java.util.List;/*** Created by Mybatis Generator 2019/06/18*/public interface SysUserMapper &#123; int deleteByPrimaryKey(Integer id); int insert(SysUser entity); int insertSelective(SysUser entity); SysUser selectByPrimaryKey(Integer id); int updateByPrimaryKeySelective(SysUser entity); int updateByPrimaryKey(SysUser entity); /** * 根据用户名查询 * @param name * @return */ List&lt;SysUser&gt; findByName(String name);&#125; (3)修改SysUserMapper.xml 文件，增加findByName 123456&lt;select id="findByName" resultMap="BaseResultMap"&gt; select &lt;include refid="Base_Column_List" /&gt; from SYS_USERS where name like #&#123;name&#125;&lt;/select&gt; 1.5.4.3 服务层开发 (1)添加vo类新增com.zone7.demo.helloworld.sys.vo 包，接口传输对象统一放到vo包中。开发过程中可以拷贝实体类并修改细节，例如拷贝SysUser对象到vo包并改名为SysUserVo ， 并给类增加可序列化接口：public class SysUserVo implements Serializable 123456789101112131415161718192021222324252627282930package com.zone7.demo.helloworld.sys.vo;import lombok.Getter;import lombok.Setter;import lombok.ToString;import java.io.Serializable;/*** Created by Mybatis Generator 2019/06/18*/@Getter@Setter@ToStringpublic class SysUserVo implements Serializable&#123; private Integer id; private String name; private String password; private String phone; private Integer score; private Integer star; private String department;&#125; (2)开发服务层代码新增com.zone7.demo.helloworld.sys.service包和com.zone7.demo.helloworld.sys.service.impl包,用于存放服务层的接口和实现类。将服务层划分为接口和实现类有利于提高系统的可扩展性。在示例里我们准备实现用户的增删改查操作，接口如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.zone7.demo.helloworld.sys.service;import com.zone7.demo.helloworld.sys.pojo.SysUser;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import java.util.List;/** * SysUserService * * @author: zone7 * @time: 2019.02.17 */public interface SysUserService &#123; /** * 保存 * @param userVo */ void save(SysUserVo userVo); /** * 修改 * @param userVo */ void update(SysUserVo userVo); /** * 根据用户ID查找 * @param id * @return */ SysUserVo findByKeyword(String id); /** * 根据用户名模糊查找 * @param name * @return */ List&lt;SysUserVo&gt; findByName(String name); /** * 加载所有用户 * @return */ List&lt;SysUserVo&gt; findAll(); /** * 删除用户 * @param id */ void delete(String id);&#125; 实现类的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120package com.zone7.demo.helloworld.sys.service.impl;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import com.zone7.demo.helloworld.commons.exception.AddOPException;import com.zone7.demo.helloworld.commons.exception.DeleteOPException;import com.zone7.demo.helloworld.commons.exception.UpdateOPException;import com.zone7.demo.helloworld.commons.mapper.PageModel;import com.zone7.demo.helloworld.sys.dao.SysUserMapper;import com.zone7.demo.helloworld.sys.pojo.SysUser;import com.zone7.demo.helloworld.sys.service.SysUserService;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import com.zone7.demo.helloworld.utils.MD5Util;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import java.util.ArrayList;import java.util.Date;import java.util.List;import java.util.Set;import java.util.stream.Collectors;/** * SysUserServiceImpl * 用户管理 * @author: zone7 * @time: 2019.02.17 */@Servicepublic class SysUserServiceImpl implements SysUserService &#123; @Value("$&#123;system.default.password&#125;") private String defaultPassword; @Autowired private SysUserMapper sysUserMapper; @Override @Transactional(rollbackFor = AddOPException.class) public void save(SysUserVo userVo) &#123; try &#123; String password = defaultPassword; String md5Password = MD5Util.encode(password); SysUser sysUser = SysUser.builder() .name(userVo.getName()).password(md5Password) .phone(userVo.getPhone()) .department(userVo.getDepartment()) .build(); // 存储用户信息 sysUserMapper.insertSelective(sysUser); &#125; catch (Exception e) &#123; throw new AddOPException("新增用户操作出错，错误原因: " + e.getMessage()); &#125; &#125; @Override @Transactional(rollbackFor = UpdateOPException.class) public void update(SysUserVo userVo) &#123; try &#123; SysUser after = SysUser.builder() .id(userVo.getId()) .name(userVo.getName()) .phone(userVo.getPhone()) .department(userVo.getDepartment()).build(); sysUserMapper.updateByPrimaryKeySelective(after); &#125; catch (Exception e) &#123; throw new UpdateOPException("更新用户操作出错，错误原因: " + e.getMessage()); &#125; &#125; @Override public SysUserVo findById(Integer id) &#123; SysUser user = sysUserMapper.selectByPrimaryKey(id); SysUserVo vo=new SysUserVo(); BeanUtils.copyProperties(user,vo); return vo; &#125; @Override public List&lt;SysUserVo&gt; findByName( String name) &#123; List&lt;SysUser&gt; users = sysUserMapper.findByName(name); List&lt;SysUserVo&gt; userList = new ArrayList&lt;SysUserVo&gt;(); users.forEach(sysUser -&gt; &#123; // 查询角色信息 SysUserVo vo=new SysUserVo(); BeanUtils.copyProperties(sysUser,vo); userList.add(vo); &#125;); return userList; &#125; @Override @Transactional(rollbackFor = DeleteOPException.class) public void delete(Integer id) &#123; try &#123; sysUserMapper.deleteByPrimaryKey(id); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new DeleteOPException("删除用户操作出错，错误原因: " + e.getMessage()); &#125; &#125;&#125; 值得注意的是，代码中的方法采用了注解@Transactional, 例如：@Transactional(rollbackFor = AddOPException.class)表示事务控制当方法抛出AddOPException异常时进行事务回滚。 1.5.4.4 控制层开发在第一个工程中我们已经介绍了控制层的开发，这个部分我们将新增用户管理模块的控制层代码，并调用服务层的功能。控制层代码我们统一放在模块的controller包下面。控制层代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.zone7.demo.helloworld.sys.controller;import com.zone7.demo.helloworld.commons.response.ResponseData;import com.zone7.demo.helloworld.sys.service.SysUserService;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import java.util.List;/** * SysUserController * 用户管理 * @author: zone7 * @time: 2019.02.17 */@RestController@RequestMapping("/sys/user")public class SysUserController &#123; @Autowired private SysUserService sysUserService; /** * 保存 * @param userVo * @return */ @RequestMapping("/save") public ResponseData save(SysUserVo userVo) &#123; sysUserService.save(userVo); return ResponseData.successMessage("新增用户成功"); &#125; /** * 更新 * @param userVo * @return */ @RequestMapping("/update") public ResponseData updateDept(SysUserVo userVo) &#123; sysUserService.update(userVo); return ResponseData.successMessage("更新用户成功"); &#125; /** * 查找 * @param name * @return */ @RequestMapping("/findByName") public ResponseData findByName(@RequestParam(value = "name") String name) &#123; List&lt;SysUserVo&gt; result = sysUserService.findByName(name); return ResponseData.success(result); &#125; /** * 删除 * @param id * @return */ @RequestMapping("/delete") public ResponseData delete(Integer id) &#123; sysUserService.delete(id); return ResponseData.successMessage("删除用户成功"); &#125;&#125; 1.5.4.5 测试在IDEA中运行HelloworldApplication类 可以看到系统启动端口是8080，与application.properties配置的一致。接下来可打开Postman （postman是web开发常用的测试工具）测试新增用户、修改用户、查询用户、删除用户四个功能。 查询刚才新增加的用户： 修改用户 删除用户 至此SpringBoot完成了与Mybatis的整合工作。]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.8 Springboot&VUE开发实践（SpringBoot整合MongoDB）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.8SpringBoot%20%E6%95%B4%E5%90%88MongoDB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.8 整合MongoDB1.8.1 MongoDB简介MongoDB（来自于英文单词“Humongous”，中文含义为“庞大”）是可以应用于各种规模的企业、各个行业以及各类应用程序的开源数据库。基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB是一个高性能，开源，无模式的文档型数据库，是当前NoSql数据库中比较热门的一种。MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bjson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。传统的关系数据库一般由数据库（database）、表（table）、记录（record）三个层次概念组成，MongoDB是由数据库（database）、集合（collection）、文档对象（document）三个层次组成。MongoDB对于关系型数据库里的表，但是集合中没有列、行和关系概念，这体现了模式自由的特点。MongoDB 在实际应用中我们最常用到的是collection和gridFS两个功能，collection一般用于存储bjson数据，gridFS用于存储文件。 1.8.2 配置工程在pox.xml文件中添加spring-boot-starter-data-mongodb引用 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; application-dev.properties 增加mongoDB配置 12345#================== mongoDB 配置 ===================#spring.data.mongodb.host=localhostspring.data.mongodb.port=27017spring.data.mongodb.database=test 开发机遇注解的配置类 12345678910111213141516171819202122232425262728package com.zone7.demo.helloworld.config.mongodb;import com.mongodb.client.gridfs.GridFSBucket;import com.mongodb.client.gridfs.GridFSBuckets;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.mongodb.MongoDbFactory;/** * MongoDB配置类 * * @author zone7 * @date 2019/5/7 */@Configurationpublic class MongoDbConfig &#123; @Autowired private MongoDbFactory mongoDbFactory; @Bean public GridFSBucket gridFSBucket() &#123; return GridFSBuckets.create(mongoDbFactory.getDb()); &#125;&#125; 1.8.3 案例开发开发服务层代码，代码中引入三个对象，分别是 MongoTemplate 、GridFsTemplate、GridFSBucket，MongoTemplate主要用于操作mongodb的collection，GridFsTemplate和GridFSBucket主要操作mongodb的GridFS文件系统; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179package com.zone7.demo.helloworld.sys.service.impl;import com.mongodb.client.gridfs.GridFSBucket;import com.mongodb.client.gridfs.GridFSDownloadStream;import com.mongodb.client.gridfs.model.GridFSFile;import com.zone7.demo.helloworld.config.exception.GlobalException;import com.zone7.demo.helloworld.sys.pojo.SysUser;import org.bson.types.ObjectId;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.mongodb.core.MongoTemplate;import org.springframework.data.mongodb.core.query.Criteria;import org.springframework.data.mongodb.core.query.Query;import org.springframework.data.mongodb.core.query.Update;import org.springframework.data.mongodb.gridfs.GridFsResource;import org.springframework.data.mongodb.gridfs.GridFsTemplate;import org.springframework.stereotype.Service;import org.springframework.util.StreamUtils;import java.io.ByteArrayInputStream;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;/** * 描述: * mongo * * @author zone7 * @date 2018/8/9 10:24 */@Servicepublic class MongoDBServiceImpl &#123; private static final Logger logger = LoggerFactory.getLogger(MongoDBServiceImpl.class); @Autowired private MongoTemplate mongoTemplate; @Autowired private GridFSBucket gridFSBucket; @Autowired private GridFsTemplate gridFsTemplate; /** * 保存对象 * * @param user * @return */ public void saveObj(SysUser user) &#123; logger.info("---------------------&gt;[MongoDB save start]"); mongoTemplate.save(user); &#125; /** * 查询所有 * * @return */ public List&lt;SysUser&gt; findAll() &#123; logger.info("---------------------&gt;[MongoDB find start]"); return mongoTemplate.findAll(SysUser.class); &#125; /*** * 根据id查询 * @param id * @return */ public SysUser getById(String id) &#123; logger.info("---------------------&gt;[MongoDB find start]"); Query query = new Query(Criteria.where("_id").is(id)); return mongoTemplate.findOne(query, SysUser.class); &#125; /** * 根据名称查询 * * @param username * @return */ public SysUser getBookByName(String username) &#123; logger.info("---------------------&gt;[MongoDB find start]"); Query query = new Query(Criteria.where("username").is(username)); return mongoTemplate.findOne(query, SysUser.class); &#125; /** * 更新对象 * * @param user * @return */ public void update(SysUser user) &#123; logger.info("---------------------&gt;[MongoDB update start]"); Query query = new Query(Criteria.where("_id").is(user.getId())); Update update = new Update().set("password", user.getPassword()) .set("name", user.getName()) .set("updateTime", new Date()); //updateFirst 更新查询返回结果集的第一条 mongoTemplate.updateFirst(query, update, SysUser.class); //updateMulti 更新查询返回结果集的全部// mongoTemplate.updateMulti(query,update,SysUser.class); //upsert 更新对象不存在则去添加// mongoTemplate.upsert(query,update,SysUser.class); &#125; /*** * 删除对象 * @param user * @return */ public void delete(SysUser user) &#123; logger.info("---------------------&gt;[MongoDB delete start]"); mongoTemplate.remove(user); &#125; /** * 根据id删除 * * @param id * @return */ public void deleteById(String id) &#123; logger.info("---------------------&gt;[MongoDB delete start]"); //findOne SysUser book = getById(id); //delete delete(book); &#125; /** * 保存文件 * @param input * @param name */ public String saveFile(byte[] input,String name)&#123; ObjectId objectId=gridFsTemplate.store(new ByteArrayInputStream(input) ,name); String s = objectId.toString(); return s; &#125; /** * 加载文件 * * @param id * @return */ public byte[] loadFile(String id) &#123; try &#123; Query query = Query.query(Criteria.where("_id").is(id)); GridFSFile gfsFile = gridFsTemplate.findOne(Query.query(Criteria.where("_id").is(id))); String filename = gfsFile.getFilename(); logger.info("加载mongodb gf 文件名："+filename); //打开流下载对象 GridFSDownloadStream downloadStream = gridFSBucket.openDownloadStream(gfsFile.getObjectId()); //获取流对象 GridFsResource gridFsResource = new GridFsResource(gfsFile, downloadStream); return StreamUtils.copyToByteArray(gridFsResource.getInputStream()); &#125;catch(IOException e)&#123; logger.error("读取mongodb文件错误",e); throw new GlobalException("读取mongodb文件错误",e); &#125; &#125;&#125; 开发一个控制层用于测试调用服务层。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.zone7.demo.helloworld.sys.controller;import com.zone7.demo.helloworld.commons.response.ResponseData;import com.zone7.demo.helloworld.sys.pojo.SysUser;import com.zone7.demo.helloworld.sys.service.MongoDBService;import com.zone7.demo.helloworld.sys.service.RabbitService;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.List;/** * * mongodb 测试Controller * @Author: zone7 * @Date: 2019/06/17 * @Version 1.0 */@RestController@RequestMapping("/mongo")public class MongoDBController &#123; @Autowired private MongoDBService mongoDBService; @RequestMapping(value = "/save",method = RequestMethod.POST) public ResponseData save(SysUserVo userVo)&#123; SysUser user = SysUser.builder().build(); BeanUtils.copyProperties(userVo,user); mongoDBService.saveObj(user); return ResponseData.successMessage("保存成功"); &#125; @RequestMapping(value = "/findAll" ) public ResponseData save()&#123; List&lt;SysUser&gt; users = mongoDBService.findAll(); return ResponseData.success(users); &#125; @RequestMapping(value = "/saveFile" ) public ResponseData saveFile(String content,String name)&#123; String id = mongoDBService.saveFile(content.getBytes(),name); return ResponseData.success(id); &#125; @RequestMapping(value = "/loadFile" ) public ResponseData loadFile( String id)&#123; byte[] content = mongoDBService.loadFile(id); return ResponseData.success(new String(content)); &#125;&#125; 接下来需要确保mongodb已经启动，然后启动工程，使用Postman进行测试：查看mongo数据库发现已经自动创建了一个collection并增加了一条信息：接着我们再继续测试剩下的几个接口：加载所有对象 保存文件，这里为了简化操作，使用字符串作为文件内容来进行测试。 文件保存成功，我们打开mongo客户端可以查看到数据库多了一个fs的buckets 最后我们再做一次加载文件测试]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.10 Springboot&VUE开发实践（SpringBoot异常处理）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.10SpringBoot%20%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.10 异常处理作为一个健壮的后端程序，必须要有健壮的返回信息，动不动就返回一个html页面内容是一种令人作呕的用户体验。通过全局异常处理可以确保不论正常或者异常都可以一统一的数据格式响应，同时也规范了异常处理机制。SpringBoot之需要采用注解@ExceptionHandler就可以实现全局的异常处理。首先我们需要定义一个状态返回码的类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * ResponseCode * 响应编码 * * @author: zone7 * @time: 2018.08.28 */public enum ResponseCode &#123; //响应成功编码 SUCCESS(200, "请求成功"), //响应错误编码 ERROR(40000, "请求错误"), ERROR_PARAM_ILLGAL(40001, "请求参数不合法"), ERROR_DATA_DUPLICATION(40002, "新增数据已存在"), ERROR_GET_NO_RESULT(40003, "查询结果为空"), ERROR_ADD_OP(40004, "新增操作异常"), ERROR_UPDATE_OP(40005, "更新操作异常"), ERROR_DELETE_OP(40006, "删除操作异常"), ERROR_RECOVER_OP(40007, "恢复操作异常"), ERROR_MODIFY_PASSWORD(40008, "修改密码操作异常"), ERROR_CONFIG(40009, "系统配置异常"), ERROR_LOGIN_NOAUTH(50000, "用户未登录，请登录后继续访问"), ERROR_LOGIN_NOAUTH_ACL(50001, "用户没有该功能权限"); private final int code; private final String desc; ResponseCode(int code, String desc) &#123; this.code = code; this.desc = desc; &#125; public int getCode() &#123; return code; &#125; public String getDesc() &#123; return desc; &#125;&#125; 接着我们需要统一定义一个响应类ResponseData作为所有接口的返回对象，所有控制层的返回值都必须是ResponseData类型，响应类的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * ResponseData * 通用服务端响应对象 * * @author: zone7 * @time: 2018.08.28 */@JsonSerialize(include = JsonSerialize.Inclusion.NON_NULL)public class ResponseData&lt;T&gt; implements Serializable &#123; /** * 响应编码 */ private int code; /** * 响应信息 */ private String message; /** * 响应数据 */ private T data; private ResponseData(int code) &#123; this.code = code; &#125; private ResponseData(int code, T data) &#123; this.code = code; this.data = data; &#125; private ResponseData(int code, String msg) &#123; this.code = code; this.message = msg; &#125; private ResponseData(int code, String msg, T data) &#123; this.code = code; this.message = msg; this.data = data; &#125; public boolean isSuccess() &#123; return this.code == ResponseCode.SUCCESS.getCode(); &#125; public int getCode() &#123; return code; &#125; public String getMessage() &#123; return message; &#125; public T getData() &#123; return data; &#125; /************************ 响应成功返回对象 ***************************/ public static &lt;T&gt; ResponseData&lt;T&gt; success() &#123; return new ResponseData&lt;T&gt;(ResponseCode.SUCCESS.getCode()); &#125; public static &lt;T&gt; ResponseData&lt;T&gt; success(T data) &#123; return new ResponseData&lt;T&gt;(ResponseCode.SUCCESS.getCode(), data); &#125; public static &lt;T&gt; ResponseData&lt;T&gt; success(String message, T data) &#123; return new ResponseData&lt;T&gt;(ResponseCode.SUCCESS.getCode(), message, data); &#125; public static &lt;T&gt; ResponseData&lt;T&gt; successMessage(String message) &#123; return new ResponseData&lt;T&gt;(ResponseCode.SUCCESS.getCode(), message); &#125; /************************ 响应成功返回对象 ***************************/ /************************ 响应错误异常返回对象 ***************************/ public static &lt;T&gt; ResponseData&lt;T&gt; error() &#123; return new ResponseData&lt;T&gt;(ResponseCode.ERROR.getCode(), ResponseCode.ERROR.getDesc()); &#125; public static &lt;T&gt; ResponseData&lt;T&gt; error(ResponseCode responseCode) &#123; return new ResponseData&lt;T&gt;(responseCode.getCode(), responseCode.getDesc()); &#125; public static &lt;T&gt; ResponseData&lt;T&gt; error(String message, T data) &#123; return new ResponseData&lt;T&gt;(ResponseCode.ERROR.getCode(), message, data); &#125; public static &lt;T&gt; ResponseData&lt;T&gt; errorMessage(String message) &#123; return new ResponseData&lt;T&gt;(ResponseCode.ERROR.getCode(), message); &#125; /************************ 响应错误异常返回对象 ***************************/ /************************ 响应其他异常返回对象 ***************************/ public static &lt;T&gt; ResponseData&lt;T&gt; error(int code, String message) &#123; return new ResponseData&lt;T&gt;(code, message); &#125; /************************ 响应其他异常返回对象 ***************************/&#125; 接着我们需要定义一个全局异常基类GlobalException，GlobalException继承自运行时异常，同时定义一堆继承自全局异常类的异常类，例如： 1234567891011121314151617181920212223242526272829303132/** * GlobalException * * @author: zone7 * @time: 2019.02.14 */@Datapublic class GlobalException extends RuntimeException &#123; private ResponseCode responseCode = ResponseCode.ERROR; public GlobalException() &#123; &#125; public GlobalException(String message) &#123; super(message); &#125; public GlobalException(String message, Throwable cause) &#123; super(message, cause); &#125; public GlobalException(Throwable cause) &#123; super(cause); &#125; protected GlobalException(String message, Throwable cause, boolean enableSuppression, boolean writableStackTrace) &#123; super(message, cause, enableSuppression, writableStackTrace); &#125;&#125; 最后，我们将使用注解@ControllerAdvice和@ExceptionHandler配置一个统一的异常处理类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * GlobalExceptionHandler * 全局异常处理器 * 当请求处理出现异常时，会根据异常处理器的配置顺序，依次尝试异常匹配和处理 * 自定义异常处理器需要继承GlobalException类 * * @author: zone7 * @time: 2019.02.14 */@ControllerAdvicepublic class GlobalExceptionHandler &#123; // TODO: 添加自定义的异常处理器 @ExceptionHandler(value = DeleteOPException.class) @ResponseBody public ResponseData deleteExceptionHandler(HttpServletRequest request, DeleteOPException e) throws Exception &#123; return ResponseData.error(e.getResponseCode().getCode(), e.getMessage()); &#125; @ExceptionHandler(value = NoResultException.class) @ResponseBody public ResponseData noResultExceptionHandler(HttpServletRequest request, NoResultException e) throws Exception &#123; return ResponseData.error(e.getResponseCode().getCode(), e.getMessage()); &#125; @ExceptionHandler(value = DuplicationException.class) @ResponseBody public ResponseData duplicationExeptionHandler(HttpServletRequest request, DuplicationException e) throws Exception &#123; return ResponseData.error(e.getResponseCode().getCode(), e.getMessage()); &#125; @ExceptionHandler(value = ParamException.class) @ResponseBody public ResponseData paramExeptionHandler(HttpServletRequest request, ParamException e) throws Exception &#123; return ResponseData.error(e.getResponseCode().getCode(), e.getMessage()); &#125; /** * 全局异常处理器 * * @param request * @param e * @return * @throws Exception */ @ExceptionHandler(value = GlobalException.class) @ResponseBody public ResponseData globalExceptionHandler(HttpServletRequest request, GlobalException e) throws Exception &#123; return ResponseData.error(e.getResponseCode().getCode(), e.getMessage()); &#125; /** * 默认异常处理器 * * @param request * @param e * @return * @throws Exception */ @ExceptionHandler(value = Exception.class) @ResponseBody public ResponseData exceptionHandler(HttpServletRequest request, Exception e) throws Exception &#123; String errorMsg = e.getMessage(); return ResponseData.errorMessage("[未知异常信息] " + errorMsg); &#125;&#125; 在统一一次处理类里面我们已经把所有自定义的异常和一些系统异常定义了处理方式，统一使用ResponseData返回错误信息，采用这种方式我们的前端或者客户端在访问接口过程中不论是否出现异常都可以得到相同的JSON格式返回。]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.2 Springboot&VUE开发实践（SpringBoot开发规范）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.2SpringBoot%20%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%20%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.2 SpringBoot开发规范1.2.1 开发规范的作用 开发规范是基于某种特定的开发语言和架构，进行开发的基本原则和推荐方式，在开发过程中有迷惑时进行参照的指南。 开发规范不同于编码规则，但一定要包含编码规则。 编码规范有以下几点意义： (1) 编码规范可以最大限度的提高团队开发的合作效率。 (2) 编码规范可以尽可能的减少一个软件的维护成本，并且几乎没有任何一个软件，在其整个生命周期中，均由最初的开发人员来维护 。 (3) 编码规范可以改善软件的可读性，可以让开发人员尽快而彻底地理解新的代码 (4) 规范性编码还可以让开发人员养成好的编码习惯，甚至锻炼出更加严谨的思维 本节关于开发规范的内容摘录自互联网上搜索到的经验，同时结合实际工作中的理解所整理，由于各个团队的开发制度或公司要求有所不同，开发规范不一定适用于所有团队，以下内容仅仅只是作为学习使用SpringBoot框架进行项目开发的参考。 1.2.2 代码仓库规范1.2.2.1 公共组件公共组件通常指Java库，提供特定问题的处理程序包。公共组件的命名规范为： (1) 分组编号：com.companyname.library 固定取值 (2) 组件名称：name name根据组件名称定义 (3) 组件版本：x.y.z x.y.z根据组件实际版本情况定义 1.2.2.2 服务组件服务组件通常指可以独立部署，运行，维护的服务程序包，应用组件的命名规范为： (1) 分组编号：com.companyname.server固定取值 (2) 组件名称：name name根据组件名称定义 (3) 组件版本：x.y.z x.y.z根据组件实际版本情况定义 1.2.2.3 开发环境 (1) 开发环境：JDK1.8+ (2) 开发工具：IntelliJ IDEA 2017（安装Lombok Plugin） (3) 构建工具：Maven3.x (4) 代码管理工具：Git /TortoiseGit，根据公司或者组织统一配置管理（有得公司使用SVN）。 本文所介绍的SpringBoot示例都是基于以下环境制作： 开发工具：IDEA可从官网下载https://www.jetbrains.com/idea/download/ JavaJDK版本号：1.8 MavenMaven版本号：3.5.2 1.2.3 工程结构规范一个工程对应代码仓库中的一个仓库，项目结构是指一个基于Maven创建的项目目录结构。公共组件项目，通常会创建一个Maven普通项目。服务组件项目，通常会创建一个Maven聚合项目，并在聚合项目目录下创建多个继承Maven聚合项目的Maven模块，它们一起作为服务组件项目的组成部分。 (1) 工程名称使用英文作为仓库、项目、项目根目录、包结构、配置文件、代码文件、组件（公共组件，服务组件）的名称。使用中文作为用于代码仓库描述、模块功能描述、类描述、方法描述等。 Maven工程的命名、版本以及描述信息如： (2) 模块命名模块名称：{项目名称}-{模块名称} 模块名称简洁体现职责 ，使用模块名字作为模块组件的名称。例如：系统管理模块名称：sys (3) 项目目录项目目录遵循Maven约定目录格式 (1) 源码目录指：{项目目录}/src/main/ (2) 打包定义目录：src/main/assembly (3) 代码目录：src/main/java (4) 资源目录：src/main/resources (5) 数据库脚本归档：/db (6) 内部依赖数据归档：/data (7) 文档目录：src/main/docs (8) 脚本目录：src/main/bin 1.2.4 编码规范1.2.4.1 包规范包规范一般包含以下部分，有的团队也在组织内部自定义一个适应于团队的包命名规范。 (1) 项目基本包：com.company.{项目英文名（较长时适当简化）}.{模块名（可选）} (2) config：配置类 (3) startup：与服务启动相关的类 (4) client：提供客户端实现的相关类 (5) common：公共类，定义常量类，通用组件 (6) entity: 数据库相关的实体类 ，有得使用pojo (7) model:数据模型类(参数模型，数据传输模型等) ，有的使用vo (8) controller:控制层接口 (9) service: 服务层 (10) dao：数据库访问层 (11) util： 工具类 1.2.4.2 日志记录系统统一使用SLF4j接口 1.2.4.3 异常处理一般情况下系统主要处理两类异常： (1) 运行时异常：通过参数检查等方式避免或抛出运行时异常，日志记录 (2) 检查异常：检查异常需要捕获，处理，日志记录在我们的示例工程代码里，我们定义了以下几个类别的业务异常： (1) AddOPException：增加操作异常 (2) ConfigException：配置异常 (3) DeleteOPException：删除操作异常 (4) DuplicationException：重复异常 (5) ModifyPasswordException：修改密码异常 (6) NoResultException： 没有结果异常 (7) ParamException：参数异常 (8) RecoverOPException：覆盖异常 (9) UpdateOPException：更新异常异常类一般为RuntimeException，源代代码如下所示：1234567891011121314151617181920212223242526272829303132333435363738package com.zone7.demo.helloworld.config.exception;import com.zone7.demo.helloworld.commons.response.ResponseCode;import lombok.Data;/** * GlobalException * * @author: zone7 * @time: 2019.02.14 */@Datapublic class GlobalException extends RuntimeException &#123; private ResponseCode responseCode = ResponseCode.ERROR; public GlobalException() &#123; &#125; public GlobalException(String message) &#123; super(message); &#125; public GlobalException(String message, Throwable cause) &#123; super(message, cause); &#125; public GlobalException(Throwable cause) &#123; super(cause); &#125; protected GlobalException(String message, Throwable cause, boolean enableSuppression, boolean writableStackTrace) &#123; super(message, cause, enableSuppression, writableStackTrace); &#125;&#125; 12345678910111213141516171819202122package com.zone7.demo.helloworld.commons.exception;import com.zone7.demo.helloworld.commons.response.ResponseCode;import com.zone7.demo.helloworld.config.exception.GlobalException;import lombok.Data;/** * ParamException * * @author: zone7 * @time: 2019.02.14 */@Datapublic class ParamException extends GlobalException &#123; private ResponseCode responseCode = ResponseCode.ERROR_PARAM_ILLGAL; public ParamException(String message) &#123; super(message); &#125;&#125; 1.2.4.4 接口定义 (1) 原则 接口地址定义表明用意 接口地址定义清晰，简洁，无歧义 同一个服务组件的接口定义具有一致性 (2) 格式 控制类的顶层地址格式:/{顶层分类名}，例如：/sys/user系统管理模块下用户管理相关的接口顶层地址 接口定义使用Swagger的API注解说明 标注完整的请求信息，请求方法，请求地址，参数可选性，接口描述 (3) 请求方式 GET URL-Params POST Form-Data POST RequestBody(JSON格式) POST Mulitpart (4) 响应方式 统一的响应模型 1.2.4.5 辅助工具- 字符串处理：apache common-lang3 - 时间日期处理：joda-time - JSON处理：Gson，Fastjson - 集合扩展工具：guava - 文件和流处理：commons-io - 编解码：commons-codec - 建议：尽可能使用开源组件1.2.4.6 代码注释代码注释是 (1) 类，接口，枚举顶层注释 (2) 接口方法注释 (3) 静态方法注释 (4) 公开方法注释 (5) 类的属性字段注释 (6) 常量注释 (7) 不限于以上 例如： 1.2.4.7 代码控制规范 (1) 拉取原则强制每日开始工作拉取，提交之前拉取。 (2) 提交原则 强制要求提交代码必须构建成功（编译，打包成功） 提交代码必须完整（例如：少提文件） 提交代码必须忽略到本地临时文件（例如：target, logs, .idea, *.iml,dist 等） 要求每完成一个功能就进行提交 每修改完一个Bug就进行提交 如有冲突，要求解决冲突完之后才可提交 建议每日结束工作提交 (3) 提交注释要求提交时使用中文填写注释，注释的内容必须反映本次提交变更情况注释描述内容需要添加前缀，前缀如下： [创建] 通常在项目创建时使用 [新增] [修改] [删除] [修复-number] 修复Bug使用，number是Bug编号 1.2.4.8 构建规范 (1) 公共组件构建规范 (1) 构建输出组件包 (2) 构建输出组件源码包 (3) 构建发布到公司私有仓库 (4) 服务组件构建规范 (5) 服务组件包命名：{组件名称}-{版本号}-bin.zip (6) 构建输出到工程根目录下的target/{组件名称}-{yyyyMMddHH}目录 1.2.5 测试规范在制定测试规范前，我们先了解下测试的概念。软件测试的对象包括软件需求、概要设计、详细设计、软件运行环境、可运行程序和软件源代码等。软件测试包括质量、人员、资源、技术和流程五大要素，以及测试覆盖率和测试效率两个目标。软件测试一般分为4个阶段：单元测试、集成测试、系统测试、验收测试。 (1) 单元测试：测试系统最小可验证单元，发现BUG，确保符合设计要求。单元测试可以通过编写测试代码实现单元测试，也可以使用postman、浏览器等工具测试开发完的模块功能。 (2) 集成测试：在单元测试的基础上，把软件单元按照软件概要设计规格说明的规格要求，组装成模块、子系统或系统的过程中各部分工作是否达到或实现相应技术指标及要求。集成测试是测试各个单元模块之间的接口，系统测试是测试整个系统的功能和性能； (3) 系统测试：将经过集成测试的软件，作为计算机系统的一部分，与系统中其他部分结合起来，在实际运行环境下进行一系列严格有效的测试，以发现软件潜在的问题，保证系统的正常运行。 (4) 验收测试：也称交付测试，是针对用户需求、业务流程进行的正式的测试，以确定系统是否满足验收标准，由用户、客户或其他授权机构决定是否接受系统。验收测试包括alpha测试和beta测试，alpha测试是由开发者进行的软件测试，beta测试是由用户在脱离开发环境下进行的软件测试。SpringBoot的测试需要在Pom 添加spring-boot-starter-test和Junit依赖。1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 测试类统一放在src/test目录下。]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.3 Springboot&VUE开发实践（SpringBoot注解）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.3SpringBoot%20%E6%B3%A8%E8%A7%A3%20%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.3 SpringBoot注解本节主要介绍常用的注解，想了解更多信息可参考官网文档：https://docs.spring.io/spring-boot/docs/2.2.x/reference/html/getting-started.html#getting-started 1.3.1 SpringBoot/Spring常用注解注解列表 1234567891011@SpringBootApplication：包含了@ComponentScan、@Configuration和@EnableAutoConfiguration注解。其中@ComponentScan让spring Boot扫描到Configuration类并把它加入到程序上下文。@Configuration 等同于spring的XML配置文件；使用Java代码可以检查类型安全。@EnableAutoConfiguration 自动配置。@ComponentScan 组件扫描，可自动发现和装配一些Bean。@Component可配合CommandLineRunner使用，在程序启动后执行一些基础任务。@RestController注解是@Controller和@ResponseBody的合集,表示这是个控制器bean,并且是将函数的返回值直 接填入HTTP响应体中,是REST风格的控制器。@Autowired自动导入。@PathVariable获取参数。@JsonBackReference解决嵌套外链问题。@RepositoryRestResourcepublic配合spring-boot-starter-data-rest使用。 注解详解 @SpringBootApplication：申明让spring boot自动给程序进行必要的配置，这个配置等同于：@Configuration ，@EnableAutoConfiguration 和 @ComponentScan 三个配置。 123456789101112package com.example.myproject;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication // same as @Configuration @EnableAutoConfiguration @ComponentScan public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args);&#125;&#125; @ResponseBody：表示该方法的返回结果直接写入HTTP response body中，一般在异步获取数据时使用，用于构建RESTful的api。在使用@RequestMapping后，返回值通常解析为跳转路径，加上@esponsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中。比如异步获取json数据，加上@Responsebody后，会直接返回json数据。该注解一般会配合@RequestMapping一起使用。示例代码： 123456@RequestMapping(“/test”)@ResponseBodypublic String test()&#123; return”ok”;&#125; @Controller：用于定义控制器类，在spring项目中由控制器负责将用户发来的URL请求转发到对应的服务接口（service层），一般这个注解在类中，通常方法需要配合注解@RequestMapping。示例代码： 12345678910111213@Controller@RequestMapping(“/demoInfo”)public class DemoController &#123; @Autowired private DemoInfoService demoInfoService; @RequestMapping("/hello") public String hello(Map&lt;String,Object&gt; map)&#123; System.out.println("DemoController.hello()"); map.put("hello","from TemplateController.helloHtml"); //会使用hello.html或者hello.ftl模板进行渲染显示. return"/hello"; &#125;&#125; @RestController：用于标注控制层组件(如struts中的action)，@ResponseBody和@Controller的合集。示例代码： 1234567891011package com.kfit.demo.web;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(“/demoInfo2”)publicclass DemoController2 &#123;@RequestMapping("/test")public String test()&#123; return "ok";&#125;&#125; @RequestMapping：提供路由信息，负责URL到Controller中的具体函数的映射。 @EnableAutoConfiguration：SpringBoot自动配置（auto-configuration）：尝试根据你添加的jar依赖自动配置你的Spring应用。例如，如果你的classpath下存在HSQLDB，并且你没有手动配置任何数据库连接beans，那么我们将自动配置一个内存型（in-memory）数据库”。你可以将@EnableAutoConfiguration或者@SpringBootApplication注解添加到一个@Configuration类上来选择自动配置。如果发现应用了你不想要的特定自动配置类，你可以使用@EnableAutoConfiguration注解的排除属性来禁用它们。 @ComponentScan：其实很简单，@ComponentScan主要就是定义扫描的路径从中找出标识了需要装配的类自动装配到spring的bean容器中,你一定都有用过@Controller，@Service，@Repository注解，查看其源码你会发现，他们中有一个共同的注解@Component，没错@ComponentScan注解默认就会装配标识了@Controller，@Service，@Repository，@Component注解的类到spring容器中。当然，这个的前提就是你需要在所扫描包下的类上引入注解。 @Configuration：相当于传统的xml配置文件，如果有些第三方库需要用到xml文件，建议仍然通过@Configuration类作为项目的配置主类——可以使用@ImportResource注解加载xml配置文件。 @Import：用来导入其他配置类。 @ImportResource：用来加载xml配置文件。 @Autowired：自动导入依赖的bean @Service：一般用于修饰service层的组件 @Repository：使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。 @Bean：用@Bean标注方法等价于XML中配置的bean。 @Value：注入Spring boot application.properties配置的属性的值。示例代码： 12@Value(value = “#&#123;message&#125;”)private String message; @Inject：等价于默认的@Autowired，只是没有required属性； @Component：泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 @Bean:相当于XML中的,放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理。 @AutoWired：自动导入依赖的bean。byType方式。把配置好的Bean拿来用，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。当加上（required=false）时，就算找不到bean也不报错。 @Qualifier：当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。@Qualifier限定描述符除了能根据名字进行注入，但能进行更细粒度的控制如何选择候选者，具体使用方式如下： 123@Autowired@Qualifier(value = “demoInfoService”)private DemoInfoService demoInfoService; @Resource(name=”name”,type=”type”)：没有括号内内容的话，默认byName。与@Autowired干类似的事。 1.3.2 JPA注解 @Entity： @Table(name=”“)： 表明这是一个实体类。一般用于jpa这两个注解一般一块使用，但是如果表名和实体类名相同的话，@Table可以省略 @MappedSuperClass:用在确定是父类的entity上。父类的属性子类可以继承。 @NoRepositoryBean:一般用作父类的repository，有这个注解，spring不会去实例化该repository。 @Column：如果字段名与列名相同，则可以省略。 @Id：表示该属性为主键。 @GeneratedValue(strategy = GenerationType.SEQUENCE,generator = “repair_seq”)：表示主键生成策略是sequence（可以为Auto、IDENTITY、native等，Auto表示可在多个数据库间切换），指定sequence的名字是repair_seq。 @SequenceGeneretor(name = “repair_seq”, sequenceName = “seq_repair”, allocationSize = 1)：name为sequence的名称，以便使用，sequenceName为数据库的sequence名称，两个名称可以一致。 @Transient：表示该属性并非一个到数据库表的字段的映射,ORM框架将忽略该属性。如果一个属性并非数据库表的字段映射,就务必将其标示为@Transient,否则,ORM框架默认其注解为@Basic。@Basic(fetch=FetchType.LAZY)：标记可以指定实体属性的加载方式 @JsonIgnore：作用是json序列化时将Java bean中的一些属性忽略掉,序列化和反序列化都受影响。 @JoinColumn（name=”loginId”）:一对一：本表中指向另一个表的外键。一对多：另一个表指向本表的外键。 @OneToOne、@OneToMany、@ManyToOne：对应hibernate配置文件中的一对一，一对多，多对一。 1.3.3 SpringMVC注解 @RequestMapping：@RequestMapping(“/path”)表示该控制器处理所有“/path”的UR L请求。RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。该注解有六个属性： params:指定request中必须包含某些参数值是，才让该方法处理。 headers:指定request中必须包含某些指定的header值，才能让该方法处理请求。 value:指定请求的实际地址，指定的地址可以是URI Template 模式 method:指定请求的method类型， GET、POST、PUT、DELETE等 consumes:指定处理请求的提交内容类型（Content-Type），如application/json,text/html; produces:指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回 @RequestParam：用在方法的参数前面。12345678@RequestParamString a =request.getParameter(“a”)。@PathVariable:路径变量。如： RequestMapping(“user/get/mac/&#123;macAddress&#125;”) public String getByMacAddress(@PathVariable String macAddress)&#123; //do something; &#125; 参数与大括号里的名字一样要相同。 1.3.4 全局异常处理注解 @ControllerAdvice：包含@Component。可以被扫描到。统一处理异常。 @ExceptionHandler（Exception.class）：用在方法上面表示遇到这个异常就执行以下方法。 1.3.5 SpringCloud注解 @EnableFeignClients 开启Spring Cloud Feign的支持 @EnableCircuitBreaker 开启断路器功能 @EnableDiscoveryClient 注册应用为Eureka客户端应用，以获得服务发现的能力。 @LoadBalanced 开启客户端负载均衡 @EnableScheduling @EnableEurekaServer 启动一个服务注册中心 @RunWith(SpringRunner.class) 引入Spring 对JUnit 4 的支持 @WebAppConfiguration 开启Web 应用的配置，用于模拟ServletContext @SpringCloudApplication @SpringCloudApplication注解的定义如下，包含服务发现及断路器的注解 123456789101112131415161718package org.springframework.cloud.client;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import java.lang.annotation.*;/*** @author zone7*/@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootApplication@EnableDiscoveryClient@EnableCircuitBreakerpublic @interface SpringCloudApplication &#123;&#125; @HystrixCommand：指定回调方法]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.7 Springboot&VUE开发实践（SpringBoot 整合RabbitMQ）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.7SpringBoot%20%E6%95%B4%E5%90%88RabbitMQ%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.7 整合RabbitMQ1.7.1 RabbitMQ简介AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。 AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。在开发过程中，我们需要了解RabbitMQ的消息交换类型（Exchange 类型）： Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。只说前三种模式。 (1) Direct模式 消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配 (2) Topic模式 topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“”。#匹配0个或多个单词，匹配一个单词。 (3) Fanout模式 每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。 1.7.2 配置工程Pom配置 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213application-dev.properties 配置#================== RabbitMq ===================#spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=admin#================== RabbitMq 队列配置 ===================#mq.env=localbasic.info.mq.exchange.name=$&#123;mq.env&#125;:sys:info:mq:exchangebasic.info.mq.routing.key.name=$&#123;mq.env&#125;:sys:info:mq:routing:keybasic.info.mq.queue.name=$&#123;mq.env&#125;:sys:info:mq:queue 创建RabbitmqConfig，在配置类中创建队列、交换机、路由及其绑定。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package com.zone7.demo.helloworld.config.rabbitmq;import com.zone7.demo.helloworld.sys.service.impl.CustomerMqServiceImpl;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.amqp.core.*;import org.springframework.amqp.rabbit.config.SimpleRabbitListenerContainerFactory;import org.springframework.amqp.rabbit.connection.CachingConnectionFactory;import org.springframework.amqp.rabbit.connection.ConnectionFactory;import org.springframework.amqp.rabbit.connection.CorrelationData;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer;import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.amqp.SimpleRabbitListenerContainerFactoryConfigurer;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.env.Environment;/** * RabbitMq配置类 * * @author wangsk * @date 2019/5/20 */@Configurationpublic class RabbitMqConfig &#123; private static final Logger log= LoggerFactory.getLogger(RabbitMqConfig.class); @Autowired private Environment env; @Autowired private CachingConnectionFactory connectionFactory; @Autowired private SimpleRabbitListenerContainerFactoryConfigurer factoryConfigurer; /** * 单一消费者 * @return */ @Bean(name = "singleListenerContainer") public SimpleRabbitListenerContainerFactory listenerContainer()&#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setMessageConverter(new Jackson2JsonMessageConverter()); factory.setConcurrentConsumers(1); factory.setMaxConcurrentConsumers(1); factory.setPrefetchCount(1); factory.setTxSize(1); return factory; &#125; /** * 多个消费者 * @return */ @Bean(name = "multiListenerContainer") public SimpleRabbitListenerContainerFactory multiListenerContainer()&#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factoryConfigurer.configure(factory,connectionFactory); factory.setMessageConverter(new Jackson2JsonMessageConverter()); factory.setAcknowledgeMode(AcknowledgeMode.NONE); factory.setConcurrentConsumers(env.getProperty("spring.rabbitmq.listener.concurrency",int.class)); factory.setMaxConcurrentConsumers(env.getProperty("spring.rabbitmq.listener.max-concurrency",int.class)); factory.setPrefetchCount(env.getProperty("spring.rabbitmq.listener.prefetch",int.class)); return factory; &#125; @Bean public RabbitTemplate rabbitTemplate()&#123; connectionFactory.setPublisherConfirms(true); connectionFactory.setPublisherReturns(true); RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMandatory(true); rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; log.info("消息发送成功:correlationData(&#123;&#125;),ack(&#123;&#125;),cause(&#123;&#125;)",correlationData,ack,cause); &#125; &#125;); rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; log.info("消息丢失:exchange(&#123;&#125;),route(&#123;&#125;),replyCode(&#123;&#125;),replyText(&#123;&#125;),message:&#123;&#125;",exchange,routingKey,replyCode,replyText,message); &#125; &#125;); return rabbitTemplate; &#125; //TODO：基本消息模型构建 @Bean public DirectExchange basicExchange()&#123; return new DirectExchange(env.getProperty("basic.info.mq.exchange.name"), true,false); &#125; @Bean(name = "basicQueue") public Queue basicQueue()&#123; return new Queue(env.getProperty("basic.info.mq.queue.name"), true); &#125; @Bean public Binding basicBinding()&#123; return BindingBuilder.bind(basicQueue()).to(basicExchange()).with(env.getProperty("basic.info.mq.routing.key.name")); &#125;&#125; 1.7.3 案例开发 (1) 创建服务层代码首先开发一个带有消息接收监听功能和消息发送功能的服务。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.zone7.demo.helloworld.sys.service.impl;import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.zone7.demo.helloworld.sys.service.RabbitService;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.amqp.core.Message;import org.springframework.amqp.core.MessageBuilder;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.rabbit.listener.api.ChannelAwareMessageListener;import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.core.env.Environment;import org.springframework.messaging.handler.annotation.Payload;import org.springframework.stereotype.Service;import java.nio.charset.Charset;import java.nio.charset.StandardCharsets;/** * 消息监听器以及发送服务 */@Servicepublic class RabbitServiceImpl implements RabbitService &#123; private static final Logger log= LoggerFactory.getLogger(RabbitServiceImpl.class); @Autowired private Environment env; @Autowired private RabbitTemplate rabbitTemplate; /** * 消息消费 * @param message */ @RabbitListener(queues = "$&#123;basic.info.mq.queue.name&#125;",containerFactory = "singleListenerContainer") public void consumeMessage(@Payload byte[] message)&#123; try &#123; //TODO：接收String String result=new String(message,"UTF-8"); log.info("接收String消息： &#123;&#125; ",result); &#125;catch (Exception e)&#123; log.error("监听消费消息 发生异常： ",e.fillInStackTrace()); &#125; &#125; /** * 消息发送 * @param message */ @Override public void sendMessage(String message) &#123; try &#123; log.info("待发送的消息： &#123;&#125; ",message); rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter()); rabbitTemplate.setExchange(env.getProperty("basic.info.mq.exchange.name")); rabbitTemplate.setRoutingKey(env.getProperty("basic.info.mq.routing.key.name")); Message msg= MessageBuilder.withBody(message.getBytes(Charset.forName("UTF-8"))).build(); rabbitTemplate.convertAndSend(msg); &#125;catch (Exception e)&#123; log.error("发送简单消息发生异常： ",e.fillInStackTrace()); &#125; &#125;&#125; (2) 创建控制层代码 12345678910111213141516171819202122232425262728package com.zone7.demo.helloworld.sys.controller;import com.zone7.demo.helloworld.commons.response.ResponseData;import com.zone7.demo.helloworld.sys.service.RabbitService;import com.zone7.demo.helloworld.sys.service.RedisService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;/** * @Author: zone7 * @Date: 2019/06/17 * @Version 1.0 */@RestController@RequestMapping("/rabbit")public class RabbitController &#123; @Autowired private RabbitService rabbitService; @GetMapping("/send/&#123;message&#125;") public ResponseData send(@PathVariable String message )&#123; rabbitService.sendMessage(message); return ResponseData.successMessage("发送消息： "+message+"成功"); &#125;&#125; (3) 测试效果确保Rabbit已经启动，启动工程后在浏览器中输入http://localhost:8080/rabbit/send/hello我们将会看到以下信息：同时查看控制台输出，确认消息发送成功并已经被消费。 通过rabbit监控网页http://localhost:15672/ 我们可看到队列、交换机、路由等信息。]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
        <tag>rabbit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.6 Springboot&VUE开发实践（SpringBoot 整合Redis）]]></title>
    <url>%2F2019%2F07%2F26%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.6SpringBoot%20%E6%95%B4%E5%90%88Redis%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.6 整合Redis1.6.1 Redis简介Redis 是一个完全开源免费的，遵守BSD协议的，具备高性能的key-value数据库。Redis缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 1.6.2 配置工程在Spring支持的Redis操作中提供有一个RedisTemplate处理类，利用这个类可以非常方便的实现Redis的各种基本操作。首先需要修改Pom 文件增加redis依赖： 1234567&lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--redis--&gt; 其次修改application-dev.properties配置文件（springboot的主要配置文件为application.yml或application.properties，这里我们以第一个工程的例子为基础进行介绍）。 123456789101112131415161718192021222324#================== redis ===================## redis 单节点地址spring.redis.host=localhost# redis 集群#spring.redis.cluster.nodes=192.168.177.128:7001,192.168.177.128:7002,192.168.177.128:7003#spring.redis.cluster.max-redirects=3# Redis 数据库spring.redis.database=0# Redis 端口spring.redis.port=6379# Redis 密码spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.jedis.pool.max-active=8 # 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.jedis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.jedis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.jedis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=3000# 其他redis配置可参考网络资源 添加注解配置类，主要用于配置RedisTemplate和CacheManager两个组件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.zone7.admin.config.redis;import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;import com.zone7.admin.utils.RedisUtil;import org.springframework.cache.CacheManager;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.cache.annotation.EnableCaching;import org.springframework.cache.interceptor.KeyGenerator;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializationContext;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;import java.lang.reflect.Method;import java.time.Duration;/** * RedisConfig * Redis配置类 * * @author: zone7 * @time: 2018.08.20 */@Configuration@EnableCachingpublic class RedisConfig extends CachingConfigurerSupport &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setConnectionFactory(factory); //key序列化方式 template.setKeySerializer(redisSerializer); //value序列化 template.setValueSerializer(jackson2JsonRedisSerializer); //value hashmap序列化 template.setHashValueSerializer(jackson2JsonRedisSerializer); return template; &#125; @Bean public CacheManager cacheManager(RedisConnectionFactory factory) &#123; RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); //解决查询缓存转换异常的问题 ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); // 配置序列化（解决乱码的问题）,过期时间30秒 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofSeconds(30)) .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer)) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer)) .disableCachingNullValues(); RedisCacheManager cacheManager = RedisCacheManager.builder(factory) .cacheDefaults(config) .build(); return cacheManager; &#125;&#125; 1.6.3 案例开发下面以RedisTemplate和StringRedisTemaplate的使用为例，介绍redis缓存的应用。RedisTemplate在使用时之需要使用@Autowired引入即可，例如： 12@AutowiredRedisTemplate redisTemplate; 这里我们通过开发一个服务层和控制层进行查看redis整合后的效果：服务层RedisServiceImpl.java 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.zone7.demo.helloworld.sys.service.impl;import com.zone7.demo.helloworld.sys.service.RedisService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;/** * @ClassName: RedisServiceImpl * @Description: redis 案例测试 * @Author: zgq * @Date: 2019/6/19 09:16 * @Version: 1.0 */@Servicepublic class RedisServiceImpl implements RedisService &#123; @Autowired private RedisTemplate redisTemplate; @Autowired private StringRedisTemplate stringRedisTemplate; /** * 写入 * @param key * @param value */ @Override public void put(String key, String value) &#123; //redisTemplate.opsForList().leftPush(key, value); stringRedisTemplate.opsForValue().set(key,value); &#125; /** * 读取 * @param key * @return */ @Override public String get(String key) &#123; return stringRedisTemplate.opsForValue().get(key); &#125;&#125;控制层RedisController.java代码：package com.zone7.demo.helloworld.sys.controller;import com.zone7.demo.helloworld.commons.response.ResponseData;import com.zone7.demo.helloworld.sys.service.RedisService;import com.zone7.demo.helloworld.sys.service.SysUserService;import com.zone7.demo.helloworld.sys.vo.SysUserVo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.List;/** * @Author: zone7 * @Date: 2019/06/17 * @Version 1.0 */@RestController@RequestMapping("/redis")public class RedisController &#123; @Autowired private RedisService redisService; @GetMapping("/put/&#123;key&#125;/&#123;value&#125;") public ResponseData put(@PathVariable String key,@PathVariable String value)&#123; redisService.put(key,value); return ResponseData.successMessage("put "+key+"成功"); &#125; @GetMapping("/get/&#123;key&#125;") @ResponseBody public ResponseData findByName(@PathVariable String key) &#123; String value = redisService.get(key); return ResponseData.success(value); &#125;&#125; 使用浏览器测试redis服务 的put： 使用浏览器测试redis服务的get： 通过redis-cli查看redis存储的内容：]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.1 Springboot&VUE开发实践（SpringBoot基础）]]></title>
    <url>%2F2019%2F07%2F25%2Fspringboot%2F2019-07-26-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%EF%BC%881.1SpringBoot%20%E5%9F%BA%E7%A1%80%20%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.1 SpringBoot 基础1.1.1 Spring框架介绍 Spring是一个开源Java轻量级框架。Spring是为了解决企业级应用开发的复杂性而创建的，使用Spring可以让简单的JavaBean实现之前只有EJB才能完成的事情。但是Spring不仅仅局限于服务器端开发，也为 Java应用提高了简单性、可测试性和松耦合性等。Spring已经集成了20多个模块，这些模块主要被分如下图所示的核心容器、数据访问/集成,、Web、AOP、工具、消息和测试等模块。Spring 框架如下图所示： (1) Core Container 核心容器核心部分分为4大块，spring-core, spring-beans, spring-context, spring-expression. 其中core和bean是整个框架的核心，提供了基础的DI（依赖注入）和IOC（控制反转）功能。 Context建立在core和beans模块之上，提供一种类似JNDI且以框架的方式来操作对象的方式。Context模块从beans模块继承它的功能同时增加了国际化支持，如资源绑定等，同时，Context模块也支持JavaEE功能，如EJB，JMX和基本的远程调用。ApplicationContext接口是context模块的焦点。expression是一种很强大的expression language，支持在运行时查询和操作对象的属性，我们会在后面的文章中举些例子来说明spring expression language的用法。 (2) AOP and instrumentationAop模块提供了面向切面编程的实现，和AspectJ集成。 (3) MessagingMessaging是spring4新增加的模块，包含了一部分主要的基于message的应用的实现。 (4) Data Access/IntegrationData access顾名思义，是spring对数据层提供的支持，是功能比较丰富的模块。提供了包括JDBC，事物，ORM，JMS等一系列实现。 (5) WebWeb模块主要提供面向web的一些实现，例如多文件上传，servlet监听器以及spring mvc方面的支持。 (6) TestTest模块主要是针对spring的各个模块做各种各样的测试，包括单元测试、集成测试等等。 1.1.2 SpringBoot框架介绍SpringBoot并非Spring官方的框架，而是由Pivotal 团队（这里就不介绍这个团队了）在Spring上二次开发并开源公布出来的一个比 Spring更为简化的开发的框架。简而言之，SpringBoot就是一个轻量级，简化配置和开发流程的web整合框架。我们在使用SpringBoot时只需要做相应的配置就可以用所有的Spring组件，不需要像SpringMVC那样手动写一堆xml配置。从本质上来说，Spring Boot就是Spring,它简化了很多开发者利用Spring框架进行开发时，都需要进行的配置。那么它到底有什么功能呢？与Spring相比又有什么优势呢？ 1.1.2.1 SpringBoot的核心功能 (1) 可独立运行Spring项目 SpringBoot 可以以jar包形式独立运行，运行一个Spring Boot项目只需要通过java -jar xx.jar来运行。 (2) 内嵌servlet容器 SpringBoot可以选择内嵌Tomcat、jetty或者Undertow,这样我们无须以war包形式部署项目。 (3) 提供starter简化Maven配置 Spring提供了一系列的start pom来简化Maven的依赖加载，例如，当你使用了spring-boot-starter-web，会自动加入如图5-1所示的依赖包。 (4) 自动装配Spring SpringBoot会根据在类路径中的jar包，类、为jar包里面的类自动配置Bean，这样会极大地减少我们要使用的配置。当然，SpringBoot只考虑大多数的开发场景，并不是所有的场景，若在实际开发中我们需要配置Bean，而SpringBoot灭有提供支持，则可以自定义自动配置。 (5) 准生产的应用监控 SpringBoot提供基于http ssh telnet对运行时的项目进行监控。 (6) 无代码生产和xml配置 SpringBoot不是借助与代码生成来实现的，而是通过条件注解来实现的，这是Spring4.x提供的新特性。 1.1.2.2 SpringBoot的优点 编码更简单SpringBoot采用 JavaConfig的方式，对Spring进行配置，并且提供了大量的注解，极大的提高了工作效率。 配置更简单SpringBoot提供许多默认配置，同时也支持自定义配置， SpringBoot项目只需一个配置文件：application.properties或者application.yml。不必担心查找配置错误的定位。 部署更简单SpringBoot内置了三种Servlet容器，Tomcat，Jetty,undertow.我们只需要一个Java的运行环境就可以跑SpringBoot的项目了，SpringBoot的项目可以打成一个jar包，然后通过Java -jar xxx.jar来运行（SpringBoot项目的入口是一个main方法，运行该方法即可）。 监控更简单SpringBoot提供了actuator包，可以使用它来对应用进行监控。主要提供功能有如下截图]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot&VUE开发实践（目录）]]></title>
    <url>%2F2019%2F07%2F25%2Fspringboot%2F2019-07-25-Springboot%26VUE%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[在工作中我们经常因为需要为开发一个后台管理系统或者业务系统，组建由前端开发人员和后端开发人员组成的开发团队，前后端开发人员负责前端页面开发、后端开发人员负责后端业务开发，并为前端暴露接口。然而有一些小项目比较小，团队人员不足的情况下，我们智能硬着头皮都做。以下内容主要介绍工作中大家用的比较多的Springboot 以及VUE框架，并结合DEMO介绍开发流程。其实Springboot、VUE可以整合的技术生态圈非常大，不能一一介绍，但只要掌握相关方法，再多的技术应用也都可以触类旁通。 目录1 SPRINGBOOT框架开发1.1 SPRINGBOOT 基础 1.1.1 Spring框架介绍 1.1.2 SpringBoot框架介绍 1.2 SPRINGBOOT开发规范 1.2.1 开发规范的作用 1.2.2 代码仓库规范 1.2.3 工程结构规范 1.2.4 编码规范 1.2.5 测试规范 1.3 SPRINGBOOT注解 1.3.1 SpringBoot/Spring常用注解 1.3.2 JPA注解 1.3.3 SpringMVC注解 1.3.4 全局异常处理注解 1.3.5 SpringCloud注解 1.4 第一个工程 1.4.1 step1:创建springboot项目HelloWorld 1.4.2 Step2:理解工程结构 1.4.3 Step3:配置工程 1.4.4 Step4:开发测试控制层 1.4.5 Step5:运行工程 1.4.6 总结 1.5 整合MYBATIS 1.5.1 配置工程 1.5.2 创建数据库 1.5.3 代码生成 1.5.4 案例开发 1.6 整合REDIS 1.6.1 Redis简介 1.6.2 配置工程 1.6.3 案例开发 1.7 整合RABBITMQ 1.7.1 RabbitMQ简介 1.7.2 配置工程 1.7.3 案例开发 1.8 整合MONGODB 1.8.1 MongoDB简介 1.8.2 配置工程 1.8.3 案例开发 1.9 整合OAUTH2.0 1.9.1 Oauth2.0介绍 1.9.2 Oauth2.0授权模式 1.9.3 SpringBoot整合Oauth2.0 和Spring Security 1.10 异常处理1.11 日志处理1.12 缓存处理 1.12.1 缓存配置 1.12.2 注解说明 1.12.3 缓存使用 1.13 前端用户权限1.14 单元测试 1.14.1 配置 1.14.2 编写测试代码 1.14.3 执行单元测试 1.14.4 打包测试 1.15 打包部署 1.15.1 Docker化部署 1.15.2 Web容器部署 2 前端开发框架VUE开发2.1 VUE简介2.2 安装及快速入门2.3 VUE项目目录说明2.4 VUE生命周期2.5 第一个工程3 SPRINGBOOT+VUE案例开发3.1 后端开发 3.1.1 创建工程 3.1.2 工程配置 3.1.3 代码开发 3.2 前端开发4 源代码下载]]></content>
      <categories>
        <category>Java</category>
        <category>springboot&amp;vue前后端开发</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>VUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps实践]]></title>
    <url>%2F2018%2F10%2F01%2Fdocker%2F2018-10-01-DevOps%E5%AE%9E%E8%B7%B51%2F</url>
    <content type="text"><![CDATA[随着软件业务复杂度增加，以及行业竞争日益激烈，无论是客户还是公司自身，都要求软件能快速发布，频繁修改，快速迭代，往往需要开发、测试和运维，三个团队之间需要紧密配合，沟通和交付耗费了大量的精力，团队之间的技术隔阂，阻碍了开发团队的生产力，成了企业亟待解决的难题。DevOps 是 Development和Operations的简称，是一种软件工程的模式，这种模式使得三个团队不再孤立，通过自动化技术将软件生命周期中的开发、测试、部署到运营的每一个过程整合成一套整体的解决方案，提高了生产效率。DevOps打通了开发、测试、运维等环节的的IT工具链，使得各个团队减少时间损耗，更加高效地协同工作。良好的闭环大大提高了软件研发的整体的产出。以下是DevOps能力图。 ##DevOps中包括版本控制&amp;协作开发工具、自动化构建和测试工具、持续集成&amp;交付工具、部署工具、维护工具、监控，警告&amp;分析工具等等，补充了一些国内的服务，可以让你更好的执行实施 DevOps 工作流。 版本控制&amp;协作开发：GitHub、GitLab、BitBucket、SubVersion、Coding、Bazaar 自动化构建和测试:Apache Ant、Maven 、Selenium、PyUnit、QUnit、JMeter、Gradle、PHPUnit、Nexus 持续集成&amp;交付:Jenkins、Capistrano、BuildBot、Fabric、Tinderbox、Travis CI、flow.ci Continuum、LuntBuild、CruiseControl、Integrity、Gump、Go 容器平台: Docker、Rocket、Ubuntu（LXC）、第三方厂商如（AWS/阿里云） 配置管理：Chef、Puppet、CFengine、Bash、Rudder、Powershell、RunDeck、Saltstack、Ansible 微服务平台：OpenShift、Cloud Foundry、Kubernetes、Mesosphere 服务开通：Puppet、Docker Swarm、Vagrant、Powershell、OpenStack Heat 日志管理：Logstash、CollectD、StatsD 监控，警告&amp;分析：Nagios、Ganglia、Sensu、zabbix、ICINGA、Graphite、Kibana]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简易流程控制框架]]></title>
    <url>%2F2018%2F08%2F04%2Fothers%2F2018-08-04-zone7-flow%E7%AE%80%E6%98%93%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[在工作流开发过程中经常会使用一些主流的工作流框架，这些框架是否强大灵活，但往往需要引入大量的资源，增加了工程的复杂度。简易工作流控制框架是一个可以独立嵌入到java工程或者与Spring整合的简易工作流程框架，可以适应一些只需要简单审核审批业务场景的开发，开发简单，极少的依赖，不对工程已有业务带来大影响。 项目依赖aspectjweaver、spring-core、spring-beans、spring-context使用说明###一、开发步骤1、添加依赖 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.zone7&lt;/groupId&gt; &lt;artifactId&gt;zone7-flow&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2、spring 配置文件 123456789101112131415161718192021&lt;!-- 流程管理.开始 --&gt;&lt;bean id="flowPersistance" class="com.github.zone7.admin.bean.FlowPersistanceImpl"&gt;&lt;/bean&gt; &lt;bean id="businessEventFactory" class="com.github.zone7.flow.spring.common.BusinessEventFactoryImpl"&gt;&lt;/bean&gt; &lt;bean id="taskService" class="com.github.zone7..flow.spring.service.impl.TaskServiceImpl"&gt; &lt;property name="flowPersistance" ref="flowPersistance"&gt;&lt;/property&gt; &lt;property name="businessEventFactory" ref="businessEventFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="flowAdvising" class="com.github.zone7.flow.spring.common.FlowAspect"&gt; &lt;property name="taskService" ref="taskService"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;aop:config&gt; &lt;aop:aspect ref="flowAdvising"&gt; &lt;aop:pointcut id="performance" expression="execution(* com.github.zone7.*.*.service.*.*(com.github.zone7.flow.spring.common.FlowAttribute,..)) and @annotation(flow) and args(attr,..)" /&gt; &lt;aop:around pointcut-ref="performance" method="round" /&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; &lt;!-- 流程管理.结束 --&gt; ####3、开发持久化类FlowPersistanceImpl 必须是IFlowPersistance接口的实现，可直接使用Demo中的持久化类 ####4、开发业务流程事件类 事件类包含流程开始、结束；流程环节的开始、结束等事件。 例如： @Component(value=”businessEvent”) public class BusinessEventImpl extends AbstractBusinessEvent { } 详细内容可参考Demo ####5、配置业务类型表Business 为每一个业务添加一条记录。 Action 配置流程事件类的服务名； ViewURL字段为经办界面还原的视图，在审核审批过程中，显示需要查看的内容。 Businessid字段需要开发人员记住，建议设置为一个有逻辑意义的字符串。 以上是手动配置，也可以通过系统的图形化界面配置。 ####6、配置流程表 Procedure 流程表由流程ID、机构ID、业务ID组成，表示一种业务，不同的机构可以定义不同的流程。 以上是手动配置，也可以通过系统的图形化界面配置。 ####7、配置流程环节表 Step 流程环节表示流程中一个环节的定义。包括流程ID、流程环节ID、流程环节名称、上级节点、下级节点、分配方式等。以上是手动配置，也可以通过系统的图形化界面配置。 ####8、配置流程环节权限表 Stepgant 可以给流程环节分配权限，可以按用户ID、角色ID或者机构ID分配权限。 以上是手动配置，也可以通过系统的图形化界面配置。####9、开发与流程相关的业务代码 与提交审核审批相关的服务代码，需要在函数前使用注解“@Flow”，并且函数的第一个入参数必须是FlowAttribute 。在调用提交审核审批的时候需要将FlowAttrribute参数传进去，FlowAttribute 包含businessid、taskid、userid等属性，以确保系统可以获取到流程相关内容。 例如： 1234567891011121314151617181920212223242526272829303132333435363738394041424344//服务层代码 Service@Override@Flowpublic FlowtestModel commit(FlowAttribute attr1,String id) &#123; String taskid=attr1.getTaskid(); Flowtest test = flowtestDAO.get(Flowtest.class, id); if(test==null)&#123; new BusinessException("数据不存在"); &#125; test.setTaskid(taskid); flowtestDAO.update(test); FlowtestModel flowtest=new FlowtestModel(); BeanUtils.copyProperties(test, flowtest); return flowtest; &#125;//控制层代码 Controller@RequestMapping("/commit")@ResponseBodypublic FlowtestModel commit(FlowtestModel model, HttpServletRequest req,HttpServletResponse res)&#123; //随机产生一个任务ID String taskid=UUID.randomUUID().toString().replaceAll("-", ""); FlowAttribute attr=new FlowAttribute(); attr.setTaskid(taskid); //配置业务类型编码参考Business表 attr.setBusinessid("1"); //设置当前用户的组织机构编号 attr.setGroupid("0"); //设置当前用户的Id attr.setUserid(getCurrentUser().getUserid()); model = flowtestService.get(model.getId()); Map params= MapBeanUtil.beanToMap(model); attr.setParams(params); FlowtestModel f = flowtestService.commit(attr,model.getId()); return f;&#125; ###二、表结构说明 ####1、业务类型表Business 1234567891011名称 类型 可否为空 默认值 描述BUSINESSID VARCHAR2(32) 否 主键业务类型IDBUSINESSNAME VARCHAR2(100) 否 业务名称ACTIVE VARCHAR2(1) 否 default &apos;1&apos; 是否可用ACTION VARCHAR2(500) 是 事件服务名称VIEWURL VARCHAR2(500) 是 审核审核查看明细页面BUSINESSURL VARCHAR2(500) 是 经办页面ALLOWCROSS VARCHAR2(1) 是 是否交叉授权预留 ####2、业务流程表 Procedure 12345678名称 类型 可否为空 默认值 描述PROCEDUREID VARCHAR2(32) 否 主键业务流程IDPROCEDURENAME VARCHAR2(50) 否 业务流程名称ACTIVE VARCHAR2(1) 否 default &apos;1&apos; 是否可用BUSINESSID VARCHAR2(32) 是 业务类型IDGROUPID VARCHAR2(32) 是 机构ID PROCEDUREDESC VARCHAR2(100) 是 描述 ####3、业务流程环节表Step 123456789101112名称 类型 可否为空 默认值 描述STEPID VARCHAR2(32) 否 主键业务环节IDPROCEDUREID VARCHAR2(32) 否 流程IDPREVIOUSSTEPID VARCHAR2(32) 是 上级流程IDNEXTSTEPID VARCHAR2(32) 是 下级流程IDSTEPNAME VARCHAR2(100) 否 流程环节名称 FLOWTYPE VARCHAR2(3) 是 流程环节类型REFUSERULE VARCHAR2(3) 是 拒绝规则ACTION VARCHAR2(500) 是 事件类ASSIGNRULE VARCHAR2(3) 是 分发规则URL VARCHAR2(500) 是 预留 ####4、业务流程环节权限stepgrant 12345678910名称 类型 可否为空 默认值 描述FLOWGRANTID VARCHAR2(32) 否 主键 STEPID VARCHAR2(32) 否 流程环节IDUSERID VARCHAR2(32) 是 用户IDGROUPID VARCHAR2(32) 是 机构IDROLEID VARCHAR2(32) 是 角色ID ALLOWGRANT VARCHAR2(1) 是 0 是否允许授权STARTTIME DATE 是 起始时间ENDTIME DATE 是 截止时间DESCRIPTIOIN VARCHAR2(500) 是 描述 ####5、业务流程任务stepTASK 12345678910111213141516171819202122232425262728 名称 类型 可否为空 默认值 描述 TASKID VARCHAR2(32) 否 主键 BUSINESSID VARCHAR2(32) 是 业务ID BUSINESSNAME VARCHAR2(100) 是 业务名称 STEPID VARCHAR2(32) 是 环节ID STEPNAME VARCHAR2(100) 是 角色ID USERID VARCHAR2(32) 是 用户ID NEXTSTEPID VARCHAR2(32) 是 下级流程ID NEXTSTEPNAME VARCHAR2(100) 是 下级流程名称 NEXTUSERID VARCHAR2(32) 是 下级流程指派用户ID TASKSTATE VARCHAR2(3) 是 任务状态 1任务未领取, 2任务已领取, 3 任务完成 CONTENT VARCHAR2(100) 是 内容描述 RESULT VARCHAR2(3) 是 审核结果 CREATETIME timestamp 是 创建时间 UPDATETIME timestamp 是 更新时间 TASKLEVEL NUMBER 是 任务级别``` ####6、任务数据明细steptaskinfo```text 名称 类型 可否为空 默认值 描述 taskinfoid VARCHAR2(32) 否 主键 taskid VARCHAR2(32) 是 任务ID name VARCHAR2(50) 是 字段名称 value VARCHAR2(500) 是 字段值 ####7、任务日志表stepTASKLOG 12345678910111213141516171819名称 类型 可否为空 默认值 描述TASKLOGID VARCHAR2(32) 否 主键TASKID VARCHAR2(32) 否 任务IDBUSINESSID VARCHAR2(32) 是 业务IDBUSINESSNAME VARCHAR2(100) 是 业务名称STEPID VARCHAR2(32) 是 环节IDSTEPNAME VARCHAR2(100) 是 角色ID USERID VARCHAR2(32) 是 用户IDTASKSTATE VARCHAR2(3) 是 任务状态 1任务未领取, 2任务已领取, 3 任务完成CONTENT VARCHAR2(100) 是 内容描述RESULT VARCHAR2(3) 是 审核结果CREATETIME timestamp 是 创建时间UPDATETIME timestamp 是 更新时间TASKLEVEL NUMBER 是 任务级别ISCANCEL VARCHAR2(1) 是 是否已经撤销]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>工作流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建mongoDB副本+分片集群]]></title>
    <url>%2F2018%2F08%2F03%2Fcloud%2F2018-08-03-%E6%90%AD%E5%BB%BAMongoDB%E5%89%AF%E6%9C%AC%2B%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[mongodb是目前开源数据库中最常用的NoSQL数据库， MongoDb在用于生产环境的三种模式，master/slaves（主从模式）;replica set(副本集);auto shard 分片模式，本文主要介绍如何搭建高可用的mongodb副本+分片（Replication）集群。 一、概念在搭建集群之前，需要首先了解几个概念：路由、副本集、分片、配置服务器等。 1.路由 mongos数据库集群请求的入口，所有的请求都通过mongos进行协调，不需要在应用程序添加一个路由选择器，mongos自己就是一个请求分发中心，它负责把对应的数据请求请求转发到对应的shard服务器上。在生产环境通常有多mongos作为请求的入口，防止其中一个挂掉所有的mongodb请求都没有办法操作。2.副本集 replica setMongoDB的replica set是一个mongod进程实例簇，数据在这个簇中相互复制，并自动进行故障切换。 MongoDB的数据库复制增加了冗余，确保了高可用性，简化了管理任务如备份，并且增加了读能力。大多数产品部署都使用了复制。MongoDB中primary处理写操作，其它进行复制的成员则是secondaries。3.分片 sharding到目前为止，你都是把MongoDB当做一台服务器在用，每个mongod实例都包含应用程序数据的完整副本。就算使用了复制，每个副本也都是完整克隆了其他副本的数据。对于大多数应用程序而言，在一台服务器上保存完整数据集是完全可以接受的。但随着数据量的增长，以及应用程序对读写吞吐量的要求越来越高，普通服务器渐渐显得捉襟见肘了。尤其是这些服务器可能无法分配足够的内存，或者没有足够的CPU核数来有效处理工作负荷。除此之外，随着数据量的增长，要在一块磁盘或者一组RAID阵列上保存和管理备份如此大规模的数据集也变得不太现实。如果还想继续使用普通硬件或者虚拟硬件来托管数据库，那么这对这类问题的解决方案就是将数据库分布到多台服务器上，这种方法称之为分片。 一个副本集可以最多支持12个成员，但是只有7个成员可以参与投票。4.配置服务器config server顾名思义为配置服务器，存储所有数据库元信息（路由、分片）的配置。mongos本身没有物理存储分片服务器和数据路由信息，只是缓存在内存里，配置服务器则实际存储这些数据。mongos第一次启动或者关掉重启就会从 config server 加载配置信息，以后如果配置服务器信息变化会通知到所有的 mongos 更新自己的状态，这样 mongos 就能继续准确路由。在生产环境通常有多个 config server 配置服务器，因为它存储了分片路由的元数据，防止数据丢失！二、环境准备1.资源系统系统 centos7，三台服务器：192.168.22.101/102/103，下载MongoDB安装包： mongodb-linux-x86_64-3.4.6.tgz2，服务器规划| 服务器101 | 服务器102 | 服务器103| |-----------|------------|---------| | mongos | mongos | mongos | | config server | config server | config server | | shard server1 主节点 | shard server1 副节点 | shard server1 仲裁 | | shard server2 仲裁 | shard server2 主节点 | shard server2 副节点 | | shard server3 副节点 | shard server3 仲裁 | shard server3 主节点 | ---------- 端口分配： mongos：20000 config：21000 shard1：27001 shard2：27002 shard3：270033、架构图 三、集群搭建1、安装mongodb解压1tar -xzvf mongodb-linux-x86_64-3.4.6.tgz -C /usr/local/ 改名mv mongodb-linux-x86_64-3.4.6 mongodb分别在每台机器建立conf、mongos、config、shard1、shard2、shard3六个目录，因为mongos不存储数据，只需要建立日志文件目录即可。 12345678910mkdir -p /usr/local/mongodb/confmkdir -p /usr/local/mongodb/mongos/logmkdir -p /usr/local/mongodb/config/datamkdir -p /usr/local/mongodb/config/logmkdir -p /usr/local/mongodb/shard1/datamkdir -p /usr/local/mongodb/shard1/logmkdir -p /usr/local/mongodb/shard2/datamkdir -p /usr/local/mongodb/shard2/logmkdir -p /usr/local/mongodb/shard3/datamkdir -p /usr/local/mongodb/shard3/log #####配置环境变量 1vim /etc/profile 内容12export MONGODB_HOME=/usr/local/mongodbexport PATH=$MONGODB_HOME/bin:$PATH 使立即生效1source /etc/profile 2、config server配置服务器mongodb3.4以后要求配置服务器也创建副本集，不然集群搭建不成功。添加配置文件 1vi /usr/local/mongodb/conf/config.conf 配置文件内容123456789101112131415161718pidfilepath = /usr/local/mongodb/config/log/configsrv.piddbpath = /usr/local/mongodb/config/datalogpath = /usr/local/mongodb/config/log/congigsrv.loglogappend = truebind_ip = 0.0.0.0port = 21000fork = true#declare this is a config db of a cluster;configsvr = true#副本集名称replSet=configs#设置最大连接数maxConns=20000 启动三台服务器的config server 1mongod -f /usr/local/mongodb/conf/config.conf 登录任意一台配置服务器，初始化配置副本集#####连接 1mongo --port 21000 #####config变量 12345678config = &#123; _id : &quot;configs&quot;, members : [ &#123;_id : 0, host : &quot;192.168.22.101:21000&quot; &#125;, &#123;_id : 1, host : &quot;192.168.22.102:21000&quot; &#125;, &#123;_id : 2, host : &quot;192.168.22.103:21000&quot; &#125; ]&#125; #####初始化副本集 1rs.initiate(config) 其中，”_id” : “configs”应与配置文件中配置的 replicaction.replSetName 一致，”members” 中的 “host” 为三个节点的 ip 和 port 3、配置分片副本集(三台机器)设置第一个分片副本集配置文件 1vi /usr/local/mongodb/conf/shard1.conf #####配置文件内容 1234567891011121314151617pidfilepath = /usr/local/mongodb/shard1/log/shard1.piddbpath = /usr/local/mongodb/shard1/datalogpath = /usr/local/mongodb/shard1/log/shard1.loglogappend = truebind_ip = 0.0.0.0port = 27001fork = true #副本集名称replSet=shard1 #declare this is a shard db of a cluster;shardsvr = true #设置最大连接数maxConns=20000 启动三台服务器的shard1 server 1mongod -f /usr/local/mongodb/conf/shard1.conf 登陆任意一台服务器，初始化副本集 1mongo --port 27001 #####使用admin数据库 1use admin #####定义副本集配置，第三个节点的 “arbiterOnly”:true 代表其为仲裁节点。 1234567config = &#123;_id : &quot;shard1&quot;,members:[&#123;_id : 0, host : &quot;192.168.22.101:27001&quot; &#125;,&#123;_id : 1, host : &quot;192.168.22.102:27001&quot; &#125;,&#123;_id : 2, host : &quot;192.168.22.103:27001&quot;, arbiterOnly: true &#125;]&#125; #####初始化副本集配置 1rs.initiate(config); 设置第二个分片副本集配置文件 1vi /usr/local/mongodb/conf/shard2.conf #####配置文件内容 12345678910111213141516pidfilepath = /usr/local/mongodb/shard2/log/shard2.piddbpath = /usr/local/mongodb/shard2/datalogpath = /usr/local/mongodb/shard2/log/shard2.loglogappend = truebind_ip = 0.0.0.0port = 27002fork = true #副本集名称replSet=shard2 #declare this is a shard db of a cluster;shardsvr = true #设置最大连接数maxConns=20000 启动三台服务器的shard2 server 1mongod -f /usr/local/mongodb/conf/shard2.conf 登陆任意一台服务器，初始化副本集 1mongo --port 27002 #####使用admin数据库 1use admin #####定义副本集配置 12345678config = &#123; _id : &quot;shard2&quot;, members : [ &#123;_id : 0, host : &quot;192.168.22.101:27002&quot; , arbiterOnly: true &#125;, &#123;_id : 1, host : &quot;192.168.22.102:27002&quot; &#125;, &#123;_id : 2, host : &quot;192.168.22.103:27002&quot; &#125; ] &#125; #####初始化副本集配置 1rs.initiate(config); 设置第三个分片副本集配置文件 1vi /usr/local/mongodb/conf/shard3.conf #####配置文件内容 1234567891011121314151617pidfilepath = /usr/local/mongodb/shard3/log/shard3.piddbpath = /usr/local/mongodb/shard3/datalogpath = /usr/local/mongodb/shard3/log/shard3.loglogappend = truebind_ip = 0.0.0.0port = 27003fork = true #副本集名称replSet=shard3 #declare this is a shard db of a cluster;shardsvr = true #设置最大连接数maxConns=20000 启动三台服务器的shard3 server 1mongod -f /usr/local/mongodb/conf/shard3.conf 登陆任意一台服务器，初始化副本集 1mongo --port 27003 #####使用admin数据库 1use admin #####定义副本集配置 12345678config = &#123; _id : &quot;shard3&quot;, members : [ &#123;_id : 0, host : &quot;192.168.22.101:27003&quot; &#125;, &#123;_id : 1, host : &quot;192.168.22.102:27003&quot; , arbiterOnly: true&#125;, &#123;_id : 2, host : &quot;192.168.22.103:27003&quot; &#125; ]&#125; #####初始化副本集配置 1rs.initiate(config); ###4、配置路由服务器 mongos先启动配置服务器和分片服务器,后启动路由实例启动路由实例:（三台机器） 1vi /usr/local/mongodb/conf/mongos.conf #####内容 12345678910111213pidfilepath = /usr/local/mongodb/mongos/log/mongos.pidlogpath = /usr/local/mongodb/mongos/log/mongos.loglogappend = truebind_ip = 0.0.0.0port = 20000fork = true#监听的配置服务器,只能有1个或者3个 configs为配置服务器的副本集名字configdb = configs/192.168.22.101:21000,192.168.22.102:21000,192.168.22.103:21000 #设置最大连接数maxConns=20000 启动三台服务器的mongos servermongos -f /usr/local/mongodb/conf/mongos.conf ###5、启用分片目前搭建了mongodb配置服务器、路由服务器，各个分片服务器，不过应用程序连接到mongos路由服务器并不能使用分片机制，还需要在程序里设置分片配置，让分片生效。登陆任意一台mongosmongo –port 20000#使用admin数据库 1234567use admin#串联路由服务器与分配副本集sh.addShard(&quot;shard1/192.168.22.101:27001,192.168.22.102:27001,192.168.22.103:27001&quot;)sh.addShard(&quot;shard2/192.168.22.101:27002,192.168.22.102:27002,192.168.22.103:27002&quot;)sh.addShard(&quot;shard3/192.168.22.101:27003,192.168.22.102:27003,192.168.22.103:27003&quot;)#查看集群状态sh.status() ###6、测试目前配置服务、路由服务、分片服务、副本集服务都已经串联起来了，但我们的目的是希望插入数据，数据能够自动分片。连接在mongos上，准备让指定的数据库、指定的集合分片生效。#####指定testdb分片生效db.runCommand( { enablesharding :”testdb”}); use testeddb.table1.ensureIndex({id:1}) #####指定数据库里需要分片的集合和片键 db.runCommand( { shardcollection : “testdb.table1”,key : {id: 1} } ) #####如果是采用hash分片#####db.runCommand( { shardcollection : “testdb.table1”,key : {_id: “hashed”} } ) 我们设置testdb的 table1 表需要分片，根据 id 自动分片到 shard1 ，shard2，shard3 上面去。要这样设置是因为不是所有mongodb 的数据库和表 都需要分片！测试分片配置结果mongo 127.0.0.1:20000 #####使用testdbuse testdb; #####插入测试数据for (var i = 1; i &lt;= 100; i++)db.table2.save({id:i,”test1”:”testval1”});#####查看分片情况如下，部分无关信息省掉了 123456789101112131415161718192021222324252627282930313233343536373839404142db.table1.stats();&#123; &quot;sharded&quot; : true, &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; : 100000, &quot;numExtents&quot; : 13, &quot;size&quot; : 5600000, &quot;storageSize&quot; : 22372352, &quot;totalIndexSize&quot; : 6213760, &quot;indexSizes&quot; : &#123; &quot;_id_&quot; : 3335808, &quot;id_1&quot; : 2877952 &#125;, &quot;avgObjSize&quot; : 56, &quot;nindexes&quot; : 2, &quot;nchunks&quot; : 3, &quot;shards&quot; : &#123; &quot;shard1&quot; : &#123; &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; : 42183, &quot;size&quot; : 0, ... &quot;ok&quot; : 1 &#125;, &quot;shard2&quot; : &#123; &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; : 38937, &quot;size&quot; : 2180472, ... &quot;ok&quot; : 1 &#125;, &quot;shard3&quot; : &#123; &quot;ns&quot; : &quot;testdb.table1&quot;, &quot;count&quot; :18880, &quot;size&quot; : 3419528, ... &quot;ok&quot; : 1 &#125; &#125;, &quot;ok&quot; : 1&#125; 可以看到数据分到3个分片，各自分片数量为： shard1 “count” : 42183，shard2 “count” : 38937，shard3 “count” : 18880。已经成功了！后期运维启动关闭mongodb的启动顺序是，先启动配置服务器，在启动分片，最后启动mongos. 12345mongod -f /usr/local/mongodb/conf/config.confmongod -f /usr/local/mongodb/conf/shard1.confmongod -f /usr/local/mongodb/conf/shard2.confmongod -f /usr/local/mongodb/conf/shard3.confmongod -f /usr/local/mongodb/conf/mongos.conf 关闭时，直接killall杀掉所有进程 12killall mongodkillall mongos]]></content>
      <tags>
        <tag>MongoDB</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SeetaFace和Dlib实现人脸识别]]></title>
    <url>%2F2018%2F02%2F24%2Fothers%2F2018-02-24-%E4%BD%BF%E7%94%A8SeetaFace%20%E5%92%8CDlib%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[使用SeetaFace 和 Dlib 实现人脸识别 SeetaFace 介绍seetaface由中科院计算所山世光研究员带领的人脸识别研究组研发。代码基于C++实现,不依赖第三方库。开源免费可用。工程包括人脸检测、人脸对齐、人脸识别三个模块。Github 地址是：https://github.com/seetaface/SeetaFaceEngine Dlib介绍Dlib是一个C++库，包含了许多机器学习算法，也包括人脸特征检测算法。它是跨平台的，可以应用在Windows、Linux、Mac、embedded devices、mobile phones等。它的License是Boost Software License 1.0，可以商用。Dlib的主要特点可以参考官方网站：http://dlib.net/。Dlib人脸特征检测实现了68点标定,拿到68点后就可以用于人脸识别比对和活体检测。 准备开发环境本案例使用的是Microsoft Visual Studio VC++ 2013 安装OpencvOpenCV实现了图像处理和计算机视觉方面的很多通用算法，可以用于人脸识别过程的图像处理。我在测试时使用的是opencv2.4.12。 下载SeetaFace并编译自行下载SeetaFace源码，并编译出三个lib文件和三个dll文件。编译出的结果包括：FaceIdentification.lib FaceIdentification.dllFaceAlignment.lib FaceAlignment.dllFaceDetection.lib FaceDetection.dll 下载Dlib源码Dlib 可以在其官网下载http://dlib.net/ 新建工程修改配置① 新建win32控制台项目，命名为：FaceIdentificationServer。在工程目录中新建目录“include/seeta”和“include/dlib”。将项目属性改为x64。将seetaFace源码所有”.h”文件拷贝到工程目录下的include/seeta 目录下。将dlib 源代码整个“dlib”文件夹拷贝到“/include/dlib”文件夹下。② 在配置属性“VC++目录”中，修改opencv的包含目录和库目录，opencv使用x64的lib库。修改“库目录”增加OpenCV的lib目录：“\opencv\2.4.12\build\x64\vc12”；修改“包含目录”，增加：“..\include\dlib”、“..\include\seeta”、“D:\greensoftware\opencv\2.4.12\build\include”、“D:\greensoftware\opencv\2.4.12\build\include\opencv”、“D:\greensoftware\opencv\2.4.12\build\include\opencv2”。 ③ 在链接器的“输入”中，加入以下几个lib：dlib.libopencv_calib3d2412d.libopencv_contrib2412d.libopencv_core2412d.libopencv_features2d2412d.libopencv_flann2412d.libopencv_gpu2412d.libopencv_highgui2412d.libopencv_imgproc2412d.libopencv_legacy2412d.libopencv_ml2412d.libopencv_objdetect2412d.libopencv_ts2412d.libopencv_video2412d.libFaceAlignment.libFaceDetection.libIdentification.lib ④将与seetaFace的6个lib文件对应的dll文件放入可执行文件目录下。⑤将seetaface源码中的三个model以及dlib人脸检测模型文件feets.dat、lbpcascade_frontalface.xml、shape_predictor_68_face_landmarks.dat放到项目执行文件夹的model文件夹下。项目整体结构：x64\Debug\model 用于放模型文件x64\Debug\data 用于放测试照片、人脸特征数据和配置文件 人脸识别实现获取照片特征123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153bool getFeature(cv::Mat src_img, float* feat_pic1)&#123; cv::Mat src_img_gray; if (src_img.channels() != 1) cv::cvtColor(src_img, src_img_gray, cv::COLOR_BGR2GRAY); else src_img_gray = src_img; IplImage src_img_grayscaletmp = src_img_gray; IplImage *src_img_grayscale = cvCloneImage(&amp;src_img_grayscaletmp); if (src_img_grayscale == NULL) &#123; return false; &#125; IplImage src_img_colortmp = src_img; IplImage *src_img_color = cvCloneImage(&amp;src_img_colortmp); int src_im_width = src_img_grayscale-&gt;width; int src_im_height = src_img_grayscale-&gt;height; unsigned char* src_data = new unsigned char[src_im_width * src_im_height]; unsigned char* src_image_data_ptr = (unsigned char*)src_img_grayscale-&gt;imageData; unsigned char* data_ptr; int hh = 0; //获取照片数据1 data_ptr = src_data; for (hh = 0; hh &lt; src_im_height; hh++) &#123; memcpy(data_ptr, src_image_data_ptr, src_im_width); data_ptr += src_im_width; src_image_data_ptr += src_img_grayscale-&gt;widthStep; &#125; seeta::ImageData src_image_data; src_image_data.data = src_data; src_image_data.width = src_im_width; src_image_data.height = src_im_height; src_image_data.num_channels = 1; // Detect faces 1 g_lock_detech.lock(); std::vector&lt;seeta::FaceInfo&gt; src_faces = seeta_detector.Detect(src_image_data); g_lock_detech.unlock(); int32_t face_num1 = static_cast&lt;int32_t&gt;(src_faces.size()); if (face_num1 == 0) &#123; delete[]src_data; cvReleaseImage(&amp;src_img_grayscale); cvReleaseImage(&amp;src_img_color); return false; &#125; // Detect 5 facial landmarks seeta::FacialLandmark src_points[5]; for (int k = 0; k &lt; face_num1; k++) &#123; g_lock_detech.lock(); seeta_alignment.PointDetectLandmarks(src_image_data, src_faces[k], src_points); g_lock_detech.unlock(); &#125; // Release memory cvReleaseImage(&amp;src_img_color); cvReleaseImage(&amp;src_img_grayscale); delete[]src_data; // ImageData store data of an image without memory alignment. seeta::ImageData src_img_data(src_img.cols, src_img.rows, src_img.channels()); src_img_data.data = src_img.data; /* Extract feature: ExtractFeatureWithCrop */ g_lock_detech.lock(); seeta_recognizer.ExtractFeatureWithCrop(src_img_data, src_points, feat_pic1); g_lock_detech.unlock(); return true;&#125; /*获取特征*/vector&lt;float*&gt; getFeatures(vector&lt;cv::Mat&gt; src_imgs)&#123; int feat_size = seeta_recognizer.feature_size(); vector&lt;float*&gt; feat_pics; clock_t start; start = clock(); for (int i = 0; i &lt; src_imgs.size(); i++)&#123; cv::Mat src_img = src_imgs[i]; float* feat_pic1 = new float[feat_size];//n * c * h * w bool suc = getFeature(src_img, feat_pic1); if (suc)&#123; feat_pics.push_back(feat_pic1); &#125; &#125; std::cout &lt;&lt; "获取人脸特征:" &lt;&lt; (clock() - start) &lt;&lt; endl; return feat_pics;&#125;string floatToString(float Num)&#123; ostringstream oss; oss &lt;&lt; Num; string str(oss.str()); return str;&#125;string featureToString(float *feature)&#123; int size = seeta_recognizer.feature_size(); string row = ""; for (int i = 0; i &lt; size; i++)&#123; row += floatToString(feature[i]); if (i &lt; size - 1)&#123; row += ","; &#125; &#125; return row;&#125; 1比1人脸照片比对12345678910111213141516171819202122/*人脸比对*/float match(cv::Mat src_img, cv::Mat dist_img)&#123; vector&lt;cv::Mat&gt; imgs; imgs.push_back(src_img); imgs.push_back(dist_img); vector&lt;float*&gt; feats = getFeatures(imgs); float sim = seeta_recognizer.CalcSimilarity(feats[0], feats[1]); for (int i = 0; i &lt; feats.size(); i++)&#123; delete feats[i]; &#125; std::cout &lt;&lt; "相似度: " &lt;&lt; sim &lt;&lt; endl; return sim;&#125; 获取特征点检测活体123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345/*获取特征点*/dlib::full_object_detection getFeaturePoint(cv::Mat temp)&#123; dlib::full_object_detection res; if (temp.rows &lt;= 0 || temp.cols &lt;= 0)&#123; return res; &#125; cv::Mat face_gray; cvtColor(temp, face_gray, CV_BGR2GRAY); //rgb类型转换为灰度类型 equalizeHist(face_gray, face_gray); //直方图均衡化 std::vector&lt;cv::Rect&gt; cvfaces; int flags = CV_HAAR_FIND_BIGGEST_OBJECT | CV_HAAR_DO_ROUGH_SEARCH; //只检测脸最大的人 g_lock_detech.lock(); face_cascade.detectMultiScale(face_gray, cvfaces, 1.1f, 4, flags, cv::Size(30, 30)); g_lock_detech.unlock(); //|CV_HAAR_FIND_BIGGEST_OBJECT //|CV_HAAR_DO_ROUGH_SEARCH //|CV_HAAR_SCALE_IMAGE dlib::cv_image&lt;dlib::bgr_pixel&gt; cimg(temp); if (cvfaces.size() &gt; 0)&#123; dlib::rectangle det; int faceSize = 0; for (int n = 0; n &lt; cvfaces.size(); n++)&#123; int s = cvfaces[n].width * cvfaces[n].height; if (s &gt; faceSize)&#123; faceSize = s; det.set_left(cvfaces[n].x); det.set_top(cvfaces[n].y); det.set_right(cvfaces[n].x + cvfaces[n].width); det.set_bottom(cvfaces[n].y + cvfaces[n].height); &#125; &#125; res = pose_model(cimg, det); &#125; return res;&#125; //DLIB 获取特征点std::vector&lt;dlib::full_object_detection&gt; getFeaturePoints(std::vector&lt;cv::Mat&gt; images)&#123; clock_t start = clock(); std::vector&lt;dlib::full_object_detection&gt; objs; for (int i = 0; i &lt; images.size(); i++)&#123; cv::Mat temp = images[i]; if (temp.rows &lt;= 0 || temp.cols &lt;= 0)&#123; continue; &#125; dlib::full_object_detection obj = getFeaturePoint(temp); if (obj.num_parts()&gt;0)&#123; objs.push_back(obj); &#125; &#125; cout &lt;&lt; "获取特征点：" &lt;&lt; (clock() - start) &lt;&lt; endl; return objs; &#125;/*是否有张合嘴*/bool isMouseLive(std::vector&lt;dlib::full_object_detection&gt; ps)&#123; if (ps.size() == 0)return 0; long min_h = 99999999999999; long max_h = 0; double min = 99999999999999; double max = 0; for (int n = 0; n &lt; ps.size(); n++)&#123; dlib::full_object_detection p = ps[n]; long w = p.part(54).x() - p.part(60).x(); long h = p.part(57).y() - p.part(51).y(); if (h&lt;min_h)&#123; min_h = h; &#125; if (h&gt;max_h)&#123; max_h = h; &#125; double bl = h*1.0 / w*1.0; if (bl &lt; min)&#123; min = bl; &#125; if (bl &gt; max)&#123; max = bl; &#125; &#125; if (max &lt;= 0)&#123; return false; &#125; if (min &lt;= 0)&#123; return false; &#125; double p = (max - min) *1.0 / max *1.0; //std::cout &lt;&lt; p &lt;&lt; endl; if (p &gt; 0.5)&#123; return true; &#125; else&#123; return false; &#125; &#125;//是否摇头bool isHeadLive(std::vector&lt;dlib::full_object_detection&gt; ps)&#123; if (ps.size() == 0)return 0; bool lefted = false; bool righted = false; double max_right = 0; for (int n = 0; n &lt; ps.size(); n++)&#123; dlib::full_object_detection p = ps[n]; long w = p.part(14).x() - p.part(2).x(); long left = p.part(30).x() - p.part(2).x(); long right = p.part(14).x() - p.part(30).x(); double l = left*1.0 / right; double r = right*1.0 / left; if (l &lt; 0.6 &amp;&amp; !lefted)&#123; lefted = true; &#125; if (r &lt; 0.6 &amp;&amp; !righted)&#123; righted = true; &#125; if (lefted &amp;&amp; righted)break; &#125; if (lefted &amp;&amp; righted)&#123; return true; &#125; return false;&#125;//是否眨眼bool isEyeLive(std::vector&lt;dlib::full_object_detection&gt; ps)&#123; //left 37,38,41,42 | 36,39 //right 43,44,46,47 | 42,45 double max_left = 0; double min_left = 9999999; double max_right = 0; double min_right = 9999999; for (int n = 0; n &lt; ps.size(); n++)&#123; dlib::full_object_detection p = ps[n]; long left_w = p.part(39).x() - p.part(36).x(); long right_w = p.part(45).x() - p.part(42).x(); long right_h = p.part(46).y() - p.part(44).y(); long right_h2 = p.part(47).y() - p.part(43).y(); long r = right_h + right_h2; double right_d = r*1.0 / right_w; if (right_d &gt; max_right)&#123; max_right = right_d; &#125; if (right_d &lt; min_right)&#123; min_right = right_d; &#125; long left_h = p.part(41).y() - p.part(37).y(); long left_h2 = p.part(40).y() - p.part(38).y(); long l = left_h + left_h2; double left_d = l * 1.0 / left_w; if (left_d &gt; max_left)&#123; max_left = left_d; &#125; if (left_d &lt; min_left)&#123; min_left = left_d; &#125; &#125; double dd_left=(max_left - min_left) / max_left; double dd_right = (max_right - min_right) / max_right; cout &lt;&lt; "eye " &lt;&lt; dd_left &lt;&lt; " " &lt;&lt; dd_right &lt;&lt; endl; if (dd_left&gt;0.45 || dd_right &gt; 0.45)&#123; return true; &#125; return false;&#125; bool isAlive(string n, std::vector&lt;dlib::full_object_detection&gt; pp, bool mouse, bool head, bool eye, int relayType=1)&#123; if (relayType == 0)return true; std::vector&lt;dlib::full_object_detection&gt; ps; for (int i = 0; i&lt;pp.size(); i++)&#123; ps.push_back(pp[i]); &#125; if (ps.size() &lt; 2)&#123; //小于两张就无法判断活体 return 0; &#125; long max_area = 0; long min_area = 99999999; long avg_area = 0; long max_len = 0; long min_len = 99999999; //long max_x = 0; //long max_y = 0; //long min_x = 0; //long min_y = 0; for (int n = 0; n &lt; ps.size(); n++)&#123; dlib::full_object_detection p = ps[n]; long a = p.get_rect().area(); avg_area += a; if (max_area &lt; a)&#123; max_area = a; &#125; if (max_area &gt; a)&#123; min_area = a; &#125; long x = (p.part(14).x() - p.part(2).x())*1.0 / 2; long y = (p.part(8).y() - p.part(27).y())*1.0 / 2; //中心点距离 long len = sqrt((x - 0)*(x - 0) + (y - 0)*(y - 0)); if (max_len&lt;len)&#123; max_len = len; &#125; if (min_len&gt;len)&#123; min_len = len; &#125; &#125; //如果脸的大小变化比较大，说明有切换图片之类的。 if ( ( (max_area - min_area)*1.0 / max_area) &gt; 0.4)&#123; cout &lt;&lt; "size changed" &lt;&lt; endl; return false; &#125; //如果中心位置移动太大，就说明有切换图片 if ( ( (max_len - min_len) / sqrt(max_area)) &gt; 0.2)&#123; cout &lt;&lt; "pos moved" &lt;&lt; endl; return false; &#125; bool m = false; bool h = false; bool e = false; if (mouse)&#123; m = isMouseLive(ps); &#125; if (head)&#123; h = isHeadLive(ps); &#125; if (eye)&#123; e = isEyeLive(ps); &#125; if (relayType == 1)&#123; bool alive = m &amp;&amp; h &amp;&amp; e; return alive; &#125; else&#123; bool alive = m || h || e; return alive; &#125; &#125;/*是否活体*/bool isAlive(string id,std::vector&lt;cv::Mat&gt; images,bool mouse,bool head,bool eye,int relayType)&#123; clock_t start = clock(); std::vector&lt;dlib::full_object_detection&gt; ps = getFeaturePoints(images); bool isa = isAlive(id, ps, mouse, head, eye, relayType); cout &lt;&lt; "活体认证：" &lt;&lt; isa &lt;&lt; " "&lt;&lt; (clock() - start) &lt;&lt; endl; return isa;&#125; 申明本开发案例仅本人用于测试人脸识别库，测试验证在一些对质量要求不是太高的场景可用。 完整代码可联系502782757@qq.com]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>人脸识别</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于H5的人脸检测实践]]></title>
    <url>%2F2018%2F02%2F22%2Fothers%2F2018-02-22-%E5%9F%BA%E4%BA%8EH5%E7%9A%84%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[基于H5的人脸活体检测实验是我在2015年的一个”生存认证“相关项目的技术实验。载自我的百度经验]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>H5</tag>
        <tag>javascript</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python实现微信自动回复]]></title>
    <url>%2F2018%2F02%2F22%2Fpython%2F2018-02-22-Python%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E8%87%AA%E5%8A%A8%E5%9B%9E%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[春节期间接收到无数新年问候，总想一一答复，不想群发，难免有遗漏，抽空学习了Python自动回复的itchat。以下是学习摘要 入门尝试123456# 加载包import itchat# 登陆itchat.auto_login()# 发送文本消息，发送目标是“文件传输助手”itchat.send('Hello, filehelper', toUserName='filehelper') 消息响应12345678910import itchat# 注册消息响应事件，消息类型为itchat.content.TEXT，即文本消息@itchat.msg_register(itchat.content.TEXT)def text_reply(msg): # 返回同样的文本消息 return msg['Text']itchat.auto_login()# 绑定消息响应事件后，让itchat运行起来，监听消息itchat.run() 其他消息处理123456789101112131415161718192021222324252627282930313233343536373839404142import itchat# import全部消息类型from itchat.content import *# 处理文本类消息# 包括文本、位置、名片、通知、分享@itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING])def text_reply(msg): # 微信里，每个用户和群聊，都使用很长的ID来区分 # msg['FromUserName']就是发送者的ID # 将消息的类型和文本内容返回给发送者 itchat.send('%s: %s' % (msg['Type'], msg['Text']), msg['FromUserName'])# 处理多媒体类消息# 包括图片、录音、文件、视频@itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO])def download_files(msg): # msg['Text']是一个文件下载函数 # 传入文件名，将文件下载下来 msg['Text'](msg['FileName']) # 把下载好的文件再发回给发送者 return '@%s@%s' % (&#123;'Picture': 'img', 'Video': 'vid'&#125;.get(msg['Type'], 'fil'), msg['FileName'])# 处理好友添加请求@itchat.msg_register(FRIENDS)def add_friend(msg): # 该操作会自动将新好友的消息录入，不需要重载通讯录 itchat.add_friend(**msg['Text']) # 加完好友后，给好友打个招呼 itchat.send_msg('Nice to meet you!', msg['RecommendInfo']['UserName'])# 处理群聊消息@itchat.msg_register(TEXT, isGroupChat=True)def text_reply(msg): if msg['isAt']: itchat.send(u'@%s\u2005I received: %s' % (msg['ActualNickName'], msg['Content']), msg['FromUserName'])# 在auto_login()里面提供一个True，即hotReload=True# 即可保留登陆状态# 即使程序关闭，一定时间内重新开启也可以不用重新扫码itchat.auto_login(True)itchat.run() 文本型消息转发isGroupChat=True 表示群聊消息,默认False[TEXT, SHARING] 表示文本型和分享内容 123456789101112131415161718192021222324252627# 自动回复文本等类别的群聊消息# isGroupChat=True表示为群聊消息@itchat.msg_register([TEXT, SHARING], isGroupChat=True)def group_reply_text(msg): # 消息来自于哪个群聊 chatroom_id = msg['FromUserName'] # 发送者的昵称 username = msg['ActualNickName'] # 消息并不是来自于需要同步的群 if not chatroom_id in chatroom_ids: return if msg['Type'] == TEXT: content = msg['Content'] elif msg['Type'] == SHARING: content = msg['Text'] # 根据消息类型转发至其他群 if msg['Type'] == TEXT: for item in chatrooms: if not item['UserName'] == chatroom_id: itchat.send('%s\n%s' % (username, msg['Content']), item['UserName']) elif msg['Type'] == SHARING: for item in chatrooms: if not item['UserName'] == chatroom_id: itchat.send('%s\n%s\n%s' % (username, msg['Text'], msg['Url']), item['UserName']) 多媒体信息转发1234567891011121314151617181920212223# 自动回复图片等类别的群聊消息# isGroupChat=True表示为群聊消息 @itchat.msg_register([PICTURE, ATTACHMENT, VIDEO], isGroupChat=True)def group_reply_media(msg): # 消息来自于哪个群聊 chatroom_id = msg['FromUserName'] # 发送者的昵称 username = msg['ActualNickName'] # 消息并不是来自于需要同步的群 if not chatroom_id in chatroom_ids: return # 如果为gif图片则不转发 if msg['FileName'][-4:] == '.gif': return # 下载图片等文件 msg['Text'](msg['FileName']) # 转发至其他需要同步消息的群聊 for item in chatrooms: if not item['UserName'] == chatroom_id: itchat.send('@%s@%s' % (&#123;'Picture': 'img', 'Video': 'vid'&#125;.get(msg['Type'], 'fil'), msg['FileName']), item['UserName'])]]></content>
      <tags>
        <tag>Python</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2010%2F01%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
